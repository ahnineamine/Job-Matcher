{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DocSim.ipynb\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import unicodedata\n",
    "import import_ipynb\n",
    "from DocSim import DocSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE =8, CI=0, DS=1, DA=3\n"
     ]
    }
   ],
   "source": [
    "#load word embeddings model\n",
    "model_path = \"./models/word2vec_model_optim\"\n",
    "model = KeyedVectors.load(model_path)\n",
    "\n",
    "#initiate DocSim object\n",
    "ds = DocSim(model)\n",
    "\"\"\"\n",
    "---this part is for Json file input---\n",
    "\n",
    "L_input=[]\n",
    "L_index=[]\n",
    "data = json.loads(open('test-data.json').read()) #name of json file in general\n",
    "for cv in data['cv']:\n",
    "    index = cv['id']\n",
    "    content = cv['exp']+','+ cv['skill']\n",
    "    L_input.append(content)   \n",
    "    L_index.append(index)\n",
    "\n",
    "content_offer = data['job']['title']+','+data['job']['desc']+','+data['job']['req']\n",
    "L_input.append(content_offer)\n",
    "\n",
    "\"\"\"\n",
    "def get_data(file):\n",
    "    with open(file) as f:\n",
    "        line_list=[]\n",
    "        index_list = []\n",
    "        for index,l in enumerate(f):\n",
    "            line = l.rstrip('\\n')\n",
    "            line_uni = unicodedata.normalize(\"NFKD\",line)\n",
    "            line_list.append(line_uni)\n",
    "            index_list.append(index)\n",
    "    return line_list,index_list\n",
    "\n",
    "\n",
    "L_input,L_index= get_data('data/validation_data/advanced_validation_SE.csv')\n",
    "\n",
    "sim_scores = ds.calculate_similarity(L_input,L_index)\n",
    "\n",
    "def category(dic):\n",
    "    DS,DA,SE,CI=0,0,0,0\n",
    "    for i in range(0,12):\n",
    "        if dic[i].get('id') <= 21 :\n",
    "            SE += 1\n",
    "        elif 22 <= dic[i].get('id') <= 42:\n",
    "            CI+=1\n",
    "        elif 43 <= dic[i].get('id') <= 60:\n",
    "            DS+=1\n",
    "        else:\n",
    "            DA+=1\n",
    "    return('SE ={}, CI={}, DS={}, DA={}'.format(SE,CI,DS,DA))\n",
    "\n",
    "#print(sim_scores)\n",
    "print(category(sim_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
