"Senior Software Design Engineer Current employerJune 2003 to Present9/2017 - Present; Web Development* Maintained Tomcat java applications, integrated major software libraries updates into java applications, added pagination to database app to improve performance of rendering the data through a browser, simplified code base to pull out common routines into its own library, and rewrote java standalone application to a Tomcat application* Research new JavaScript Framework for future web/desktop application11/2015 - 9/2018; ServiceNow Development* Configure, Develop, implement and maintain multiple ServiceNow modules including, but not limited to: Incident Management, Change Management, Knowledge Management, and Service Catalog* Configure and customize ServiceNow applications, including creating workflows, writing JavaScript, customizing the UI, and managing groups & roles to meet user requirements.* Analyze, troubleshoot, and fix identified ServiceNow system issues and operational support tickets* Maintain ServiceNow instance across multiple Government fabrics.6/2003 - 11/2015; C++ Software Development* Involved in C++ software design reviews, which consist of developing algorithms, discussion on integrating GOTS/COTS software, creating use cases, and designing data flow diagrams.* Designed, coded and modified various software components in C++ and Ruby.* Integrated C++ prototype software into the current Program software product baseline. This included modifying and debugging the prototype software to correct defects and adapt to new hardware.* Designed and coded new C++ software adapters to intercommunicate between the current Program existing code and the prototype code.* Started the initial development of a central logging server which will capture, store and display log files from various C++ software components. This task will allow for analysis of historical data, check for anomalies, and impediments in the software system.* Lead a C++ software development project to integrate NetFlow traffic collection software. This involved coordinating requirements with the customer, determining hardware/software task, implementing software changes, integration testing, coordinating deployment and maintaining the flow system.* Implemented and maintained C/C++ applications for creating, authorizing and tagging metadata records from network traffic on a Linux Operating System.* Created scripts for transferring metadata files across servers, packaging software products, installing the software product and establishing control scripts for the software applications.* Unit test, document and version controlled software under a Subversion repository and/or ClearCase repository.* Reviewed and modified software applications changes with other software developers, database developers and/or system engineers.* Assist with developing and executing test procedures for transitioned, modified and new software components.* Wrote and reviewed software and system documentation for transitioned code, new software components and software deployments.* Assist with the deployment and maintenance of the software systems deployed to the customer’s site.* Mentored newly hired employees into the program; assist them with resources to execute their daily task.* Reviewed resumes and interviewed candidates for Software Design Engineer positions.* Training: Red Hat Linux Application Development and Porting, Essential of ClearCase UCM, Solaris Internals, Advanced Programming in Java, Snort IDS training and certification, Introduction to Scrum, Internet Security for Technicians, Certified Ethical Hacker v7 Prep Boot Camp and Proctored Exam, ServiceNow Fundamentals, Scripting in ServiceNow and Application Development in ServiceNow.,""TECHNICAL EXPERTISELanguages:     C++, C, Java, JavaScript, Perl, Linux/Unix Shell Scripting,                          Ruby, Boost C++ Libraries, XMLConcepts:        Object Oriented Design, Scrum/Agile Development, Test                         Driven Development, Java ServletsSoftware:         Subversion, Vim, Word, Visio, Excel, MySQL, Tomcat, Visual                         Studio Code, EclipseSystems:         Linux (Red Hat, CentOS)""";;;
"Chief Software Engineer Engineer with PLCSeptember 2018 to PresentWonderware Archestra lead software Engineer with PLC development Projects for Medical devices, government automated fueling system, tank gauging, integrated network configurations, and cyber security.  Also, Archestra and SCADA system development for the chemical, and oil and gas industries.  IIOT for windows and lynx networking with server 2012 to 2016 including all CIP standards.Professional	VistakonSenior Control System EngineerRockwell Automation PLC and Wonderware Archestra and RS Logix PLCSeptember 2017 to Presentdevelopment for the Projects for Medical devices including contact lenses and remediation for the FDA quality requirements.  Instrumentation for the contact lens manufacturing with photo eyes, VFD's, robotics and conveyors.Professional	Saft BatteryTelecom, Mobility and ESS Program Manager Contract300A BMMMarch 2016 to August 2017Filmwerks and Evolion Program Manager for management of the battery in various industries including mobility, transportation and energy.  Manage Engineers and procurement for program work including professional design, software updates, quality improvement and technological advancement.PLC/HMI, Software and Network Product ManagerRockwell Automation Factory Talk Vantage Point EMI Web PortalNovember 2014 to February 2016Professional	EESCOExperience	11/2014 - 02/2016PLC/HMI, Software and Network Product ManagerRockwell Automation Factory Talk Vantage Point EMI Web Portal, Factory Talk Historian SE/ME, Factory Talk View SE/ME, PanelView Plus 6 and 7 and Control Logix 5000, 500, 5 controls distributor.  Cisco and Stratix networking hardware and software solutions.  Also, represent encompass partners for I/O hardware and software solutions.  Responsible for the demonstrations and management of all Rockwell Automation products concerning the PLC, HMI, Software and Networking solutions.  Rockwell Automation Factory Talk Vantage Point EMI Web Portal, Factory Talk Historian SE, Factory Talk View SE, and Control Logix 5000 controls programming.  Reporting responsibilities include the excelcious and excel programming with dash boards for mobile applications.Professional	ACESenior Project ManagerGE Proficy - Latrobe, PAJanuary 2013 to October 2014Also managed the installation of Wonderware reporting, InSQL and  Allen Bradley RSLOGIX additions for US STEEL in Clairton, PA.  Work with RTP safety system for Wonderware connectivity.  Responsible for the Wonderware MES and SQL development for the steel manufacturing industries located in Welland Canada, Harrow Canada, Thomasville Alabama, Chicago Illinois, and Plymouth Michigan.  Also provided help support for Microsoft installations throughout field installations.  Also responsible for the major project upgrade from GE IFIX to Wonderware System Platform including addition of SAP, thinclient, VMWare, Gray Matter Junot NLINK.  Also Foxboro I/A modification and programming for Chemical plant PPG Industries.  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.  Accredited Rockwell Automation/Allen Bradley solutions provider.Professional	InvensysSenior Field Service and Application EngineerInfusion and FCS - Wilkinsburg, PAAugust 2008 to December 2012Water Authority, Kraton Chemical, Mark West Chemical Plant, Homeland Energy, DOW Corning, Neenah Paper, Cliffs Natural Resources, Morehead State University and Lewistown PA Water Authority, and Chemical plant PPG Industries.  .  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.Control Systems EngineerElliott Co - Jeannette, PAJanuary 2007 to July 2008Responsible for the Siemens Simatic S7 PLC and Safety Matrix programming, formulations and calculations for a Liquid Natural Gas facility in Yemen.  Responsible for the Wonderware HMI and Bently Nevada Control System to control and communicate with the GE Gas Turbine Mark IV and Invensys Foxboro I/A Series DCS systems.  Also, responsible for the Allen Bradley Control Logix PLC, Wonderware HMI and Bently Nevada controls programming and communications for a Liquid Natural Gas facility in Russia.  Responsible for the Emerson DeltaV and Provox DCS with AIM historian for multimillion dollar Chemical plant process facility.  Also, responsible for the Allen Bradley Control Logix PLC, for power and water treatment controls.  Responsible for the direction and supervision of project work with instrument and electrical personnel.  Manage duties of project work with contractors and union employees including all instrumentation and controls equipment.  .  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.Control Systems EngineerAlliant Ammunition and Powder Company, Radford Army Ammunition Plant (RFAAP)January 2000 to December 2006Responsible for the identification and management of major process software applications and the leadership, direction and management of Electrical and Instrumentation employees for all military and commercial propellants and ammunition/ordnance manufactured by Alliant Ammunition and Powder Company at the Radford Army Ammunition Plant.  Maintenance engineering functions included support of all drives, motors and instrumentation with direction and management of assigned instrument and electrical personnel.  Managed projects including wireless digital security camera system, wireless integration of electronic forms in various manufacturing areas and wireless integration of intrinsically safe PDA x10-Ex i.roc integrated barcode readers infrastructure for final propellant operations.  Responsible for the control of the Lighthammer Web Server, InSQL Web Server, Windows NT, 2000 and XP workstations, Windows NT and 2000 Servers, Wonderware HMI and Modicon and Siemens PLC's for a chemical process facility.  Also, Allen-Bradley and Triconex PLC's, Taylor MOD 300 DCS, Intellution HMI, Honeywell TDC3000, Process Windows and Protool.  Government liaison for projects REDMAP, MANATEE and CBRNE.  Responsible for adherence to production schedules and budgets, personnel development and training, plant and supplier Statistical Process Control (SPC) programs, and interaction with Government Quality personnel.  Key contributor to the successful award of several multimillion dollar technologically-advanced, government-financed environmental excellence projects.  Additional experience in Visual Basic.NET programming for manufacturing area that automated daily logging of real-time data.  Played key role in establishing vertical integration for DOD facility and launch of new cutting-edge automation for the propellant industry.  Responsible for establishing and managing a new collaborative manufacturing network for current and future operation needs.  Performance areas include strong technical and project management skills in automation applications and controls systems.  Successful background in development of strategic planning, analysis and identification of solutions for custom-engineered projects related to environmental awareness and prevention practices.  Also, responsible for the testing of the Mark IV DCS control system including all Analog and Discrete points respectively.  .  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.Deputy Program Manager, Hydra 70 System, MK 90 ProgramResponsible for helping oversee all aspects of the Multi year 1 PP5 ($122M) MK90 program including contractual, financial, production, quality, customer satisfaction/liaison. Strictly monitored quality activities including Six Sigma and process improvement projects.  Worked diligently with the statistical process control integrated process team evaluating and preparing cost of quality yields. Helped to compile and evaluate finance and labor rate data and implement project proposals including SOW, RFP and RFQ.  Developed a very good working relationship with the customer (GDATP) in Burlington as well as the Army and Navy customers.  Directly responsible for providing work instructions to salary and wage employees in the areas of Quality Assurance, Quality Engineering, Quality Control and Technical Engineering.  Responsible for adherence to production schedules and budgets, personnel development and training, plant and supplier Statistical Process Control (SPC) programs, and interaction with Government Quality personnel.Six Sigma Green BeltResponsible for leading Six Sigma project for propellant operation with a savings of ~ $250K for this segment of the business.Six Sigma Black Belt Team MemberResponsible for leading Six Sigma project for propellant operation with a savings of ~ $1M for this segment of the business.Microsoft Certified Systems EngineerAlliant Ammunition and Powder Company, Radford Army Ammunition Plant (RFAAP)2002 to 2002DFSS (Design For Six Sigma) CertifiedVoice of the customer, defining metrics, quantifying results, and effective reporting return on investment.MCSE (Microsoft Certified Systems Engineer)MCSE, MCSA and MCP for Windows 2000 Professional and Server Including Active Directory, Directory Services Infrastructure, and Network Infrastructure and Security, 2002.Control Systems EngineerCDI Engineering - Saint Albans, WVNovember 1997 to January 2000Responsible for the project work involving cost reduction and increase in revenue for the chemical manufacturing facility Union Carbide/DOW Chemical in Charleston, WV.  Specific duties included PLC control design, database construction, Modicon Concept, Rockwell software RSLogix 5 and 500, Triconex and Siemens programming and Modicon Process Windows configuration.  Traveled extensively for Union Carbide/DOW Chemical for Year 2000 collections of critically sensitive process data, worth over $100 million. .  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.Electrical EngineerKvaerner John Brown Engineering - Charleston, WVJanuary 1995 to November 1997Responsible for the project work involving PLC and DCS control design, database construction and upgrade, Intergraph and AutoCAD design support, DuPont software PSR, CCS and automatic cable router, retrofit and non-retrofit upgrade and startup, Allen Bradley and Wonderware modification, Bailey INFI90 DCS upgrade and Modicon Taylor installation.  Developed a very good working relationship with the customers DuPont and Flexsys in Charleston, WV as a representative of Kvaerner John Brown.  Also reduced operating costs and refined process of specialty resins by implementing $2 million distributed control system. .  Member of ISA and compliant of ISA standards for all project work.  NEC compliant for all project work regarding class 1 div 1 and 2 classifications.Instrument EngineerProcess Instruments - Cross Lanes, WVJuly 1993 to December 1993Responsible for project work involving the retrofit PLC and DCS upgrade at the chemical plant facility of Union Carbide in South Charleston, WV including Taylor MOD 300 programming, Triconex, and Honeywell TDC 3000 Graphics Interface support.  Contributed to the success of $3 million project for refractory and chemical plant retrofit and Upgrade.,""Four years Program Management ExperienceCertified Six Sigma Black BeltCertified Six Sigma Green BeltCertified MCSEPMP/PMBOK ClassEffective Communication, Organization and Planning SkillsPC Skilled in Word, Excel, PowerPoint, Visio, Project, SQL, VB.NET, VMS, Lotus Notes, SAP and AutocadProgramming	Four years VB.NET and SQL programming with database and historian connection""";;;
"Software Engineer 2014 to Present Principal Software Engineer Broadcom Corporation2014 to 2014Strong written and verbal	• Developed/maintained SDK including, proprietary firmware, technical communications 	documentation and open source softwar eFirmware and embedded software	• Worked with OEM customers to solidify project requirements and specifications• Created and provided technical documentation Software	• Supported/trained field application engineers and sales/marketing groups• Provided technical presentations, debug and technical support at customer C/C++ sitesPython	• Maintained functional FreeBSD network device driver• Developed and maintained Linux network drivers and submitted to kernel.orgBASH and other shell scripting• Windows networking software and device driver developmentGit, Linux, FreeBSD, Windows, UEFI,• Wrote and debugged Ethernet and MAC/PHY/MDIO/I2C/SOC softwareBIOS• Created Ethernet controller UEFI DXE driver• New hardware bring-up and FPGA supportSoftware EngineerMarvell2000Software EngineerUEFI, BIOS, TCP/IP, networking, OS internals, hardware interface, CPUs,""Skills	• Analyze/debug system software/hardware/device drivers using PCIe analyzer,""";;;
"Software Engineer / Senior Software Engineer Green Hills Software - Palm Harbor, FL2006 to PresentRequirements-based test engineer for Safety- and Security-Critical Products. Focused on robust testing and analysis directed toward EAL6+ and DO-178B Level A standards-based software certification. Extensive experience with real-time operating systems, including task scheduling, memory management, multi-threading, inter-process communication, device I/O management, interrupt controllers, and simultaneous multi-core processing with an emphasis on common resource bandwidth allocation. Primary activities have included: • Supervision and coordination of a team of test engineers developing automated test suites for architecture and board support and I/O device management on avionics platforms.• Management, ownership, and design of automated test platforms for board-specific software and external hardware device drivers, including support for interrupt controllers, 10/100/1000 Mbps Ethernet, UART Serial, wear-leveling NOR and NAND Flash, and USB.• Engineering solutions for controlling and restricting bandwidth across multiple parallel processors accessing shared memory and external device resources.• In-depth assessment and qualification of the interference impacts of concurrent execution in a multi-core processing environment.• Analysis and development of PowerPC and MIPS architecture support software as well as system-specific applications.• Implementation of abstract machine tests, activity monitoring, file system organization, and graphical display of program resource distribution on single- and multi-core systems.• Consolidation of pre-existing test applications into a common framework for improved efficiency and portability.• Documentation of detailed technical analysis of partition integrity, platform vulnerabilities, and processor- and device-specific capabilities for enhancement of product efficiency and security.• Process-oriented development, review, and verification of software requirements and documentation.,""TECHNICAL EXPERTISEPLATFORMS	Windows, Linux.LANGUAGES	C, C++, Java, PowerPC assembly, MIPS assembly.SOFTWARE	Microsoft Office suite, MULTI IDE, INTEGRITY RTOS.PROTOCOLS	PCI, NOR/NAND Flash, Serial, USB, TCP/IP, UDP, TFTP, ARINC-653.""";;;
"Lead documentation outlining software requirements Raytheon Software Engineer IJuly 2018 to PresentJuly 2018 - Present? Implement messages sent to and from real time embedded flight software and test software in C and C++? Design, integrate, and implement search manager algorithm into flight software using VxWorks IDE in C? Lead documentation outlining software requirements, timing graphs, and logic flow? Provide feedback on build schedule, manage AGILE workflow process, and communicate roadblocks in software to product team lead? Assist Integrated Project Team Lead in writing key software proposals and outlining costs for materials and labor? Teach new hires about flight software, track channels, and test GUIResearcherSmart Campus Energy LabJanuary 2018 to May 2018? Developed statistical model using Python to pre-process, normalize by zenith angle, and predict solar irradiance data? Worked on implementing batch machine learning algorithms: Least Mean Squares, AR, and ARMAProgram ManagerSmart Campus Energy LabMay 2017 to May 2018? Organized monthly lab presentations & parts orders, weekly leadership meetings, recruitment & outreach, and resources? Liaison with professor and UHM Energy Coordinator to update progress of 45 students and 7+ projectsSoftware Engineer InternRaytheon Software Engineer IMay 2017 to August 2017? Refactored classes to support Visual Studio 2005 to 2012 migration and increased code reliability to createexecutable? Compiled satellite simulations and access data sets with various scenarios with Satellite Tool Kit (STK)? Developed software to transmit and receive packets through a spacecraft communication network? Worked in an agile development environment and promptly completed sprint tasksStudent Research Assistant, Biological EngineeringUniversity of Hawaii at ManoaAugust 2014 to January 2017? Developed script to automate temperature regulation using ATmega328P MCU programmed in C? Tested hand-held incubator to be used in conjunction with the Smart-DART DNA amplification machine for on-sitemicrobial contamination and disease detectionStudent ResearcherTokyo University of Agriculture and Technology - Tokyo2016 to July 2016? Developed line tracing algorithm using IR sensors to control autonomous robot in C for LPC1343 MCU? Designed an electromyography circuit to measure electrical impulses in muscles on the ATmega328P MCU in C,""SKILLS & QUALIFICATIONS:Programming Languages/Tools: C, C++, MATLAB, Python, RTOS, VxWorks, CSS, HTML, JavaScript, Git, SVN, Gulp, JIRA, AGILE,GreenHills, Six Sigma, LeanCapable of reading, writing, and speaking Japanese, Secret Clearance""";;;
"Software Engineer Elementz Engineer's Guild Pvt Ltd - Thiruvananthapuram, KeralaJanuary 2018 to July 2018India.•   Developed software for Bluetooth Low Energy (Bluetooth 4.0) devices, using Apple's iBeacon and SEGGER EmbeddedStudio for ARM IDE, to implement a project called Smart IoT Home Automation.•   Designed a user interface, in MPLAB X IDE for the visualization of a radar using 2D graphics, to enhance the user experienceof an obstacle avoiding robot.•   Designed software using Arduino IDE, for the timing of the three different colors in a traffic light system, for 'KELTRON', a Govt. of Kerala owned enterprise.Software EngineerGES Infotek, Technopark - Thiruvananthapuram, KeralaJuly 2017 to December 2017India.• Developed a part of the User Interface using WPF & C# in Microsoft Visual Studio IDE, for a HMI system in an automationbased production unit for a MNC.• Designed the automation logic software, using PLC's in GX Works IDE using Structured Text and C, for the HMI system of an automation line for testing of mobile phones.• Developed software for the timing logic of the automation trays in the conveyer system, which was used for the testing of mobile units.,""Javascript (Less than 1 year), MySQL (Less than 1 year)""";;;
"Software Engineer I-Engineering Software IncMay 2016 to November 2017 EXPERIENCE (7 Years) Worked on Ecommerce System in FinelineSetting USA from May 2016- Nov 2017. In my past have worked as Sr. Software Engineer in Gspan Automation since 04 May 2014 to 11 May 2016. I have worked Software Engineer at I-Engineering Software Inc., Ahmedabad for 3.5 Years. The Projects undertaken till now by me are mentioned below.? Project Name: FLSWEB (Web Application)• Front-End: C#.net with MVC• Back-End: SQL 2013• Team Size: 1• Project Duration: 18 Months• Responsibilities: Converting ERP from desktop to web application for Manufacturing company with includes all the technical functionalities in MVC, Crystal Reports, PDF/Report Generation, Barcode labels printing? Project Name: Groundspan Partners (Web Application)• Front-End: C#.net(WPF)• Back-End: SQL• Team Size: 2• Project Duration: 8 Months• Responsibilities: Maintainence Project- Upgrading current sytem from 3.0 framework to	MVC. This project is responsible for parsing of data in required format to the client/ Travel Agencies.? Project Name: Santa Cruz- Reports(Dev Express) (Desktop Application)• Front-End: C#.net(WPF)• Back-End: SQL• Team Size: 2• Project Duration: 4 Months• Responsibilities: Creating reports using DevXpress third party tool.? Project Name: Booking Management System (BMS) (Web Application)• Front-End: C#.net• Back-End: SQL• Team Size: 1• Project Duration: 8 months• Responsibilities: Maintainence Project- Performance Tuning at page Level and Database side. SP tuning, introduced Custom paging in Gridview removed dynamic table which was used to display data. Enhancement of new functionalities.? Project Name: All Line Insurance System(ALIS)-Cheque Printing Software (WPF-WCF Application)• Client: Many US Insurance Companies• Front-End: C#.net• Back-End: SQL• Team Size: 1• Project Duration: 3 Months• Description: It is used to print cheque dynamically for one of client using crystal reports on their cheque leaf. Co-ordinates for cheques are admin driven. It will print cheques based on the co-ordinates are set in the admin.Here all the data in chequ leaf are dynamic. Along with the all labels in leaf.? Project Name: All Line Insurance System(ALIS)-Accounting-Claims Module(Integration)• Client: Many US Insurance Companies• Front-End: C#.net• Back-End: T-SQL• Team Size: 1• Project Duration: 7 Months• Profile: Integration of Two modules of ALIS product.• Responsibilities: Creating GUI, Class Files, WebServices, Creating Store Procedures, Views, Synonyms, working with Javascript, Json, XML, AJAX and Crystal Reports, UserControls, Database tuning• Description: This Module handling all the Claims payment in Accounting System: Check Printing and all actual posting of data occurs in Accounting module. Capturing of all reqiuired data for accounting is done here.? Project Name: All Line Insurance System(ALIS)-Accounting Module(Web Application)• Client: Many US Insurance Companies• Front-End: C#.net• Back-End: T-SQL• Team Size: 4• Project Duration: 1 Year 4 Months• Profile: Implementation of Web based Accounting Module into system.• Responsibilities: Creating GUI, Class Files, WebServices, Creating Store Procedures, Views, Synonyms, working with Javascript, XML, AJAX and Crystal Reports, UserControls, Database tuning• Description: This Module is the handling account department for MGA. This consists of various sub modules like General Ledgers, Payables and Receivable, Check Register. Also have various crystal report for verifying dues of invoices and payments applied in these invoices.? Project Name: All Line Insurance System(ALIS)-Cheque Printing Software (Crystal Report)• Client: Many US Insurance Companies• Front-End: C#.net• Back-End: SQL• Team Size: 1• Project Duration: 6 Months• Profile: Implementation of Actual Check Printing Software in Accounting Module.• Responsibilities: Creating GUI, Class Files, Creating Store Procedures, working with Javascript, XML, AJAX and Crystal Reports.• Description: It is used to print cheque dynamically for one of client using crystal reports on their cheque leaf. Co-ordinates for cheques are admin driven. It will print cheques based on the co-ordinates are set in the admin.? Project Name: All Line Insurance System(ALIS)-Claim Manager (Web Application)• Client: US Insurance Companies• Front-end: C#.net•	Back-End: SQL• Team Size: 2• Project Duration: 10 months• Profile: Implementation of Claim Manager Module into system.• Responsibilities: Creating GUI, Class Files, Creating Store Procedures, Synonyms, working with Javascript and AJAX, UserControls.• Description: This module handle Claiming for the insured. Which capture information of insured, its policy, claim file and its incident file.Payment for claimant are handled.? Project Name: Inventory Management System (Window Application)• Client: 8th Semester College Project• Front-end: C#.Net• Back -end: SQL• Project Duration: 3 Months• Team Members: 2? Project Name: Restaurant Management System• Client: 3rd Semester College Project• Front-end: Visual Basic 6.0• Project Duration: 6 Months• Profile: Implementation system  using Visual Basic 6.0,""TECHNICAL SKILLSLanguages: ASP.Net(C#) with MVC, AJAX, XML, Javascript, Crystal Reports,WPF, WCF(Beginner),3rd Party Tools: DevXpressD.B.M.S: MS SQL Server-2013, MS SQL Server-2008, MS SQL Server-2005, MS AccessOperating Systems: MS WindowsWeb Designing: HTML, ASP 3.0, Photoshop, Dreamweaver""";;;
"Embedded Firmware EngineerInterface Masters Technologies - San Jose, CAJuly 2017 to PresentC,linux,bash,pythonLead Engineer Automotive Infotainment deviceTech MahindraNovember 2011 to May 2012Worked to integrate the FM car radio module. (Using NXP FM radio chip set) with the automotive infotainment device for Mahindra vehicles. The code could also support android devices.Module Lead Automotive diagnostic toolAutomotive company (USA)November 2009 to November 2011The automotive diagnostic tool communicated with the vehicle ECU and received the error. We used the (CAN based and proprietary) automotive protocols to talk to ECUs using our scanner tool.• Was responsible for the design and development of the complete J1939  automotive protocol based module.• Worked on the on board diagnostic protocol OBD-1, OBD-2 for the scanner.• Was involved in writing the flash algorithm to support external flash and use it to store the constant data thereby providing a temporary work around to the team as the internal flash was insufficient.Embedded Software Engineer Access Control system (Encoder/Reader) RFMindtree ltd for UTCJanuary 2008 to August 2008system (Encoder/Reader)-Mifare, iCLASS, NFCMindtree ltd for UTC- January 2008 to August 2008• Was responsible for the design and development of the complete iclass reader module. The iCLASS and also worked on Awid /Mifare and magnetic reader.• Was involved in interfacing it with the control module /lock using the ORP (proprietary) protocol.• Fixing bugs in the control module lock application code and adding new features to the lock. Worked closely with the hard ware team in debugging of boards.• Optimization of speed and current consumption of the lock.• Work involved transfer of data between the card reader and a block in the control module through the SPI interface. The work also included the SPI driver (master mode).• The device now supports NFC supported FeliCa, Mifare, 14443 Type-B, iCLASS cards. The command frames were transferred between the MSP (mixed signal processor) microcontroller and the reader SoC through the SPI driver.Firmware engineer SONET / SDH firmware API developmentMindtree ltdMay 2007 to December 2007• Developed the SONET firmware API(s) to support the EoS (Ethernet over SONET), EoPoS (Ethernet over PDH over SONET), PoS (Packet over SONET) modes in various path configurations like EoS VC-4, EoS VC-3 etc.• The SONET packets received were sent to the Ethernet or PDH side based on the path. The PDH or Ethernet (10/100/1000 Mbps) packets to be transmitted as SONET frame were converted to STM-1/STS-3 frame (SDH/SONET) (synchronous transport module) and sent as OC-3 through the fiber optic network.Feature Addition/Code fixing of Data PathMindtree LimitedNovember 2006 to April 2007Mindtree Limited - November 2006 to April 2007• Had to analyze the cause of the packets getting dropped in the receive interface NP after learning the architecture, IXP2400 instruction set• Added packet counters to the receiver Rx driver of the PP which could detect and log the various types of faulty packets entering the network processor.I had reviewed and optimized the packet processing pipeline code.SLAC device driver for routerMindtree LimitedJanuary 2006 to October 2006• Involved in porting of the customer supplied SLIC/SLAC device driver to SMBR.• Developed various dynamically loadable test kernel modules for testing the integrity of the Ctrl-E interface, firmware download to the ADSL daughter card and reading the status registers of the ADSL daughter card.Code PortingMindtree LimitedNovember 2005 to December 2005Ported VG4800 APIs and an application used to test the Co-systems CoPCE 1600 Rev 5.1 boards to Linux.Technology Skills C, Linux,""Technical Skills:• OS - RTOS, Linux(2.6 kernel), Windows• Languages - C, Microcode(Intel IXP2400/IXP2350NP)• Tools / simulators: - Andriod SDK,Gdb, Code warrior, Intel Developer Workbench 4.2, Host Simulator, IAR embedded workbench IDE-JTAG Debugger (Texas Instruments), Source Insight, X-manager, Win-CVS, SVN, Arm Boot, Arm-Linux GCC compiler, Asterisk PBX.• Technology/ Protocol - Automotive diagnostics SAEj1939, CAN, obd-1, obd-2 protocols, NFC (Near field communication ), SONET, SPI driver, UART,canalyzer.""";;;
"Software Engineer ClearWave Software January 2016 to PresentAt Clearwave Software I work on a team building several applications for differententerprise companies and a large portion of my contribution is with E&J Galloworking on a significant software project called Wineos. In addition, at ClearWaveI have implemented server-less technologies in Node to custom full-stack webapplications using Angular/Node and Java/Spring.Software DeveloperGymformed.comAugust 2017 to August 2017I worked with a team of developers building a Angular application with Node andKoajs. In addition, at Gymformed I migrated from Firebase to a custom backendapi with mysql. This startup is a mobile focussed fitness application with a webapplication dashboard that can be downloaded at the apple app store.R&D Software development and DesignWolfram Lights IncJuly 2009 to March 2016July 2009 - March 2018R&D Software  and EngineerinG- R&D internal software tooling- Delegate product builds for each department - Effectively solve new challenges and maintain efficiency throughout departments.Software DeveloperCounty of StanislausSeptember 2015 to 2016Private contract for the County of Stanislaus to build a web application calledGreenTag. This application was designed to replace the need for buildinginspection paperwork. I was the team lead of development and reversedengineered a mobile android application to run in the web browser. Technologiesused for this app were, Angular, Javascript and Firebase, Java, Spring-boot.Software EngineerThinfilm Electronics - Modesto, CAJanuary 2019I work as a full stack JavaScript developer.i am proficient in Angular, ionic, node, typescript, express, my sql, sql server,""SKILLS     Programming in Javascript, Node, Angular(latest), Typescript, Ionic, HTML, CSS,Express, Git, Npm, Bootstrap, REST, MongoDB, Mongoose, Firebase, SQL, MySQL,Microsoft sql server, terminal. Experience with Jira, AWS, and many more.""";;;
"Software Engineer Orchard Software - Carmel, INFebruary 2014 to Present• Project lead for multiple large new development modules created in Java, JavaScript, Typescript and JQuery these projects ranged from 10000 to 20000 lines of code and required working closely with Product Management on the design as well as other senior developers to achieve the desired outcome on time • Content matter expert for Typescript and the lead developer in decoupling the company's legacy system back end from the browser front end. This entailed creating new infrastructure in Typescript to help facilitate development in this language as well as training guides and meetings to help other developers learn the language and best practices for it • Designed, developed and maintained modules for Harvest, the number one hospital laboratory software in the United States. Using the environment 4th Dimension. This development entailed large scale projects for major features requested by clients, small feature requests and bug fixes for minor to major issues • Designed, built and maintained HL7 2.3 and 2.5.1 interfaces. These include patient, laboratory and billing interfaces for both results outbound and inbound and for billing outbound • Wrote extensive and detailed technical documents for both end users and in-house testing for all the software I created.• Reviewed code and technical documentation for other developers to help reduce bugs and critical oversights • Trained and mentored new hires in the basic and advanced practices of Orchard Software as well as industry standards and expectations • Assisted in the hiring of new team members including resume review, interviewing and input on the final decision for the best candidate,""Skills Profile:? Expert skill level? JQuery? Typescript? JavaScript? SQL? HTML? 4Th Dimension? Advanced knowledge of VBA? Advanced knowledge of PHP? Advanced skill with Gerrit change management systems and the Git repository? Proficient with Microsoft Word, Excel, Access, and PowerPoint? Leadership and organizational skills? Team oriented? Experienced in mentoring new developers""";;;
"Senior Software Engineer EnterPi Software Solutions August 2017 to Present Worked as Software Engineer in Vsoft consulting Inc. from November 2017 to Apr 2018.? Worked as Software Engineer in Athena Global Technologies Ltd., from 7th December to November 2017.? Worked as a Software Developer in UBN Qtech Solutions, from 1st March 2013 to 30th November 2015.Projects:Yoyo Grocerieshttp://app.yoyo.doRole: Dedicated Developer,Team: 3,Frontend Technologies: Html5, Css3, JavaScript, jQuery, Bootstrap, Ajax.Backend Technologies: Php, Laravel 5.1, FCM Push Notifications, Implemented Cron Jobs.Database: MySQLWeb services: Restful,Roles & Responsibilities:? Responsible implementing Restful Web Api's and Development of Scrum Tasks.? Followed AGILE Methodology and attend in SCRUM Meetings.? Designed Entire Database SchemaDescription:Online E-Commerce Platform for selling alcohol in US. User/Purchaser can order the products online directly or the User/Purchaser can split the amount to multiple persons to pay the order amount through a link. The ordered product will be received by the nearest Sellers and they can deliver the order, in case no seller responds to the order, After 5 Minutes admin will responds to order and assigns to a seller to get it delivered.Veloscienthttps://app.velosccient.comRole: Leading Team,Team: 4,Frontend Technologies: Html5, Css3, JavaScript, jQuery, Bootstrap, Ajax.Backend Technologies: Php, Codeigniter (PHP Framework).Database: MySQLWeb services: Restful,Roles & Responsibilities:? Responsible implementing Restful Web Api's.? Followed AGILE Methodology and attend in SCRUM Meetings.? Designed Entire Database SchemaDescription:Veloscient is a user driven data capture and documentation service, for use on mobile devices. Clinicians can create customized data collection forms on our web application that can be immediately available for patient data collection on a mobile or tablet device through the clinician or patient app. It can be used as a stand-alone system or integrated into an existing EHR to provide a flexible, intuitive interface, assured to enhance speed of data capture during a clinical consultation. Veloscient empowers medical professionals to take control over their clinical notes by allowing users to create meaningful clinical data capture tools that can be immediately accessed on their mobile device of choice. World's First global clinical note knowledge sharing platform.Medleymedhttp://medleymed.comRole: Team Member,Team: 8,Frontend Technologies: Html5, Css3, JavaScript, jQuery, Bootstrap, AjaxBackend Technologies: Php, Codeigniter, implemented GCM Push Notification.Database: MySQLWeb services: RestfulDescription:Tag line of 'Health is harmony', MedleyMed seeks to reimagine healthcare for the new age - with the patient at the centre. Our vision is to harness the power of technology to orchestrate the complex healthcare value chain for the benefit of patients. We are improving accessibility, reliability and affordability through efficient demand aggregation, supply chain reengineering and analytics.Roles & Responsibilities:? Responsible implementing Restful web API's.? Followed AGILE Methodology and participated in SCRUM Meetings.Goldnsliverwww.goldnsilver.inRole: Team Member,Team: 6,Frontend Technologies: Html5, Css3, JavaScript, jQuery, Bootstrap, AjaxBackend Technologies: Php, Laravel(5.1)Database: MySQLWeb services: RestfulDescription:The Portal www.Goldnsilver.in is an E-Commerce Portal based on Marketplace Model. Currently the Portal has products under Minted Products, which are all MMTC-PAMP products. It will have only Handpicked and Quality Sellers on its Portal.The Objective of the ecommerce portal www.GoldnSilver.in is to *  Provide the Pure and Quality Products to Customers.*  Ensure the Trust of the Customers.*  Create Transparency in the Pricing of the Gold and Silver Products.*  To be a One Stop Portal for Buying of the Gold and Silver Products at the LowestRate in the Country with the best QualityRoles & Responsibilities:? Responsible Integrating in Restful Api's.? Coding and developing php code for the websites from scratch, using a practical approach and meeting the client requirements.Greycampushttp://www.greycampus.comRole: Team Member,Team: 6,Frontend Technologies: Html5, Css3, JavaScript, jQuery, Bootstrap, AjaxBackend Technologies: Php, Laravel (5.0)Database: MySQLWeb services: RestfulDescription:Greycampus is a leading provider of on-demand training that address the unique learning needs ofProfessionals, delivered as online self-learning, online virtual training or in-person classroom training. It provides quality training enabling professionals to achieve their certification and career enhancement goals. It offer training for certifications in areas of Big Data & Analytics, Project Management, IT Service Management, Quality Management, Mobile & Cloud, IT Security Management and Workplace Tools. User buys a product here will have the access to the learn.greycampus.com with automatic registration.Roles & Responsibilities:? Responsible implementing Restful Web Api's.? Followed AGILE Methodology and participated in SCRUM Meetings.Banyan Storehttp://banyanstore.com/Website is about E-commerce Portal, built with Laravel.CineScopehttp://www.cinescope.in/Online movies watch application built with Laravel.,""Operating Systems: Windows, Ubuntu.Other skills:, Angular Js, NodeJs.Web Hosting: AWS, GodaddySFTP Servers: BitwiseSSHCLient, Winscp, putty, Ftp etc.""";;;
Software Engineer CXT SOFTWARE - RemoteMay 2016 to February 2019• Focused on backend development with C#, WCF, and Microsoft SQL Server, as well as use of Microsoft Azure• Involved in employee training and inter-team cooperation• Integrated our software with external APIs - primarily Google• Automated some of our common tasks with Powershell scriptsMedical Coding Analyst IIIUNM Comprehensive Cancer Research & Treatment Center - Albuquerque, NM2012 to May 2016• Abstract ICD-9, ICD-10, and CPT codes from medical records• Conduct training for other employeesMedical CoderHealthSpring (now Cigna-Healthspring) - Houston, TX2011 to 2012• Abstracted ICD-9 codes from medical recordsContract Web DeveloperProlink Media (now Inturact) (contract) - Houston, TX2010 to 2010• Developed a web application using PHP and MySQLWeb DeveloperAECsoft USA, Inc (now Sci Quest Inc) - Houston, TX2007 to 2010• Created and revised web applications using ASP.NET, C#, and SQL,• Worked in a team-based, fast-paced environmentFreelance Web DeveloperGood Fibrations (no longer in business) - Houston, TX2006 to 2009• Developed and maintained a web application using PHP and MySQL.Web Developer InternshipBoone Distributors, Inc - Houston, TX2006 to 2006• Added functionality to company forum using PHP.,I would prefer a remote position.  Note that I currently have been working remotely quite effectively since 2016.;;;
"Sr. Software Engineer (DevOps Engineer) Itrigon Software Solutions June 2016 to Present Platform: Linux, Maven, GIT, GITHUB, CHEF, Artifactory, AWS, Ruby, Shell Scripting, JenkinsProject Description:Vodafone ASM based on the he Sun and One Portal those are a web portal to a variety of Vodafone operational systems, including Remedy/Clarify. The MyCW Portal website interfaces with a Service Layer that routes requests and responses to the correct Vodafone systems. One Portal is a web based portal which will front services like Quote to Order, Fault ticket management for selected Vodafone fixed line Products and is for both internal and external customers. This portal application acts as a one stop for all the analysts for gathering information from various internal and external sources.Responsibilities as Software Engineer• Responsible for versioning the source code, releasing binary files, creating and applying labels on source files and release files Using GIT.• Defining, building and automating CI/CD build pipeline using Jenkins.• Responsible for identifying, troubleshooting and resolving problems with the build process using Jenkins and ensures that the release has been accepted by all parties.• Periodically monitored logs for optimal performance.• Resolving conflicts occurred in merging process.• Create/upload cookbooks using Ruby in Chef and trouble shoot issues while convergence.• Worked closely with Developers, QA and project management for smooth scheduled releases. Participated in the application builds and deployments to Dev, QA, Pre-Prod and Prod environments.• Involved in the release process and deployed applications (WAR, EAR and JAR).• Configured and Managed AWS services like EC2, CloudWatch, ELB, AUTOSCALING.• Troubleshoot build issues and coordinate with development team on resolving build issues.• Worked on minimally with Maven build scripts.• Maintain knowledge base to track known issues and their resolutions.• Updating the release note for every release.• Involved in the documentation of all the process and procedures.• Joining into bridge calls and providing necessary information to teams are involved.Project Assignment 2: Green Quotient SystemsSr. Software Engineer (DevOps Engineer)Itrigon Software SolutionsAugust 2014 to PresentTechnical SpecificationsSoftware EngineerItrigon Software SolutionsAugust 2014 to May 2016Platform: .Linux, ANT, SVN, Ansible, shell scripting, Jenkins.• Duration: Aug 2014 to  May 2016Project DescriptionGQ Maps is a software platform to measure asset utilization and energy consumption, dynamically. It is a Cloud enabled application that monitors a heterogeneous ICT landscape and generates real-time and historical reports on application and asset utilization and imputed energy costs.Roles and Responsibilities as DevOps Engineer:• Responsible for versioning the source code, releasing binary files, creating and applying labels on source files and release files.• Led Jenkins continuous integration server installation and configuration for all SVN Repositories.• Defined branching and merging strategies.• Automated application packaging and deployments. Managed Linux staging and testing environments.• Established coding standards and enforced them through automated tools.• Educated team about continuous integration and automated testing practices and supported them throughout development.• Configured Jenkins to implement nightly builds on daily basis and generated change log that includes changes happened from last 24 hours.• Created multiple ANT, MAVEN, Shell scripts for build automation and deployment.• Configured and maintain Nexus Servers for storing final build Artifacts.• Automated deployment using Ansible.• Documented the SCM process and policies of the company and recommended some process changes.• Responsible for writing the Release Notes, documenting all the useful info about the release, software versions, changes implemented in current release, Defects fixed, Labels applied.• Deployed Java/J2EE applications on to Apache Tomcat application servers and configured it to host the wiki website.,""? Operating Systems: LINUX/UNIX, Windows.? Version Control Tools: SVN, GIT and GITHUB.? Contiguous Integration tools: Hudson/Jenkins.? Build Tools: Ant, Maven.? Artifact management tools: Artifactory.? Configuration Management tools: Chef.? Virtualization: Docker, Vagrant.? Cloud Services: AWS.? Databases: SQL, PostgreSQL.? Application Servers: Apache Tomcat.? Programming Languages: Java.? Scripting Languages: Shell Scripting Python and Ruby""";;;
"Software Engineer Canela Software - Temecula, CA2016 to Present Developed a database technology in LiveCode, a scripting language, including the database language itself, the distributed cloud storage, and the management portal software o Responsible for improving the speed of accessing and querying data by 50% o Utilized Ansible to automates servers' maintenance and deployment o Constructed a portal software that allows users to view their data • Designed and developed healthcare software with database integration that handles millions of records o Contributed to the software throughout its software development life cycle, from system design and requirements analysis, to development, deployment, and training.o Overcame the challenge of creating a database software that functions in the environment without internet access while preserving the data securely and upload the data to the cloud later.• Regularly communicate and meet with clients and implement their input • Performed routine software testing, debugging, and maintenance • Experienced with restful API • Provided technical support for clients • Implemented UI/UX for multiple software •   Improved software security to keep up with industry standard,""SKILLSWorking Knowledge:• LiveCode, Python, C++, Java, C#Basic Knowledge:• R, Ansible, SQL, Various NoSQL databases""";;;
Software Engineer Domico Software - Oakland, CAApril 2000 to Present Serve as a key member of a software development team, designing, coding and maintaining Web-based and legacy self-storage software products.• Successfully integrated a credit card interface authorizing real time payments based on sparse technical documentation and limited resources.• Developed and deployed complex T-SQL queries, stored procedures, and functions to populate a customized reporting suite for self-storage facilities.• Partnered with technical support to improve departmental lines of communication to expedite issue reporting, and customer feedback.Designed User Interface for desktop and Web-based products, from conceptualization through implementation.Travel ConsultantBancroft Travel Inc - Berkeley, CAFebruary 1990 to July 1995I was hired to file brochures, and deliver airline tickets on the UC Berkeley campus.  Within 3 months, I was promoted to Travel Consultant and spent the next 5 years working with faculty, staff and students from UC Berkeley, planning domestic and international travel.   It is here that I gained professional customer service experience, and was privileged to work with an experienced and nurturing team of owner agents.,Skill Summary• Data Analysis• Report Creation• Visual Basic .NET• Microsoft SQL Server• Web Services• Advanced Excel• Complex SQL Queries• Technical Writing• Typing: 70 WPM;;;
"Senior Software Engineer/Firmware Engineer Various Personal Inventions - Freelance Software/Embedded Firmware Engineer - Boulder, COJanuary 2018 to PresentSenior Software/Embedded Firmware EngineerRiskBand - Denver, COSeptember 2017 to January 2018Developed an untethered wearable emergency response platform. Aided in the bringup of our device. Brought up the LCD watch display and developed a 9-bit SPI driver to communicate with the watch display. Designed and developed a small footprint display library to meet our resource needs. The Display was divided into several regions that were managed by our custom library. All production code is written in C/C++. Test applications and supporting applications are written in Python.Advisory Software EngineerIBM - Boulder, COFebruary 2015 to December 2016Designed and developed the Allegro automated server provisioning engine. Allegro is currently being used by IBM and other large data centers to automate their server deployment. Allegro is a Ruby/Rails web application with an AngularJS front end. The server side code is written in Ruby with MongoDB as the database. We took advantage of the flexibility of Docker containers to deploy our software. I also created Docker containers to deploy our development environment greatly speeding up the on boarding process for new employees. All software and tools were developed using Agile software methods. GIT was the primary version control system for our division in IBM.Staff Software/Firmware EngineerMedtronic/Covidien - Boulder, COApril 2008 to February 2015Developed software for real-time embedded electro-surgical devices currently used in the medical industry. Developed code for several microprocessors and DSPs in C++ using common design patterns. Developed a lightweight RPN scripting language and interpreter for our embedded devices. Designed and developed many applications and test fixtures in Java to support our electro-surgical generators including applications to flash, service and stress test the generators. I designed and developed a C#.NET application to interface with the ForceTriad and collect real-time electrical data from the generator during clinical trials. All software and tools were developed using Agile software methods.Senior Software/Embedded Firmware Engineer, Engineer Manager/Team LeadiTi Imaging Technology International - Boulder, COOctober 2005 to April 2008Led a team of 4 software engineers in the design and development of several core printing and vision analysis tools in the iTi product line. Worked closely with both the electrical engineering and mechanical engineering groups to develop a line of laboratory and production printers. I am very comfortable working with electronics. The software for these motion and vision systems consisted of controller microcode, device drivers, communications layers, and graphical interfaces. I designed and developed microcode for several popular motion controllers, developed drivers for a data pump PCI card, developed image processing algorithms and developed GUI's for the different systems. I have developed several .NET applications to distribute iTi software and license iTi software over the web. Ported the middle tier API from C++ to C#.NET and redesigned the MFC GUI in .NET.Senior Software\Embedded Firmware EngineerIndependent Contractor Services - Boulder, COMarch 2003 to August 2005Worked with a small construction company to gain a strong knowledge of the industry and determine software needs for the trade. Designed and developed weather and ground monitoring stations for the construction industry. This is a portable self contained station that can be placed on construction sites prior to development of the site. This station monitors ground temperature at several depths, precipitation, air temperature, and moisture content of soil and sun intensity. This station gathers data and posts it to a website for contractors to view and make decisions on when to start construction. This station was developed from individual electronic components and several micro processors. Designed the form factor of the station. Designed and developed C#, ASP.NET applications to help with the bidding process and tracking of active construction projects allowing general contractors, sub contractors and clients better communicate. This application allowed all parties to view and communicate on a daily basis so problems could be identified immediately keeping the project on schedule. Designed and developed C#, ASP.NET applications for other areas of the construction industry for later resale.Senior Software EngineerLegato Systems Inc - Louisville, COJune 1999 to March 2003Worked with the Legato marketing and development teams to design software to backup large storage area networks in a Windows NT environment. Designed and developed MFCapplications to configure and monitor the Legato Replication Driver. I Designed and developed a Snapshot Control Module for EMC SnapView that runs on the EMC Clariion network storage system. This enables Legato Networker to manage the snapshots. Designed and developed a storage area network discovery tool. This tool enabled querying of the SAN for any possible storage devices.Software EngineerSystemSoft Corporation - Boulder, COAugust 1995 to October 1998Developed multi-threaded applications with client/server architecture and a DHTML user interface. Components are written in C++ using ActiveX and COM. ActiveX objects are accessed through VB Script and JScript in HTML and ASP pages. Developed applications, which integrate voice and data over a standard phone line using the VoiceView protocol, developed by Radish. Designed the applications using OOD methodologies and coded them in C++. Integrated the VoiceView protocol with standard computer telephony hardware on UNIX and Windows NT systems. Developed other applications for Windows 95 and Windows 3.11 with the MFC library. One of which is the VoiceView client, which is shipped by many PC manufacturers including Packard Bell, HP, Acer, AST, and Sony.,""Operating Systems: Windows, Linux, Embedded Linux, ThreadX, Embedded Systems with no OS""";;;
"Chief Software Architect/ Software Engineer Dataflyt Software - Lake Charles, LAPresent-  Chief Software Architect and Software Developer in charge the design and development of data driven Graphical User Interface software, operated on Windows and Linux Operating Systems platforms. net-centric database capabilities using JSON protocols to communicate near-real-time cargo tracking metadata to next generation hand-held android scanning devices. Projects - FlytSuite M3-Manifester, the company’s flagship ‘flight manifesting’ software product. - Fully implements new Java based database-to-web communications capability into the baseline, tied to ISN lookup services, greatly enhancing our client’s ability to visualize and quickly verify critical training and credential information, while providing an interface for end user validations.  - Effectively plans and demonstrates proof-of-concept capabilities.  - Designs and implements graphical means for processing (parallel and multi-source) operator-generated flight data across LAN and WAN networks. Develops dynamic flight and sub-leg segment creation, assigning and weighing cargo, and presents metadata by segment for pre-flight review. All done in Java SWING and JavaFX, using MAVEN structured GUICE dependency service injection and a fully responsive state-machine software design.·       Databases: SQL (Postgre-sql), Couch-DB, Couch-DB Lite, Microsoft ACCESS, Mongo-DB·       Architecture: standardized MAVEN structures, GUICE Services, Dependency Injection, and JUnit testing·       Software Design: code written primarily using JAVA Swing and JAVA-FX libraries with FXML. ·       Release Builds/Version Control:  performed using GIT, BitBucket, and TeamCity·       Agile Methodology:  Atlassian's collaboration software (JIRA, CONFLUENCE, BitBucket, HipChat)Software Systems EngineerNorthrop Grumman Corporation - Redondo Beach, CAJune 1999 to July 2011•	Software Systems Engineer / Team Lead,                                     (3 year assignment)Managed Core Systems Integration Software Development over ‘Vertisee Program’ – a multi system/multi-platform, highly adaptable near-real time networked data visualization toolset.         Was the chief software architect over prototype design, and assigned as manager over project development, testing, and deployment tasks.        This powerful software can be network-tied to almost any data-driven system to produce on-call analysis, metrics, events, alarms, and re-playable post-run simulations.          Operated both actively and passively to direct massive databased and data-stream military intelligence systems toward a central processor of constant situational awareness displays, for command level decision makers.          Presented the finished product at the 2010 Technology Expo. Praised by CEO’s and stakeholders as a ‘must have’ for winning future contract bids•	Software Developer, Classified Program Support 		         (6 year assignment)Developed software products for a wide range of high valued programs geared for processing Live multi-source data streams and networked databases to identify/geo-locate ground and airborne assets using orbiting space systems.  Focused on creating powerful scientific algorithms and tools for performing fast data analysis, dynamic event handling, event prediction/response, and in-depth product capability demonstrations.  Was recognized for software presented to our United States Congress and Japan’s DIET Council •	Software Developer, ‘Mosaic’ Program 		                       (1 year assignment)‘Mosaic’ –  a competitive ballistic missile tracking program written in C-language and legacy Fortran code.  When old tracking methods failed to meet our customer’s stringent accuracy requirements, I conceived an algorithm using ‘closest approach’ principles learned in calculus to overcome dual-sensor range errors.  My resulting algorithm proved to be remarkably accurate; passing acceptance tests while greatly improving processing and response times•	Software Integration and Test, ‘Diamond and 4171’ Programs	         (2 year assignment)Integrated new code and developed software that thoroughly tested critical subsystems on-board highly classified national assets.  Played a key role in troubleshooting efforts.  Received award for maintaining a 100% pass rating on all Quality Assurance and ISO 9000 reviews,""Technical Hobbies/Side Interests:  Developed (for fun) custom end-to-end software historical stock market trade analysis gui (analysis/filtering/scoring of NASDAQ mass historical data-sets)Technical SkillsetsPROGRAMMING: (Expert) Java, C++, C-Language (Experienced), XHTML, JavaScript, Perl/ Perl-Tk,Segue & Roadrunner Auto Software Test-Suite, (Educated) AssemblyPLATFORMS and SYSTEMS: (WINDOWS, UNIX, LINUX, MAC, SUNSPARC Workstations)SW IDEs: (ECLIPSE, MS Visual Studio, INTELLI-J)OFFICE SUITES: (Expert) Spread-Sheet Designer (Microsoft EXCEL)"; (Expert) Word Processing                            Author (Microsoft WORD);" (Expert) Presentation Designer (Microsoft PowerPoint)AGILE FRAMEWORK:  Atlassian's collaboration software(JIRA, CONFLUENCE, BitBucket, HipChat)WEB SERVER SERVICES: (AWS) Amazon Web ServicesDATABASES: (SQL, SQL-Lite, APACHE Tomcat, Mongo DB, H2, PostgreSQL, Couch DB, CouchBaseLite DB) FRAMEWORKS/TOOLS: MAVENVERSION CONTROL: GIT, CVS    BUILD MANAGEMENT: TeamCity""";
"Software Engineer Gcom Software Inc - New York, NYFebruary 2010 to PresentDevelop and implement new software programs.• Maintain and improve the performance of existing software.• Regularly communicate with network team and technical support colleagues.• Design and update software database.• Test and maintain software products to ensure strong functionality and optimization.• Recommend improvements to existing software programs as necessary.• Generating daily, weekly & monthly Outage report.• Developing BTS report generating tools.AnalystNew York, NYJanuary 2008 to January 2010Develop Supply Chain Management software as per as requirements.• Maintain and improve the performance of existing software.• Design and update software database.• Test and maintain software products to ensure strong functionality and optimization.• Recommend improvements to existing software programs as necessary,""Interested in Research. One my best research topic mentioned here:AMP: An Adaptive MAC Protocol For Cognitive Radio Ad-Hoc NetworkDEVELOPED IN TCL, PYTHON & PERL• To Identify parameters in cognitive radio environment that play important roles for route selection.• To develop an interface between network simulation and machine learning environment that enables data interchanging.""";;;
"Software Engineer Breitenbach Software Engineering - NRWFebruary 2019 to PresentSoftware Development• Research, design and implement a full ERP System used by thousands of people.• Implenent Applications on various Platforms(Android, Apple, Windows, Linux)• Research, design and implement custom IDE and Compilers for embedded SystemsSoftware DeveloperroTeg - Dortmund, DEAugust 2016 to February 2019Software Development• Implementing and deploying Real Time Application handling automatic robotic systems.• Research, design and implement a custom ERP(Enterprise Relationship Planning) System.• Research, design and implementing a Realtime Web Server as API(Application programming Interface) and Overview for data analyses.• Focus on individual clientele need and advise actions regarding the maintenance of the robotic systemsIT TechnicianCucos Retail-Systems - Soest, DEAugust 2015 to August 2016System Integration• Assemble and deploy Retail Systems for Supermarkets,""SKILL Highlights• RESTful API design• Efficient data management (MySQL, MS Server, Mongo-db)• Sound knowledge in C, C++, Pascal, Java• Basic knowledge in Javascript, HTML, C#, Python, PHP, Assembly• Frameworks: Bootstrap, jQuery, Laravel• Libraries: Node.js, React, AngularJS• Basics in Penetration Testing (Hobby)• Writing smaller test cases and reviewsPrivate Projects• Android App using Android Studio(Java)• Personal Website using PHP with Laravel as MVC(Model-View-Controller)""";;;
"Lead Software Engineer Quest SoftwareApril 2000 to PresentLead Software Engineer creating industry leading space management and monitoringtool for the Oracle database, which greatly simplified database management tasks, while incorporating the latest Oracle features• Developed database replication software for Oracle, SQL Server and Postgres• C#, C++, Java, Python, Delphi, PL/SQLSoftware EngineerInternet Tools CorporationFebruary 2000 to April 2000• Developed Internet applications for electronic marketing and targeted e-mail• Delphi, HTML, JavaScript, SQL ServerSoftware Engineer, Megabyte SystemsMarch 1998 to February 2000• Designed and developed client/server application for property tax processing• ISAPI application for Internet inquiry• Delphi, SQL Server, Crystal WriterSoftware EngineerADPJune 1997 to March 1998• Developed database application for automation of vehicle registration and inquiry processes• Delphi, SQL Server,""Specialties: C#, C++, .NET, Java, Python, Delphi, Oracle internals, SQL, PL/SQL, SQL Server,Postgres, Object Oriented Programming, GUI design, TCP/IP, XML, JSON, Agile Development""";;;
"Software Engineer Focus School Software - Saint Petersburg, FLJuly 2016 to January 2018Providing software enhancements to all of Florida public schools.• Programmed a JSON like parser to find data on MSQL database server.• Created advanced school reporting • Enhanced audit trail to be human readableProprietorWl Mark Inc2006 to 2016Launched revolutionary wifi AAA portal, enabling many small businesses to become WISPS.Cutting edge software that was in a constant state of evolution to fit the growing needs of clients.• Wifi Networking.• Switch Configuration.• Router configuration with maximum security for wifi hosts.• PCI compliance.• Database administration.•   Linux administration.•   RADIUS Server.•   Advanced programming and web development.•   Customer support (Technical).,""Soft Skills	• CSS3.• Object Oriented Programming (OOP)Leadership	• jQuery, javaScript.Team Oriented• PHP / SQL (Postgres, MSSQL, MySQL/Maria DB).Problem SolvingTime Management• Linux Admin.Customer Relations	• Graphic Design, Photoshop.Motivated	• OSI and DOD models.Self Starter	• IP ranges and subnet masking (VLSM).Hard Skills	• Authentication and access controls.• Firewalls, DMZ, ACL.Hardware Installation	• SNMP (Trap).Software Installation	• IPS/IDS.Security	• CAT5e/6 toning, testing and terminating.System Patch/Maintenance• Zendesk/Jira.Programming""";;;
"Software Engineer DPS Software March 2016 to March 2019in DPS Software, which provides a legal document management system that helps law firms to manage their cases for all matters. There are more than 100 law firms and more than 18,000 individual users are using this system in the UK (United Kingdom). During my stay, I worked for several products and became the product owner of the main product. Involved in backend and front- end development.Languages and Technologies used, •   C# •   Asp.net, .NET Core, MVC6, Web API 2, Classic MVC, G suite, Angular •   Web development, Back End, and Front End •   CICD with VSTSSoftware EngineerSiyanmo TechnologiesMay 2015 to March 2016in Siyanmo Technologies, provides e-commerce Desktop application and Mobile application solutions to make life easier for business world.Languages and Technologies used, •   C#, Android •   WCF application development, web API development, Android developing •   Install solutions in client sites and maintainsSoftware Engineering InterniOneSoft SolutionsNovember 2014 to May 2015Provides self-service KIOSK Salon, Hotel Software, MobileResponsive Web solutions.Languages and Technologies used, •   C# •   Classic MVC, Facebook add-insProjects •   Spitfire - A Single Page Cloud Web application for Legal Case Management (Main product)DPS SoftwareC#, .NET, .NET Core, MVC6, Azure Web Services, Azure AD, Azure SQL, VSTS, Angular 7, React JS, AzureSearch, Rad, AsposeSpitfire is a web application mainly developed using C#, .NET, .NET Core, and Azure services. It provides a rich cloud-based case management system for law firms in the UK. This is a leading product serving more than 100 law firms and around 15000 users' email management, cost management, and workflow systems.Responsibilities and Activities: •   Implemented the Mail module back-end service which is a fully functioning mail client with case management integrations. Used C#, Exchange web services, and outlook API.•   Developed Case and Client Core business logic in services.•   Used dependency injections with .NET core.•   The key developer in Backend services of the mail module.•   Global file content search using Azure Search.•   Implemented pdf editing module.•   Became the main developer and the development owner of the application.•   Application building and releasing was done with VSTS.•   Documentation and release management. •   DPS WOPI - Fully implementation of customized MS_WOPI protocolDPS SoftwareC#, .NET, .NET Core, MVC6, Azure Storages, Redis Cache, Azure SQL, VSTS,Provides office document view/edit services through Microsoft Office web app. Used customized WOPI server with fully implemented WOPI protocol and MS-FSSHTTP protocol to get the documents from proprietary storage. Enable collaborative document editing with a locking mechanismResponsibilities and Activities: •   Designing, implementing and managing the services.•   Involved in WOPI validation process with Microsoft Help Desk.•   Used dependency injections with .NET core.•   The main developer and owner of the WOPI host.•   Application building and deployment using VSTS.•   Debugging and analyzing issues, train and guide other developers.•   Documentation and release management. •   G Suite Integration for SpitfireDPS SoftwareGoogle Authentication, Gmail API, GDrive APIGoogle login was Integrated to the application. Spitfire normally uses Azure Active Directory for the authentication process. The application switched into Google services after G suite integration. Google authentication, Gmail API, G-Drive API, were used for the implementation so that a user with a corporateGoogle account can sign in to the system. JWT token was used for authentication and auth code exchange for backend API usages.Responsibilities and Activities: •   Designed a workaround to generate the access token in the backend using Google user id token and the auth code.•   Implementing Google authentication.•   Implementing Google Mail services and Google Drive services.•   Main developer and Module owner.•   Application building and deploying using VSTS.•   Documentation. •   Spitfire MS Word Add-inDPS SoftwareOffice Web Add-ins, C#, JavaScript, .NET core, MVC6, VSTO add-inSince the online MS Word editor is not fully featured, designed and developed an add-on which downloads MS word files and provides the capability to edit in local MS Word application. Then the files will be uploaded to the cloud once the user saves. First developed ad VSTO add-in and when clients are moving to O365 it convert as web add-in with Single sign-on is used therefore no login needed (Azure ad V2).Responsibilities and Activities: • Implementing VSTO add-in • Implementing front end.• Design and implementation of backend.• Authentication module for communicate between frontend and backend using single sign on.• Convert older document to Open XML formats using office interop.• Documentation. •   DPS SafeChatDPS SoftwareC#, .NET Core, Azure IOT hub, Azure queue, Azure functionSafe chat is an encrypted message chat application, this system supports for both web and mobile.Basically, it provides end to end secure channel for conversations. Any message or document sent through this system is impossible to intercept by a third party. RSA encryption applied using Azure key vault.Responsibilities and Activities: •   Implementing decryption middleware for WEB API.•   Implementing message distribution to chat group using IOt hub.•   Designed and implemented message security module.•   Documentation. •   DPS Letter EngineDPS SoftwareC#, .NET Core, Actor system, MS-OrleansThis is a letter generating module for Spitfire. Used distributed actor system to persist state during letter processing.Orleans is a framework that provides a straightforward approach to building distributed high-scale computing applications, simply this module work as follows,Front end web app communicates with actor through WebSocket, actor uses Microservices, it starts execution of template commands and keep the state alive during letter processing. The Letter engine contains number of commands to do various tasks such as prompt user for input, query backend services, substitution, formatting etc. The user interactions command push data to web browser real- time to get user input.Responsibilities and Activities: •   Implemented Letter engine command.•   Implemented Orleans actors.•   Integrated SignalR with Orlens Actor systems.•   Documentation. •   Siyan Inventory SystemSiyanmo TechnologiesC#, .NET, WPF, IIS Server, MS SQL, Crystal Report, TelerikThis product is an inventory system for small companies. Used WPF for the implementation, system has Android mobile support as-well. Mobile application will be used by sales representatives.Responsibilities and Activities: •   End to end development in GRN.•   Generate reports.•   Implement web API for mobile app.Activities & Clubs •     IESL Associate Member (The Institution of Engineers Sri Lanka) •     Active Member Astronomy Society, Editor of science society, U15 U18 Chess team (St.Anne's college),""SkillsProgramming: C#, VB, SQL, XMAL, C, XMLBasic Knowledge: Android, HTML, TypeScript, JavaScript, AngularFrameworks: net, .net core, Entity Framework, Azure Web (Platform, WebApp, Functions,Database, Web jobs, Storages, Search, Key Vault, Insights, Active DirectoryDesign Skills: OOP, UML, Design Patterns, Service oriented architectureProcesses: Agile Development (Scrum), Waterfall, Continues Integration (CI)Tools: SQL management studio, Git, Visual Studio Team Services, TFS, JIRAIDEs: Visual Studio, Visual Code, Azure Portal, NetBeansFamiliar DBMS: MsSQL, MySQL, COSMOS, GremlinPlatforms: Windows, Azure Cloud""";;;
"DevOps /Cloud Engineer Cloud Technology Partners - San Antonio, TXJanuary 2018 to PresentResponsibilities:? Creating the automated build and deployment process for application, re-engineering setup for better user experience, and leading up to building a continuous integration system for all our products.? Implementing new projects builds framework using Jenkins & maven as build framework tools? Maintaining environment and tool configurations, such as Jenkins, SonarQube, and Nexus? Implementing a Continuous Delivery framework using Jenkins, Chef, Maven & Nexus in Linux environment.? Unblocked development efforts with additional or upgraded Chef Capabilities. Wrote new chef cookbooks and utilized LWRP's from community cookbooks and recipes to build new Open Registry (nginx) application server and MongoDB server roles? Repaired broken Chef Recipes and corrected configuration problems with other chef objects.? Developed Scripts and great ideas to automate system deployment to scale infrastructure.? Leading the automation of implementation and configuration work through Chef.? Deployment and implementation of Chef for infrastructure as code initiative.? Writing different Chef Cookbooks for installing, configuration, and upgrading different applications on the Servers.? Extensively used Docker for virtualization, Ship, Run and Deploy the application securely for fasten the Build/Release Engineering.? Manage deployment automation by creating Chef Roles.? AWS Cloud management and Chef automation? Imported and managed multiple corporate applications using GIT.? Responsible for Design of different Release Environments for new projects.? Using Jenkins AWS Code Deploy plug-in to deploy into AWS.? Defining Release Process & Policy for projects early in SDLC.? Responsible for Database build, release and configuration.? Experience working with log monitoring with ELK Stack (Elasticsearch, Logstash, Kibana)? Perform Deployment of Release to various QA& UAT in Linux environments.? Configured Elastic Load Balancers with EC2 Auto scaling groups.? Extensively used Docker for virtualization, Ship, Run and Deploy the application securely for fasten the Build/Release Engineering.? Familiarity with Kubernetes, Mesos and Docker Swarm.? Created documents on build and release process and flow, release processes, order of activities for all releases, user guide for developers for local builds.? Implemented AWS solutions using E2C, S3, RDS, EBS, Elastic Load Balancer, Auto scaling groups,? Optimized volumes and EC2 instances.? Used IAM to create new accounts, roles and groups.? Created monitors, alarms and notifications for EC2 hosts using Cloud Watch.? Migrated applications to the AWS cloud Environment.? Scripting in multiple languages on UNIX, LINUX and Windows - Perl, Ruby, Shell, etc.? Work with different team members for automation of Release components.? Resolved system issues and inconsistencies in coordination with quality assurance and engineering teams.? Troubleshoot the build issue during the Jenkins build process.Environment: Solaris, Linux, Eclipse, Java, SQL, AWS EC2, Python, Subversion, Bash, Hudson, NT Command Shell, Java/J2EE, Maven, Gradle, Chef, AWS, JIRA, XML, Vagrant LINUX (RHEL, CentOS), Docker, JenkinsDevOps EngineerJade Global Inc - San Jose, CANovember 2016 to December 2017Responsibilities:? Participated in the release cycle of the product which involved environments like Development, INT, QA, UAT and Production.? Responsible for the building and deploying the artifacts into DEV, INT and QA Environments? Used Subversion as version Control for maintaining the versions.? Created Subversion configuration record for builds using derived objects generated during build audit process.? Perform biweekly build cycle and testing processes.? Used Maven to automate the build process.? Installed and Configured Nexus to manage the artifacts in different Repositories.? Configured and automated the Jenkins Build jobs for Continuous Integration.? Participated in configuring and monitoring distributed and multiple platform servers using Puppet Used Puppet server and workstation to manage and configure nodes.? Experience in managing virtual instances and disks using Puppet.? Deployed Puppet, Puppet dashboard for configuration management to existing infrastructure? Managed environments DEV, BCP, UAT and PROD for various releases and designed instance strategies.? Hands on experience with Microsoft Azure and a strong understanding of Azure capabilities and limitations.? Strong Experience using Azure cloud infrastructure environments? Expertise in Azure infrastructure management.? Managed release management and deployment, building SharePoint Farm in Azure, non- HA- Farm for development, QA, and UAT environment.? Experience in implementing and migrating and deploying workloads on Azure.? Managed backups and restored from the newly created Azure based SharePoint environment.? Basic experience with code repository systems such as BitBucket, GitHub? Deployed files from dev box using versioning controls such as GitHub, Bitbucket, Gitlab? Production experience in large environments using configuration management tool Puppet supporting with 500+ servers and involved in developing manifests.? Implemented continuous integration web hooks and workflows around Jenkins to automate the development test deploy workflow around Puppet codebase? Used Apache Tomcat as application server for deploying the artifacts.? Developed UNIX and Perl Scripts for the purpose of manual deployment of the code to the different environments and E-mail the team when the build is completed.? Experience with build tools such as Jenkins, Gradle, Maven, SonarQube, etc.? Managed and performed the environment related configuration changes as a part of deployment.? Coordinated application releases with Development, DBA, QA and Project Management teams.? Build Java code and .NET code on to different Jenkins servers as per the schedule.? Migrating J2EE, PHP, .NET, and Cold Fusion applications to UNIX and Windows environments by configuring application via IDE Eclipse, Subversion.? Coordinated Release effort among various teams (Integration, QA, Testing, and Business Analysis) in geographically separated environment.? Created deployment request tickets in Remedy for the deploying the code to Production.? Attended the Minor/Major Event change control meetings to get necessary approvals for the deployment request.? Used Perl/Shell to automate build and deployment Process.? Documented the deployment process (Migration Doc) of code to production.? Used JIRA as Issue Tracking Tool.Environment: Azure, Puppet, Jenkins, Maven, Make, JIRA, Perforce, Shell, Unix, Linux, Subversion, bitbucket, Nexus.DevOps/AWS EngineerLiberty Mutual Insurance - Boston, MAFebruary 2016 to October 2016Responsibilities:? Responsibilities included designing and developing new back-end services, maintaining and expanding our AWS infrastructure.? Involved in design, built, and deploy a multitude of application utilizing almost all of the AWS stack? Experienced in Branching, Merging, Tagging and maintaining the version across the environments? using SCM tool like GIT? Maintained build related scripts developed in Maven, Created and modified build configuration files including Ant's build.xml and Maven Pom.xml.? Managed the Version control systems GIT and GITHUB.? Hands on experience using source control systems such as GitHub and understand git workflow? Provided technical direction to development teams.? Install an OpenShift Container Platform cluster and Configured and manage masters and nodes to Secure OpenShift? Monitored and collected metrics on OpenShift to Deploy applications on OpenShift Platform Container using Source-to-Image (S2I)? Generated deployment profiles (jar, war, ear) using Jenkins.? Worked on deploying software applications on AWS and configuring EC2, RDS, EMR, Elastic beanstalk.? Involved in deploying the content Cloud platform on AWS using EC2, S3 and EBS.? Experience in Performance Tuning and Query Optimization in AWS Redshift.? Involved in all projects that move to production and work closely with the Development, Quality Assurance and Management teams to ensure cross communication and confirmed approval of all production changes? Provided end-user training for all Subversion (SVN) users to effectively use the tool.? Worked on Linux in Cloud Computing environments using AWS.? Used IAM for creating roles, users, groups and also implemented MFA to provide additional security to AWS account and its resources.? Created S3 backups using versioning enable and moving objects to Amazon Glacier for archiving purpose.? Created load balancers (ELB) and used Route53 with failover and latency options for high availability and fault tolerance.? Mastery of using JIRA defect tracking system and configuring various workflows, customizations and plugins for JIRA.? Implementing a Continuous Delivery framework using Jenkins, Puppet, Maven and Nexus in Linux environment.? Supported API development team in creating Ansible playbooks for deploying, integrating and monitoring their continuous integration environment.Environment: Jenkins, GIT, Maven, Chef, Ansible, AWS (EC2, EFS, S3, VPC, Lambda, API Gateway, Route 53 (DNS), ECS, Cloud Formation, RDS, Dynamo DB, Load Balancers, Cloud Watch, SNS, SES, SQS, IAM, Ops Works), openshift, Shell Scripting, Tomcat, Docker, UNIX, RHEL and WindowsDevOps EngineerZelos Technologies - Hyderabad, TelanganaJune 2013 to November 2015Responsibilities:? Installed and administered GIT and ensured reliability of application besides working on branching strategies for GIT.? Configured and deployed GIT repositories with branching forks, tagging, merge requests and notifications. Integrated Eclipse IDE with different versioning tools like SVN, CVS and GIT.? Developed build and deployment scripts using ANT as a build tool in Jenkins to move from one environment to another environment.? Involved in installing Jenkins on Linux environment and implemented a master and slave configuration to run multiple build operations in parallel.? Hands-on experience in configuring workflows, writing jobs in Jenkins for performing automated build and deployments.? Worked on various POCs to demonstrate the feasibility of implementing CI/CD in various projects.? Managing nightly builds, weekly builds and feature addition builds using Jenkins.? Wrote Puppet modules for Tomcat/Apache services in distributed infrastructure.? Configures Docker container, created Docker Images for various applications and worked on infrastructure with Docker containerization.? Developed Perl and Shell scripts for automation of the Build and Release process, developed Custom Scripts to monitor repositories and Server storage.? Integrated JIRA with SVN to help the change management process run smoothly.? Written Shell Scripts to deploy the Java applications into JBoss application server.? Worked on setting up WebSphere Application servers and configuring SVN and Database connection over Eclipse IDE for development teams.? Worked with developers for resolving runtime failures, troubleshoot Build and Deployment Issues with minimal downtime.? Experienced administering a large-scale distributed application environment.? Resolved system issues and inconsistencies in coordination with QA and engineering team.Environment: GIT, Ant, Ansible, Jenkins, Puppet, Docker, Shell Script, JIRA, JBoss, WebSphereLinux AdministratorCyber Security Works Pvt Ltd HydJune 2011 to March 2013Responsibilities:? Implemented test automation for web application (SWAP module) using Cucumber.? Performed Red Hat Linux Kickstart installation configurations on Red Hat 4.x/5.x/6.x, performed Red Hat Linux Kernel Tuning, memory upgrades.? Troubleshooting performance issues in IBM AIX b and Red Hat Linux Servers.? Storage provisioning, volume and File system management using LVM, Veritas Volume manager and Veritas File System (Veritas Storage Foundation), Configuring ZFS File Systems.? Troubleshooting Network, memory CPU, swap and file system issues, TCP/IP, NFS, DNS and SMTP in Linux servers.? Experience in using Nagios and Graphite monitoring system.? Maintained user access in VMware, vCenter and configured mail alerts for any failure in Dynamic Right Sizing (DRS), CPU and Memory.? Maintained Volumes and File systems for MySQL, DB2, MS Access.? Installation, maintenance and regular upgrades of Red Hat Linux servers using Kickstart based network installation.? Wrote Bash shell scripts for getting information about various Linux servers. Configured SSL for secured communication between applications.? Developed Cron tab scripts for timely running jobs and provide server status.? Installed and configured WebLogic server 10.x and JBoss 4.x.? Involved in writing reporting automation/Web tools for IT/Ops groups using LAMP (Linux Apache, MySQL, PHP) Development and Java Scripts, HTML, LDAP (Lightweight Directory Access Protocol) and Shell scripting.Environment: Linux, Shell Scripts, MS Access, Java/J2EE, Unix, MySQL, Apache, HTML, LDAP,""Technical Knowledge:Operating Systems    RHEL/CentOS 5.x/6.x/7, Ubuntu/Debian/Fedora, Sun Solaris, Windows Server, Linux/Unix.DevOps Tools         Puppet, Docker, Ansible, Chef, GitHub, AWS.Build Tools          ANT, MAVEN, Gradle, MS Build, Bash shell, VMWare.Monitoring Tools     SplunkLanguages            Shell, Bash, Ruby and Python scripting, PowerShell Scripting.Databases            MySQL, Cassandra, PostgreSQL, SQL Server.Web/App Server       Apache, IIS, HIS, Tomcat, WebSphere Application Server, JBossBug Tracking Tools   JIRAVersioning Tool      SVN, GITCI Tools             Hudson, JenkinsCloud Services       Azure, AWS- EC2, S3, IAM, Lambda, CloudTrail, CloudWatch, Auto ScalingSDLC                 Agile and Waterfall""";;;
"Cloud Engineer Commercial IT Solutions - San Antonio, TXMarch 2018 to Present Cloud Engineer focusing on both network and server administration.- Server/Switch/Access Point installs.- Data Migrations.- Office 365 / Exchange Server- Virus/Malware Removal- Data Backup and recoverySoftware / Hardware Uses:Microsoft SuiteConnect WiseVPN/VM Ware/RDP Remote SessionsCisco Meraki Switches / FirewallsWebroot.3CX and Shift 8 phones.Owner/Lead ConsultantR.A.W. IT Consulting - San Antonio, TXOctober 2017 to PresentIT Consulting for Small to Mid Size BusinessServer and Network Installation and ConfigurationCloud Computing and Virtual ServersData Backup and RestoreCCTV Installs and ConfigurationIT Management - System & Network Administrator1224 LTD / Superior Home Health - San Antonio, TXMarch 2017 to March 20181224LTD / Superior Home HealthServer Administration• Server 2008-2012 Environment• Exchange Server 2013Network Administration• Cisco switch management• Netgear switch and firewall management• Patch and Cable managementPhone/VoIP• ShoreTel Phone Systems• Administering mailbox and extensions using ShoreTel Director.Citrix Administration• Manage HCHB clients including but not limited to adding new users, password resets and account management.AT&T Mobility Administration• Administer and patch over 200 phones and tablets.• AT&T Premier account management changing IMEI/Sim for hardware swaps.• Track and locate devices, change Kiosk menus and features using MobiControl.HIPPA Compliance• Maintain and compliant to all HIPPA standards and procedures to unsure customers privacy and protection.General IT Work• Plan, organize and support client moves between difference offices and cities. Including equipment and desks.• Mount and configure all displays and kiosk systems and time clocks.• Inventory and accountability of all IT devices.• Document all policy and procedures.• Network Topology.• Assisted with new building layout and wiring, Installed, Configured, and migrated multiple EOL servers• Manage and maintained all APC battery backups with notification emails and warnings• Created company disaster recovery methods and procedures• CCTV for multiple locations to ensure privacy and security of all locations are intact.Microsoft Compliance• Maintain all logs and records of all devices serial and license numbers.• Ensure all servers have required CAL licenses.• Document all new instances of hardware and software swaps.IT System & Network AdministratorReyes Automotive Group - San Antonio, TXSeptember 2015 to March 2017Server Administration• HP Proliant and Dell Power Edge Servers.• On a daily basis administer and maintain Windows Server 2003-2012R2 supporting over 1000 users in AD and Outlook 365. Manage, host and administer Exchange server.• Red Hat Linux• Set up domains, permissions and user rightsVirtual Servers• Configure and manage 25 virtual hosts, apply updates and software as needed• . ITIL Management• Maintain, Service and Configuration the virtual Servers.Project management• Follow and plan Agile Methodology & General 6 Sigma. I plan, develop and pursued all project management projects in a timely and affordable manner.Budget control• Strive for Loss Prevention and take place in Order Management to cut costs as needed.Network Admin• Administer on a daily basis Cisco Firewall, Access Points, and Switches• Support over 20 switches and 10 Access Points. From port management to client moves and simple cable management.• Install and configure Juniper SwitchesVoIP -  Configured and administered the VoIP system by providing Inbound/Outbound Call Management, Time of day routing, Call distribution, Call recording, Disaster Recovery, Call Whisper, IVR, Voicemail to Email, Smartphone Applications, Call Statistics.• Cisco Internet Phones• ShoreTel Phone SystemGeneral IT Work• Assisted with new building layout and wiring, Installed, Configured, and migrated multiple EOL servers• Manage and maintained all APC battery backups with notification emails and warnings• Created company disaster recovery methods and procedures• Support with Service Now Ticketing System Management answering and closing tickets as needed.IT Specialist (Middle Management)Vutex Inc - San Antonio, TXJanuary 2011 to September 2015• Managed and coached a team of IT specialist on server and network administration.• Assisted with budget control and spending allotments.• Provided project management job aspects for all projects and infrastructure upgrades.• Worked with department heads to coordinate assigned projects.Windows Administrator• Installed and Configured Microsoft Servers 2003-2012R2• Worked with VMware Virtual Servers• Set up domains and user rights within Microsoft ExchangeActive Directory• Set up Group Policies• Set up User Profiles / Passwords• Set Domains / Forest Logics• DNS SupportNetwork Administrator• Installed and Configured Cisco ASA and Access points• Monitored Sonic Wall FirewallSecurity Administrator• Provided Technical Advice on Access Control• Assisted with Disaster Recovery plans• Worked with Data FailsafeVoIP -  Configured and administered the VoIP system by providing Inbound/Outbound Call Management, Time of day routing, Call distribution, Call recording, Disaster Recovery, Call Whisper, IVR, Voicemail to Email, Smartphone Applications, Call Statistics.• Intermec Phone Systems• Mitel Phone SystemsCoding Technician / Help DeskThe Hartford - San Antonio, TX2008 to 2011• Tier 1-2 Customer Service / Help DeskBasic Active DirectoryInsurance Coding TechnicianComputer TechnicianReal Property Management2006 to 2008• Microsoft Computer repair both hardware and software• Software License management• Helpdesk Related Environment (How to questions)• Print Server maintenance,""SKILLS SUMMARYManagement: Staff and Project ManagementSystems: MS Server 2003/2008/2012, Linux, Unix, JuniperSoftware: VMware, Active Directory, Logics 5000, Mattec, MS Office 2007-2016/Office 365, Google Apps, VPN, GhostNetwork: LAN administration, design, installation, configuration, maintaining infrastructure, policy creationSecurity: Symantec Antivirus Corporate Edition, Sophos Protection, LAN Security Cameras / CCTV""";;;
"SENIOR CLOUD ENGINEERGE APPLIANCES September 2018 to Present Home Delivery 2.0 Cloud EngineerIn addition to prior role responsibilities:• Primary technical resource and direct support contact for business users, external customers, and external vendors regarding Home Delivery APIs and web portal• Responsible for delegating technical tasks, reviewing work, and providing feedback to offshore team members• Track and provide updates on all tasks to IT Leadership and impacted business users regarding Home Delivery including determining deliverable dates• Interviewing and selecting college student candidates for IT internshipsCLOUD ENGINEERGE APPLIANCESApril 2016 to September 2018Home Delivery 2.0 Cloud Engineer• Work closely with the Cloud Architects, GE Infrastructure team, Commercial IT team, and business stakeholders to deliver cutting edge Cloud-based software solutions serving GEA Home Delivery Management Services• Design and develop re-usable components and operational strategies in Amazon Web Services to support scalability, high availability, performance, monitoring, backup, restore, etc. for Home Delivery 2.0 efforts• Work on a high velocity team that is expected to deliver solutions in a few weeks - from concept to delivery• Take an automation first approach to streamline business processes• Leverage modern software design principles around Test Driven Development, Continuous Integration/Continuous Delivery, version control and performance metrics• Develop and maintain architectural strategies, support, and system documentation• Assist with incident response, troubleshooting, root cause analysis, and problem resolution• Assist with the addition of new customers and users into cloud-hosted Home Delivery Management System solution• Technical Resource and direct support contact for customers and vendors• Campus Recruiter for multiple universities; Co-Lead Recruiter for University of CincinnatiOBIA TECHNICAL ANALYSTGENERAL ELECTRICAugust 2013 to April 2016Oracle Business Intelligence Applications Technical Analyst• Leader for standardization of reporting processes and documentation• Analysis of functional requirements through data queries & understanding existing warehouse structures• Develop high level design & technical specifications documentation for reports based on functional requirements• Collaborate with cross-functional teams to design solutions• Design and develop reports using OBIA technology set as per the functional and technical specs• Perform developer's testing and debugging on the issues.• Collaborate with other teams for issues originated due to data from source applications• Supporting testing life-cycle, migration and cut-over activities, and post go-live activities• Drive collaboration efforts among Business, GE IT and Third-party IT teams.4th Rotation - Problem Management and Operational AnalystGENERAL ELECTRICJune 2011 to August 2013• Refactored problem management process based on leadership• Facilitated weekly outage assessment to determine potential problems• Co-created and utilized standard templates for communication• Compiled monthly outage summaries for IT Staff and improved Operations Review process• Produced global webcast events and provided technical support• Served as technical expert during eCDS redesign efforts• Created architecture, procedure, & best practices documentation for webcast & problem mgt.3rd Rotation - Cloud and Remote Site Virtualization Engineer• Architected a new lab environment for testing new virtual products and solutions• Deployed Data Director POC and presented findings and suggestion to IT Staff• Member and strategic asset to webcast/event production team• Organized all-day, cross-business technical seminar which was broadcasted live globally• Collaborated with VMware and acted as Stage Manager during technical seminar event2nd Rotation - Project Leader supporting Legal and HR functions• Developed and implemented Social and Digital Media strategy for HR Recruiting• Analyzed Compliance Scorecard assignment code and presented findings to Legal• Collaborated with Legal to update and simplify Scorecard assignment criteria• Implemented LogMeIn Rescue chat client for HR Staffing to streamline on-boarding• Served on the Data Loss Prevention committee as an IT liaison for the Legal function1st Rotation - Security Incident Analyst• Responsible for incident management• Identified key issues with VPN filtering and delivered actionable research for future utilization• Documented and enforced whitelist review on all outbound FTP transactions• Deployed internal knowledgebase for security team through Corporate GE toolGENERAL ELECTRICMay 2009 to July 2010MAY 2009 - JULY 2010Network• Implemented Intrusion Detection System devices and configured Cisco Routers• Participated in On-Call during business hours and configured devices to help tech support callsConsumer Home Services• Reverse engineered Access databases in order to catalog them and eliminate waste• Professionally photographed parts at Indiana warehouse for GE Parts websiteSupply Chain• Analyzed current documentation process to find errors and/or room for improvement• Utilized Six Sigma tools to map out the As-Is and To-Be processes• Tested multiple solutions and presented findings to team• Initiated implementation to improve the documentation system,""Senior Cloud Engineer responsible for development and support of Home Delivery 2.0 APIs and the Home Delivery Management System web portal which utilizes Amazon Web Services and multiple programming languages. Also, a GE ITLP Graduate with broad knowledge base in several IT fields";" effective communicator across broad audiences & skilled in technical writing.Home Delivery APIs are a B2B e-commerce solution that provide a way for our customers to interact with us virtually and integrate their systems with ours to streamline the order process. The web portal provides a GUI interface to the backend APIs for customers and vendors (competitors) with some additional features.SKILLS & CERTIFICATIONSSKILLSAmazon Web Services   HTML Bootstrap   JavaScript   Technical DocumentationGo Language           SQL              Jenkins      Data Analytics""";;
IT Operations Engineer IT Video and Cloud Collaboration May 2012 to February 2019 Cisco Systems• Support, configure, and manage the infrastructure for all Cisco video productsincluding CUCM, CMS, TMS, VCS and collaboration endpoints• Work internal cases by debugging and applyingfixes in the Unified Communications Voice and TelePresence environment• Q-Duty: Monitor incoming cases assigned to group and determine to which subgroup and engineer to distribute cases to• Projects: Find areas of need within the organization and create projects to solve problems• On-Call: Provide 24/7 support for production Video/Voice environmentTelePresence EngineerSTS International for Cisco SystemsMay 2008 to May 2012• Implemented, upgraded, and maintained video environment globally• Built voice and video lab for testing of new code releases providing critical feedback to TelePresence developers• Provided high-touch TelePresence support for Cisco executive staff, setting up and overseeing critical meetings from a technical prospective• Implemented and verified global code upgrades for video hardware• Trained team members on all hardware changes, software changes and new features relating to production video environment• Setup and supported high visibility TelePresence special events• Troubleshooting production video endpoints as well as the video/voice infrastructureTelepresence Red Carpet SupportSTS International for Cisco Systems - San Jose, CAJune 2007 to May 2012Provide high-touch TelePresence support for Cisco executive staff, setting up and overseeing critical meetings from a technical prospective.Support Briefing Center Project Managers to setup and support customer facing meetings.Provide TelePresence technical training to Executive Administrators and Briefing Center Project Managers.Tier 2 Voice EngineerSTS International for Cisco Systems - San Jose, CAApril 2002 to June 2007• Troubleshooting repair requests (CUCM, Unity, TNM, EMAN)• Troubleshooting IP phone devices globally• Troubleshooting analog lines for the following devices: Polycoms, fax machines, modem, In-Ceiling Configure lines on analog cards and H323 gateways• Collaborated with Tier 3 Voice team to resolve outages and repairs• Supported Lucent PBX and Octel VM systems including installation, support and troubleshooting,HARD SKILLS• Cisco Unified Call Manager (CUCM)• Cisco Video Communication Server (VCS)• Cisco TelePresence Management Suite• Cisco WebEx• Cisco Expressway• Series• Cisco Jabber• VOIP• Cisco Collaboration EndpointsSOFT SKILLS• Collaboration• Time Management• Communication;;;
"Cloud IT Manager Datto Backup Inc - Norwalk, CTJanuary 2012 to PresentNorwalk CT		January 2012-CurrentBackup and Disaster Recov eryInternal IT Engineer, Cloud Systems Administrator, Datacenter Operations and Administration, Development and DocumentationManaged Datto’s Cloud, composed of all-purpose cloud storage and recovery-virtualization servers based on Ubuntu Linux Served as Product Manager for Datto’s Private Cloud product line, for Datto Cloud Solutions deployed to private client datacenters.Used SALT, Puppet and Ansible for Cloud Orchestration and Configuration managementManage Zabbix, Kibana and rsyslog deployments for cloud-wide system monitoring and process loggingDeveloped workflow metrics analysis with Tableau, including ties to product fleet growth. conditions and behaviorAdvanced implementations for ZFS and Zpool storage management, pioneered procedural applications of the technology in the context of optimizing incremental backup management and disaster recovery.Implemented methods to scale support for large Virtual Environments, taking Datto’s Cloud from supporting a maximum of 10 virtual machines per client to proven ability to support an environment of 70 or more virtual machines.Leveraged ITSM/ITIL and Agile SCRUM training to manage and coordinate product problem remediation, specializing in severe/urgent issues.Coordinated security and access control rollouts to large Technical Support staff of 200+ users, maintained access control lists for subroles of this departmentManaging and maintaining Zendesk ticket workflows, integrating sharing hub-spoke agreements, automations, triggers, macros and tags into procedural mechanisms for processing and logging Technical Support requests.Led development of PHP scripting to tie command-line ZFS data management back to Zendesk work-ticket documentation and workflowsExperience using Git and Jira systems for change managementExtensive experience in technical writing, composing editing and publishing Knowledge Base informational and procedural articles, organizing documentation efforts throughout a writing team.Linux routing tables and OpenVPN for managing connections to and between Cloud Virtual environmentsVirtualization  experience: VirtualBox and vboxmanage command line, VMWare, vSphere, VMWare Converter, vmkfstools command line, VMDK descriptor file manipulation, KVM command line, using ISCSI and NFS SAN storage implementations.Incremental backup-agent software deployments and Business Continuity PlanningParticipated in major overnight datacenter move and production restoration of 4 server racksIT SupervisorTowers Watson Corporation - Woodbridge, CTJanuary 2011 to January 2012Information Technology Support Analyst, Data Center Operations and Administration, VOIP Conferencing• Datacenter design and operations - Dell and HP rack servers consoled through ILO.• Network design and troubleshooting - Cisco routers, firewalls and load balancers.• Major Datacenter move and overnight operational reinstatement of working office and call center network and phone systems.• Organizing acquisition integration, desktop distribution and orientation• Entrusted access to systems management.• Managing IT communications to client management.• Researched, developed and maintained linux-based SIP/VOIP Conferencing system, manage backups, billing and Call Detail Reporting.• Manage operations change-order applications.• MSSQL and Batch scripting.• Worked on Web site development, MSSQL, MYSQL, PHP, Microsoft Excel, Windows Vista/7/Server 2003, Open Office, Ubuntu and CentOS.IT EngineerAliquant Corporation - Milford, CTSeptember 2007 to December 2010Note: Towers Watson acquired Aliquant on Jan. 1, 2011Health Benefits Outsourcing and Data Management.Information Technology and Data Center Operations• Datacenter design and operations - Dell and HP rack servers consoled through ILO.• Network design and troubleshooting - Cisco and Netgear equipment.• Research, develop, implement and maintain SNORT Intrusion Detection System.• Composing and editing procedural and technical documentation for server setups, MSSQL, batch scripted backup schemes, Web application monitoring and Intrusion Detection Systems.• Research and implement operational efficiency measures and improvements.• Work with FTP, MSSQL, PHP, Microsoft Excel, Windows Vista/7/Server 2003-2008, Open Office, Asterisk, SNORT, Ubuntu and CentOS.Technical Support EngineerDelTech LLC - Ridgefield, CTApril 2005 to August 2005Home PC Technical help, troubleshooting and repair.• Composing and editing troubleshooting procedural documentation.• Execute troubleshooting and full reload procedures on designated client machines.,""SKILLS• Obtained Cisco Networking Associate certification in November 2011 - certifications obtained in 2016 include ITIL Foundations, SCRUM Master and CompTia Cloud+.• Experienced IT Operations professional with broad expertise in networking and storage management for secure data applications.• Experienced in Bash and PHP scripting for data management and data analysis applications• Software Used: DRScout Remote Backup imaging, MSSQL, FTP, Windows XP/Vista/7/Server 2003/server2008/ Open Office, Microsoft Excel, Microsoft Powerpoint, PHP, HTML, Java, CSS, OpenVPN, VirtualBox and vboxmanage command line, VMWare, vSphere, VMWare Converter, and vmkfstools command line, ShadowProtect and ShadowSnap backup software, xshell for SSH connections, rsync, testdisk, vssadmin.  Camtasia Studio for video recording,• Familiar Systems: Windows, Ubuntu, CentOS, ESXi 4.1 through 5.1, ZFS• Experience  using Git and Jira systems for change management, configuration and management of Nagios, Monitis, and similar alerting systems.• Virtual Machine configuration, migration and conversion between most popular hypervisors - Hyper-V, VMWare, VirtualBox, Xen and KVM.• UCONN English Major, excellent reading, writing and communication skills.• 10 years experience working in trusted positions with Datacenter hardware and administrative systems access.• Experienced in researching, developing and operating office and organizational IT solutions.• Comprehensive experience developing and implementing data storage and backup, intrusion detection, and telecommunications solutions.• Extensive experience working with Virtual Machines within and between Hyper-V, VMWare, VirtualBox, KVM and Xen environments.• Extensive experience administering a linux-based cloud environment.• Extensive experience troubleshooting backups and disaster recoveries for Windows servers.• Extensive experience authoring documentation and conducting training class sessions on many IT topics.• Extensive experience maintaining IT affairs communications with client technical teams and corporate level management.  Highly experienced in communicating between technical levels to coordinate troubleshooting and project management.""";;;
"Cloud Engineer Hybridge Inc - San Mateo, CAJuly 2018 to Present-   Consultation on Cyber and Information Security, Business Continuity and Disaster Recovery, and Internal Employee IT Policy-   Providing managed services to the 100+ Bay Area Clients with an emphasis on bringing cloud solutions to the masses. Specializing in cloud infrastructure andnetwork security best practices using various software.-   Monitor security measures for firewalls, IDS, anti-virus software, authenticationsystems, log management and content filtering to ensure the protection of computer systems, client data, SIEM and cyber security.-   TCP/IP networking, workgroups, and Windows Active Directory. DNS, DHCP,SIEM tools and SMB file sharing configuration, remediation, ISO StandardsSolutions SpecialistVerizon Corporate - San Leandro, CADecember 2016 to May 2018Use my exceptional knowledge of and passions for technology, professionalism,and people skills to create the ultimate in-store experience for 100+ clients and smbs a month.Technical Support AgentGeek Squad - Vallejo, CAJuly 2014 to November 2016Provided all level IT Support to clients primarily from security/malware, network,hardware and printer troubleshooting for about 60+ clients a month.,""TECHNI CAL SKI LLS-   Information Security Analysis-   Security Incident Event Monitoring-   Malware Research-   Windows, Mac OSX, Software Testing-   LAN / WAN, TCP/IP, VPN, DHCP-   Risk assessment-   All tier level support-   Cisco Meraki Network Admin-   Python, HTML5, SQL Modeling Active Directory, Information Assurance,-   Vulnerability AssessmentPERSONAL SKI LLS-   Vast growing technical knowledge-   Self-motivated team player-   Reverse engineering thinking-   A passion for problem solving-   Great communication skills-   Active listening/learning-   Technology Design-   Business Sense-   Creativity-   AnalyticTECHNI CAL CERTI FICAT I ONS-   Cisco Meraki Network Associate (CMNA)February 2019 - Present-   Security+January 2019 - Present-   Network+January 2019 - In Progress""";;;
"AWS/Cloud Infrastructure Engineer Hercrentals Inc - Bonita Springs, FLNovember 2017 to Present Responsibilities:• Provided configuration management expertise to all software development projects.• Creation of Cost optimization metrics to Monitor, Optimize the total spend on cloud resources and Support the Cost-Effective Resources.• Monitoring, collecting and tracking metrics and setting up to react automatically to change in AWS resources.• Involved in the production release cycle, which includes phases like Development, Quality Assurance, User Acceptance Testing and Production Environments.• Acted as Release Manager on several projects utilizing various build and release tools (Team City, Jenkins, VSTS, Powershell, Terraform and many more)• Configured BitBucket with Jenkins and schedule jobs using Poll SCM option.• Developed Templates for AWS infrastructure as a code using Terraform to build staging and production environments.• Experience in setting up CI/CD pipeline integrating various tools with CloudBees Jenkins to build and run Terraform jobs to create infrastructure in AWS.• Implemented Project Management tool on AWS Cloud which requires Apache Tomcat application Server, PostgreSQL DB.• Used Jenkins for Continuous Integration and deployment into Tomcat/Web Logic Application Server.• Implemented continuous integration and tracking source code changes using Jenkins.• Build, manage, and continuously improved the build infrastructure for global software development engineering teams including implementation of build scripts, continuous integration infrastructure and deployment tools.• Created JIRA issues for prioritizing what is important, and cope up with what's going on around the project.• Integrated Maven with Jenkins for the builds as the Continuous Integration process.• Integration and automation of source control applications like Git, Liquibase, Team Foundation Server and Artifactory.• Deploying and maintaining Micro services using Docker.• Experienced on Docker, Docker Swarm, Mesos/Marathon, AWS ECS, Kubernetes• Created private cloud using Kubernetes that supports DEV, TEST, and PROD environments• Migrated docker swarm to Mesos/Marathon for the microservices project• Configured plugins for the integration tools to the version control tools.• Created Jenkins jobs for Applications for Dev, QA, STAGE and PRODUCTION Environments.• Build Java code on to different Jenkins servers as per the schedule as a DevOps engineer.• Migrated code on to Stage and Prod from Dev and QA environments.• Deployed code to Dev, QA, Stage and Production Environments.• Providing Application Support from the Infrastructure point of view.• Environment configuration and product deployments using Puppet.• Used maven profiles to create different builds so that it can be released early and released often agile/extreme programming.• Develop and maintain Perl, Shell scripts for automation of build and release tasks.• Maintained JIRA for tracking and updating project defects and tasks.• Integration of Jenkins with Jira, GITHUB.• Imported and managed multiple corporate applications in Git.• Worked with web server like Apache Tomcat for deploying and starting application, as a main part of DevOps.• Worked with cloud providers and API's for Amazon (AWS) EC2, S3, VPC with CloudSigma (EU) and GFS storage.• Troubleshooted Production issues pertaining to AWS Cloud Resources and Application Infrastructure point of view.• Managed and Documents all post deployment issues utilizing the Post Deployments Issue Log.• Kept information organized and accessible with a flexible page hierarchy using confluence pages.• Documentation of builds, source control processes, plans and the work done to mitigate future projects.• Assisted my seniors and project leaders in troubleshooting technical issues.• Involved in Scrum meetings, artifacts and other scrum activities in collaboration with the team.Environment: AWS Cloud Resources, Perl Scripting, Shell Scripting, Subversion, Kubernetes, JIRA, GIT, Puppet, Apache Tomcat, Confluence, Bamboo, Terraform, Docker, Maven and Jenkins.AWS EngineerOn Max Solution and Services - Bowie, MDMay 2016 to October 2017Responsibilities:• Provision AWS resources using management console as well as Command Line Interface. (CLI)• Plan, build and configure network infrastructure within the VPC with public and private subnets and configure routing tables and internet gateway.• Responsible for launching EC2 instances w/ Linux AMI and bootstrapping with Apache using Bash scripting, auto-scaling and Load balancers (ELB).• Define Security Groups depending on access parameters provided.• Create IAM user accounts and role-based policies for access to AWS services.• Perform automated snapshots using CloudWatch rules and create EBS volumes from snapshots.• Implement and maintain monitors, alarms, and notifications for EC2 instances using CloudWatch and SNS.• Implementing a Continuous Delivery framework using Jenkins, Puppet, Maven & Nexus in Linux environment• Archived outdated data to Glacier through Life Cycle Policy configuration.• Launching databases via RDS to support web application functionality.• Worked with cloud providers and API's for Amazon (AWS) EC2, S3, VPC with CloudSigma (EU) and GFS storage.• Virtualized the servers using the Docker for the test environments and dev-environments needs. And also configuration automation using Docker containers.• Experienced on Docker, Docker Swarm, Mesos/Marathon, AWS ECS and Kubernetes.• Create CloudFormation stacks and templates to provision AWS resources.• Create low latency website using S3, Cloud Front, and Route53.• Installed Apache Web Server.• Create and manage user permissions, directories and files in Linux environment.• Automated the cloud deployements using Ansible, Python and AWS Cloud Formation Templates.• Set up Ansible environment for configuration management, Dynamo DB, Elastic cache and Lambda.• Responsible for Continuous Integration (CI) and Continuous Delivery (CD) process implementation using Jenkins along with PYTHON and Shell scripts to automate routine jobs.• Configured terraform with Jenkins and schedule jobs using Poll SCM option• Coordinated and assisted the developers in establishing and applying appropriate branching, labeling/naming conventions using GIT source control.• Worked with GitHub private repositories.• Developed build and deployment scripts using ANT and MAVEN as build tools in Jenkins to move from one environment to other environments.Environment: VPC, subnets, EC2, AMI, Internet gateways, CloudWatch, SNS, S3, CloudFront, CloudFormation, Apache Web Server, Linux, Ansible, Jenkins, Docker, Nexus, Dynamo DB, Elastic cache and Lambda.AWS Operations EngineerRSG Media Systems LLC - New York, NYFebruary 2015 to April 2016Responsibilities:• Designed Architectural diagrams based up on the client requirements for their application hosting in the AWS Cloud Environments.• Created AWS computing instance Services like EC2 and Amazon Elastic Load Balancing in AWS Cloud.• Created and managed AWS Storage services like S3, EBS and Amazon CloudFront.• Created an Amazon RDS and Handled software installation, backups, and patches as well as routine administrative tasks.• Implemented popular networking services like Amazon Virtual private Cloud (VPC) for the private cloud in the public cloud.• Worked with Amazon Web Services (EC2, Elastic search, Route53, Elastic Beanstalk, VPC, Iaas).• Configured and implemented the Amazon EC2 instances for our application teams.• Troubleshooting issues with the application developers to the EC2 instances.• Configured the SSL certificates for EC2, database and Amazon cli servers.• Created User accounts for the Development group, DB-Group, Testing group by using AWS IAM service.• Monitoring the AWS Infrastructure Response Time, Application/Service availability, Backend Transaction time, Throughput using CloudWatch and Site24x7.• Configured Federation services for the Applications Single-SignOn in AWS cloud using AWS IAM service• Automating daily and incremental backups by using Duplicati tool for windows to transfer the data in to S3.• Created Alarms and Alerts in CloudWatch, Site24x7 and AWS SNS services for monitoring the Servers Performance CPU Utilization, Diskspace, Storage and Bandwidth Utilization.• Worked on Puppet to perform automation of Configuration management and application deployments.• Configured VPN'S for the communication between the servers of AWS side and client side.• Written multiple cookbooks in Chef using Ruby scripting language.• Create Chef Recipes, automation tools and builds, and do an overall process improvement to any manual processes.• Worked in an agile development team to deliver an end to end continuous integration/continuous delivery product in an open source environment using tools like Chef& Jenkins.• Developed and implemented Software Configuration Management strategies for various applications according to the agile process using Git/GitHub.• Designed, implemented, and support of automated containerized infrastructure, leveraging continuous integration and continuous delivery processes for service development, and cluster/monitoring/day2 tooling for infrastructure service deployment and administration.• Maintained and executed Build scripts to automate development and production builds.• Maintained and administered the Source code repositories, including implementation of automated controls and enhancements.• Developed custom images on Cloud using AWS AMI'S (Amazon Machine Images) and on VMware ESX using Templates.• Monitored health check of servers after patching / rebooting and checked all the services of Linux servers on AWS Cloud and also physical servers.• Worked on Popular Application Services like Amazon Simple Queue Service (SQS) and Simple Workflow Service (SWS).• Worked with Storage Area Network (SAN) team to get LUNS (EMC and Hitachi) and scan them on both RHEL and Solaris servers to create/expand the File systems and worked with Network Attached Storage (NAS) to allocate NAS on different servers.• Proactive maintenance on systems by timely scheduling of at jobs, batch jobs and Cronjobs, Auto-sys Jobs. Worked on Scheduling cronjobs, installed the necessary packages for back up requirement.• Designed and scripting using Gradle & MAVEN for (J2EE, WebServices, Reusable JARS, Web Client and Open Source) in creating MasterBuild.xml.• Developed and maintained UNIX/Perl/Gradle scripts for Java/J2EE build and release tasks.• Using Docker container enabled rapid deployment with minimum run-time requirements.• Worked in DevOps group running Jenkins in a Docker container with EC2 slaves in Amazon AWS cloud configuration.  Also gain familiarity with surrounding technologies such as Mesos (and Mesosphere) and Kubernetes.• Developed PowerShell/Ruby Scripts for automation purpose.• Installed Jenkins and Nexus, Performed troubleshooting during the build failures.• Installed and configured J2EE Application servers on Windows and Unix Environments.• Installed fix packs to overcome App server problems.• Implemented Migration planning, developed, tested and moved the migration process onto full-fledged production network.• Created documentation for Client environments, processes Technical training and support procedures.Environment: Amazon EC2 Services, VPC, S3, Glacier, CloudWatch, Cloudformation, Puppet, Chef, Bash, Jira, Nexus, RedHat Linux, Cisco UCS, EMC SAN, VMware, Windows 2012, Windows2008, Microsoft exchange, DNS, DHCP, NFS.Storage/Cloud AdministratorAllstate Inc - Chicago, ILAugust 2013 to January 2015Responsibilities:• Experience in working with EMC private cloud with VMware stack using VCE VBLOCK environment.• Worked with EMC, Cisco and VMware vendors to understand the plan to implement the VCE private cloud infrastructure in the environment.• Worked on Installing and implementing the profiles in Cisco UCS blades and install VMware on the Cisco UCS blade environments.• Worked with the network admins to create the FCOE or converged infrastructure in the environment.• Troubleshoot any issues with the deployment of the multiple servers with BLOCK based VMDK and NFS storage environment for VMware.• Configured multiple virtual Machines (Linux and windows) and hand over the VM's to the application teams.• Configured Amazon EC2 machines in amazon web services• Configured VPC and created multiple ip's for the team to loginto the public cloud• Managed the public cloud environment and installed modules using puppet• Configured modules in the AWS and private linux stacks using puppet• Configure manifests and deploy them using puppet• Created bash and shell scripts to automate some of the services required in the environment• Created AWS s3 buckets and glacier vaults for backup and archive purposes• Handling production servers and network infrastructure that includes Windows Administration of Domain Controllers, IIS Web Servers (HTTP/S, FTP and SMTP), Exchange 2003 Mail Servers, NAS, File and print Servers, RADIUS clients and Terminal Servers on Windows 2012.• Responsible production support of Active directory (AD), GPO, Domain users, Users and groupsand given appropriate permissions, shares and privilege to access LAN and Domain environment.• Familiar with web based .Net application, xml integration in IIS web server, IIS Clustering, Load Balancing, Logging and Reporting.• Installed and Implemented VMware vSphere 4.x on the host servers with vSphere Client, vSphere CLI Configured HBAs for in-house infrastructure environment.• Configured the virtual environment backup and restore policies of VMware  and physical server environment• Installed and implemented NFS server using windows UNIX service and configured with VMware Host servers for storage.• Configured and  managed the EMC products such as• Data Domain for backups intend of Tapes• DMX: Allocated storage to the VMware private cloud environment• Vplex: Used for VMware replication from one site to another to make it active/in-active• Vmax: configured and migrated the data from the old DMX to the new VMAX• Installed and implemented open source Open Filer 2.3 iSCSI SAN with RAID 10 for VMware and other servers with iSCSI initiators. Also managing iStor SAN and Symantec Backup Exec 12.• Connected Thin Client (WYSE, DevonIT), desktop Windows Xp2 clients to RDS 6.1.• Installed and implemented to Manage Engine monitoring application and configured SNMP and WMI on Servers and other network devices for reporting and alerts notifications.• Responsible for helpdesk support using Spice works ticketing system, inventory and system reporting.• Participated in the migration planning, developing, testing and moving the migration process onto full-fledged production network.Environment: Windows 2003/2008, Exchange Server 2003 , Windows XP/Vista/Win 7, Vmware ESX 4.1 Server, Open filer iSCSI SAN/NAS, iStore SAN, Dell PowerEdge Servers, Dell Power Vault NAS, Zywall and SonicWall Firewall Remote desktop services.Middleware Infrastructure AdminAmerican Express - Phoenix, AZNovember 2012 to July 2013Responsibilities:• Configuration of WebLogic Domain, Cluster and Managed servers.• Experience in problem tracing, log file management and implementing the Workload Management using clustering for Weblogic/JBoss Servers• Handling all the major enterprise releases, deployments, configuration/architecture changes and fine-tuning of BEA WebLogic environment• Creating and configuring JDBC and multi pool connection pools for automatic database failover.• Work with Performance analysts in fine-tuning the applications.• Used Admin tool for adding and managing new users, groups, software and printers, resolving permissions issues, user and group quota.• Performance tuning the JVM to suit the specific application needs.• View the menu items that the users can access through Oracle Identity Manager Administration Web interface.• Assign users to roles ,and Assign a role to a parent role•  Installed and configured new hard drives and memory upgrades.• Used Admin tool for adding and managing new users, groups, software and printers, resolving permissions issues, user and group quota.• Perform daily maintenance routines on Linux servers, monitoring system access, managing file space and tuning the system for optimum performance.• Setting up FTP, NFS and Samba servers for file sharing.• Involved in Creating Shell Scripts like Automation of Startup and Shutdown Processes.• Created disk groups, volumes, volume groups and RAIDs using Veritas Volume Manager.• Created new slices, mounted new file systems and un-mounted file systems.• Designate status to the users so that they can specify defined responses for process tasks.• Designate role administrators to perform actions on roles, such as enabling members of another role to assign users to the current role, revoke members from current role and so on. Developed documentation to describe support infrastructure and related procedures.Environment: IBM WebSphere App Server v8.0/7.0. WebSphere MQ, IBM HTTP Server 8.x/7.0, DB2 9.x, RHEL 5.3, TAM 6.x, TDS 6.0Software Engineer InternHyve Solutions - Fremont, CASeptember 2010 to October 2012Responsibilities:• Designed Online Security solutions using Graph Theory.• Designed and developed components using Python.• Designed unit test framework for new code.• Implemented database access and data manipulation functions using MySQL.• Designed the architecture of the hardware environments and methodology of the code.• Experienced in Agile Methodologies and SCRUM Process.• Involved in entire lifecycle of the projects including Design, Development, and Deployment, Testing and Implementation and support.• Used Pandas library for statistical Analysis.• Used Numpy for Numerical analysis for Insurance premium.• Experienced with Python programming and Python libraries for data science included in the Anaconda distribution including NumPy, Pandas, NetworkX, Matplotlib, SciPy, Scikit-learn and Natural Language Toolkit (NLTK)Environment: Python, MySQL, Ubuntu, Windows.,""TECHINCAL SKILLS:Operating Systems	Ubuntu, Windows 2008, 2012, AIX, Solaris and RHEL, VMWare ESXi 5.1Amazon Web Services	EC2, S3, RDS, IAM, Ops Works, Cloud Formation, VPC, cloud front, Docker, Lambda, Microsoft Azure, Glacier, storage gatewayIntegration tools	CloudWatch, Beanstalk, Nagios, Bamboo, Puppet, ANT/Maven, Gradle, Jenkins, Ansible, GITProgramming languages   Python, C++, C, php, xml, JavaScript.Storage	VNX 7500, 5700,5300 and 7600 , 5800,  VNXe, Vplex  ClARiiON, CX600/CX700/ CX3-40/CX3-80/CX4-480 /CX4-960SAN Switches	Cisco, McData and BrocadeSAN SoftwareEMC-Solutions Enabler, EMC-Centera, SYMCLI.Unisphere for VMAX with Performance Analyzer, Unisphere for VNX Unified Administration, Unisphere Manager, NAVISECCLI, PowerpathBackup and Recovery	EMC NetWorker 7.6, Veritas NetBackup 6.5/6.0/5.1, IBM TSM 5.2/4.2NAS Platform	EMC Celerra, Windows CIFS server, NetAppDatabase	SQL, MySQL, RDSScripting Language	UNIX ShellWeb Server	Tomcat, HTTP Server, Web LogicNetworking	TCP/IP, NIS, NIS+, NFS, DNS, DHCP, WAN, SMTP, SNMP, LAN, SSH, FTP/TFTPFile Systems	UFS, swapfs, Tmpfs, zfs, jfs, jfs2, ext2, ext3, fat, ntfs""";;;
"Cloud Engineer MyAppsHub LLC - Redmond, WADecember 2015 to Present Destination Security collecting the security best practices to use when we are designing, deploying, and managing your cloud solutions by using Azure. Developer has the security questions and controls them to consider at each phase of the software development lifecycle when developing applications for the cloud and it provides provide the sample app, documents and videos to perform the above actions on multiple phases ·      Designed, architected and implemented, analyzed, Azure cloud security, cloud infrastructure services and correlated events from security solutions/technology such as firewalls, IPS/IDS, security event management, anti-virus software, web and reverse proxies, data encryption, data loss prevention and other industry-standard solutions·      Azure cloud security and cloud infrastructure services and workload transition challenges·      Develop and implement Azure Cloud Infrastructure, Azure Data Streaming Analytics, Azure Data Lake store and Analytics and Platform Automation in Microsoft PowerShell, ARM SDK and API and .NET.·      Develops techniques and procedures for conducting IS and cyber security risk assessments and compliance audits, the evaluation and testing of hardware, firmware and software for possible impact on system security, and the investigation and resolution of security incidents·      Cyber Security & IAM including managing Privileged Access Management requirements ·      Help with finalization of current Centrify Identity Platform for single sign-on deployment surrounding Multifactor Authentication and Mobile Device Management within the enterprise·      Managed day-to-day security operations processes and technical solutions to support business needs.·      Managed operational support for CCE IT security solutions/technologies. AV, PKI/certificate management, Directory services, patch management, vulnerability scanning, network security, etc.·      Identifies areas for operational improvements of existing security solutions·      Developed and enforced corporate information security policies and procedures; ·      Appropriately maintained and demonstrated compliance with Azure security including FISMA, HIPAA, HITECH, PCI-DSS and EU Data Privacy Directive, etc.·      Performed end-to-end information system, application, web application and network security assessments; ·      Developed and implemented internal and external security assessment procedures and processes;·      Translated assessment results into business requirements and communicated business impact and risk to executive leadership; ·      Served as an internal auditor for security and risk related issues; ·      Add project users to the Azure account with multifactor authentication enabled and least privilege permissions.·      Branching, Tagging, Release Activities on Version Control Tools: TFS, GitHub.·      Carried Deployments and builds on various environments using continuous integration tool Jenkins.Environment: Azure Core Security, Threat Modeling, OWASP, VS2017, C#, Web API Web Service, ASP.Net and Azure SQL, Angular JS, VS Unit test, Bootstrap, jQueryTechnical LeadINFOSYS LTD - Seattle, WADecember 2015 to June 2018Project: CRM and Azure SQL PerformanceCRM Reliability: This track responsible for removing bottleneck on PrepareSync Pipeline in Azure Infrastructure for CRM and Azure SQL product• R&d, design, architect and develop a cloud platform solution (.NET, C#, Microsoft Azure, Entity Framework, Linq, WebApi)• Analyze of existing on-premises management software's family to build a brand new load test with the goal to create a cloud first scalable platform based on Microsoft .NET / C# / Azure /Angular JS• Implemented Layers/Components: Azure/.Net C#: WebApi 2 Rest, Linq, Sql Azure, Azure AD, Elastic Database Pool• Create and Deployed VMs using Azure Cloud Services• Configure Azure cloud service for end point deployment• Enable Open ID and Windows Live authentication in Azure cloud apps• Deploy Scale Group and POD services on Azure cloud• Evaluating performance and provide the reports of end to end execution• Developed automation tool using Powershell to perform the online server operations• Recreate module with different approach.• Bug fixing in different module.• Understanding the existing feature and maintain it.• Sync up with offshore team and assign task to them.Environment: Azure, Dynamics CRM, VS2013, C#, Web API Web Service, ASP.Net, IIS7.0 and SQL Server 2014 R2, Angular JS, VS Unit test, Bootstrap, JQuerySenior developerTRINGAPPS - Dover, DEApril 2015 to December 2015Project: DEEDSDEEDS (Delaware Educator Data System) are a licensure/certification application which has BackOffice (windows desktop) and website (ASP.NET 4.0) application. This application maintains the License and Certification of the educators. The Desktop version is used for scanning the transcripts / correspondence and issuing certificates / license to the educators. The web version is open to general public to create their profile and submit documents and apply for certificates / license.• Senior Developer tasked with implementing a new development project for creating, tracking and searching for certificates / license at DOE.• Implemented a multi-layer, multi-tier solution utilizing SQL Server 2012, Entity Framework 6, ASP.NET MVC 5 with Web API, Bootstrap, TwitterBootstrapMVC and an object-oriented JavaScript solution using Backbone.js, and node.js, Grunt for compiling modules and requires• Implemented ASP.NET MVC 5 pattern mechanism to display License and certificates.• Developed the services using WCF to access catalog and basket related functionalities.• Implemented AngularJS framework for binding the data to do concurrency update from different sources.• Implemented JQuery Mobile Touch Optimized Framework for web pages.• Written SQL queries, Triggers and done the analytical test with Crystal reports.• Used TFS for as the Version Control tool for the source code.• Used the Entity Framework 6.0.• Trained development team on the latest web technologies used in this project.Environment: VS2013, C#, MVC 5, Web API Web Service, ASP.Net, Entity framework 6.0, IIS7.0 and SQL Server 2008 R2, VS Unit test, Bootstrap, AngularJS, JQueryComputer SpecialistTRINGAPPS - Dover, DEFebruary 2015 to December 2015Senior developerTRINGAPPS - New York, NYFebruary 2015 to April 2015Project: Video Conferencing PortalVideo Conferencing Portal is a proprietary framework designed and implemented for the in-house project. The Solution and framework is designed in platform agnostic fashion to manage, schedule, monetize, analyze, report and monitor Video Conferencing and Document Exchange activities between Enterprises and Individuals. The Portal is designed to serve as an engine for both B2B and B2C applications.• REST WEB API to be consumed with multiple clients.• Implemented ASP.NET MVC pattern mechanism to display product catalogs and categories.• Implemented AngularJS framework for concurrency data transmittance.• Developed the services using WCF to access catalog and basket related functionalities.• Implemented JQuery Mobile Touch Optimized Framework for web pages.• Written SQL queries, Triggers and done the analytical test with Teradata reports.• Used TFS for as the Version Control tool for the source code.• Used the Entity Framework 6.0.Environment: VS2013, C#, Web API Web Service, ASP.Net, Entity framework 6.0, IIS7.0 and SQL Server 2008, VS Unit test, AngularJS, JqueryNET ConsultantWIPRO TECHNOLOGIES - Richfield, MNMay 2014 to February 2015Project title: One System of Records (OSR)Description:Best Buy's Appliances One System of Records (OSR) includes merging business models between Pacific Sales (PAC) and Best Buy (BBY)  which will allow expanded assortment, deposits, relationship selling, inventory sharing and seamless 3rd party delivery and installation.  Phase 1 of this initiative is to launch one market on OSR for Appliances pre-holiday FY15 with focus to maintain Pacific Sale's Labor Model and Expanded Assortment• Developed SSRS Report for Application using Visual Studio 2012.• Written SQL queries, Triggers and done the analytical test with Teradata reports.• Prepared release builds using Source Control tools such as Clear-Case.• Leading team and ensuring that team is meeting customer & management expectation.• Established an SLA against bugs, provided periodic statistical reports to the management teams.• Managed risks and issues impacting the project deliverables.• Ensured that the project documents are complete.Environment: Visual Studio 2012, SQL Server 2012, Oracle 11g, PL/SQL, JIRA, NUnit, Web API, Xamarin, Win form, SSRS, SSIS and SSASDot Net DeveloperWIPRO TECHNOLOGIES - New York, NYDecember 2013 to February 2015NET ConsultantWIPRO TECHNOLOGIES - SingaporeDecember 2013 to May 2014Domain: Banking and FinancialsProject title: MyAccess (Access Provisioning System)Description:MyAccess is an Access Provisional System for the users (bank employees). It is a web portal used for creating and maintaining the IT requests within the organization. Access Provisional System facilitates the users to obtain access of applications and assets by generating requests in the automatic and rule-based system.• Refactored, re-architected, and enhanced an existing AngularJS application to follow strict MVVM/MVC patterns for improved source code maintenance, 40% code reduction, ease of upgrade, scalability, ease of developer spin up, enhanced performance and offline with client caching.• Added the necessary responsive design for display and full functionality on tablet and mobile.• Consuming and Developing Windows Communication Foundation services (WCF).• Creating WCF applications requiring Instance and concurrency management.• SQL Development, ability to write and troubleshoot SQL Code and design (stored procedures, functions, tables, views, indexes, constraints).• Leading team and ensuring that team is meeting customer & management expectation.• Established an SLA against bugs, provided periodic statistical reports to the management teams.• Involved on RCA in order to resolve the production issues.• System consumes ESB services and depreciated MAG services.• Managed risks and issues impacting the project deliverables.• Ensured that the project documents are complete.Environment: Visual Studio 2010, ASP.NET 4.0, C#, Web Services, Winforms, WCF, SQL Server 2008 R2, HTML, MVC5, Jquery, CSS, AngularJS, JSON, JIRA, NUnit, Web API, SQL profiler, Oracle 11g, PL/SQLNET ConsultantDATAMATICS VISTA INFO SYSTEMSMarch 2013 to November 2013Projects:Lead the requirement gathering from internal business team to designDATAMATICS VISTA INFO SYSTEMS - Chennai, Tamil NaduMarch 2013 to November 2013Chennai, India		Mar 2013 - Nov 2013PFI Development - This assignment is to deal with multiple PFI application development in .NET framework and make it compatible for new migrated database. The application development is for internal clients and is in C#.Net with Visual Studio 2010.Responsibilities:• Lead the requirement gathering from internal business team to design, develop applications in C#.NET• Ensure the application enable accurate extraction of reports from business data.• Define and enhance the architecture of application, its integration with pre-existing databases and creating intermediate business layer.• Developed Winform for Application using Visual Studio 2010.• Manage the deployment to UAT.• Post deployment support for the development activity.Environment: .Net Framework 4.0, C#.NET, Visual Studio 2010, COM, Winforms, Power Shell, ADO.NET, MVC, XML etc.Senior Software EngineerACCENTUREJuly 2011 to October 2012Projects:CIO, GlobalGPs and OGs in GUsMay 2011 to October 2012Supply Demand Management System - Forecasting/planning at appropriate level of detail to make good sourcing decisions. Influences RP demand plans and fulfillment plans by providing ""guideposts"" Interlock discussions between business entities (GPs and OGs in GUs) to agree on demand forecasts and sourcing actions. Resource Pool (GPs, DCs and CSGs in GUs) S/D Specialists responsible for defining near term demand plans and fulfillment plans to meet resource needs in agreed timeframes and at appropriate productivity levels..Responsibilities:• Worked as Application support team lead and involved in debugging and trouble ticket analysis.• Worked as configuration Manager.• Application development utilizing procedural, object-oriented (OOP) and functional methodologies, design patterns, forms (Winforms/WPF), Excel add-ins (XLAM/VSTO), Word add-ins (XLAM/VSTO)• Built a variety of innovative Excel-based add-ins e.g., automated migration of OLAP-based pivot tables to new SSAS schemas, and automation/scheduling of pivot table updates, using C#/VSTO with ribbon and panel UI• Helping team to solve the raised issues.• Handling the raised issues and support to business.• Preparing weekly subscriptions template and uploading into the report manager• Monitoring the ETL, Index jobs to update the SDM database• Doing automated tool to monitoring the subscribed reports and update the status periodically to Business• Involved as trainer in Greenfield training to train the Entry level capabilityEnvironment: .Net Framework 3.5, C#, SSRS, SSIS, SSAS, SQL Database, VSTO (Excel), VSTO (Word), Crystal Reports 10.0, MVC, HTML, MVC5, JQuery, CSS, AngularJS, JSON, JIRA, NUnit, TFS and WPFSoftware EngineerCOGNIZANT TECHNOLOGY SOLUTIONS - Phoenix, AZMay 2010 to May 2011Projects: Cruise Next GenCruise Next Gen - Cruise nex gen is a project that is used to re-underwrite the credit limit of a customer. It is used to increase or decrease the credit limit of a customer based on some criteria such as previous payment history of a customer, income status etc. The PEGA system is raised request. This request is then sent to web services, request is sent to parallel aggregator where request is processed in Request Processor. The Request Processor processing the request, the processed request is sent to Moody's Qry Services and then sent to eMFA database to retrieve customer and account information. Once retrieving customer and A/c information from the eMFA database then again sent to Moody's Qry services and then to Response Processor and then again to PEGA system. The Risk Calc is also a web service application where the calculation required on account information are calculated and then sent to PEGA system. The parallel feed services, from the PEGA system, request is sent to GDAS and then from GDAS, that request is sent to parallel feed services. In EMI, all the request is converted into an XML format and then sent to PEGA system.• Transformed client's requirements into technical scope document, architectural design document, application used cases and low level design document.• Built best practices using Microsoft technologies in multiple projects to implement application development and deployment environment.• Designed and implemented application architecture of the project, database designing, integrating third-party components, workflows and APIs. Ex. - integrating authentication mechanism of social network sites like Facebook, Google plus and LinkedIn in the project.• Actively involved for front-end development for responsive application design using HTML5 templates, framework like twitter bootstraper, Zurb foundation etc.• Performed peer reviews of the codes, involved in integrating those codes into repository systems, functional testing of the application in both Mobile and Web.• Utilized MS Project 2010 for planning, monitoring and defining the milestones of the project.• Simultaneously managed multiple projects using agile methodology by leading a team of 8-10 developers, QA, Designers, etc.• Proactively identified forthcoming challenges and risks in the daily stand-up meetings and prepared mitigation plan for them.• Conducted weekly meetings with the client, updated various stakeholders on the current progress and incorporated their feedback in a timely manner.Environment: .Net Framework 3.5, ASP.NET, C#, WCF, SQL Database, Oracle 11g, PL/SQL, MVP, SVNDeveloperCOGNIZANT TECHNOLOGY SOLUTIONSDecember 2006 to May 2011DeveloperCOGNIZANT TECHNOLOGY SOLUTIONS - CrawleyOctober 2008 to April 2010Apollo - Apollo is a workflow and document imaging system. It severe as an entry point for policy submission and claim registration. The Skeletal policies and short names that are created in Apollo application are fed back to the backend system like (Meridian/Genius/SIS). Any amendments to the policies are made in the back end system (Meridian/Genius/SIS) and sent back to Apollo. There are no financial processes or amendments which are made in Apollo. It just acts as a repository for all the policy and claim documents and reports. Whenever a policy document is required it is pulled from Apollo.• Built best practices using Microsoft technologies in multiple projects to implement application development and deployment environment.• Proactively identified forthcoming challenges and risks in the daily stand-up meetings and prepared mitigation plan for them.• Developed stored procedures in SQL Server 2000 using T-SQL.• Prepared and executed unit test cases.• Co-ordinated with Clients and Onsite team for the requirements.• Entered data will be transforming to Mainframe application.Environment: VB 6.0,.Net Framework 3.5, ASP.NET, C#, WCF, DB2, SQL Database, Visual Studio 2008 , VSSDeveloperCOGNIZANT TECHNOLOGY SOLUTIONS - Phoenix, AZDecember 2006 to April 2008Domain: Banking and FinancialsExpress Suite:This Project include two applications1. Express Change2. TFS Back officeExpress Change:American Express Travel Services Offices are located all over USA. There are about 60 retail offices around the country. Every such office is called a cost center. These offices interact with a variety of customers every day for different foreign exchange transactions, which includes different products. Foreign Exchange Services Express Change is the common software used by all the branches countrywide. All these cost centers mainly deal with exchange of different products like currency, traveler's cheques, card products etc.TFS Back Office:TFS back office provides various supporting functions for Express Change offices. This is the integrity work to be done in maintaining different cost centers by ensuring each center gets ready for the next working day business. Back office support includes Rate transmission, Consolidation process, generating reports, scheduling jobs etc. It also includes consolidation of all the data from each cost center to a single database for reporting purpose.• Involved in maintenance and enhancements of the application for Express Change and TFS Back Office.• Coded stored procedures in SQL Server 2000 using T-SQL.• Interacting with Client and Onsite-Team about new requirements analysis.• Developed applications that produce reports in Excel in the spcified format and send them to the concerned business people through an automated e-mail.• Execution of Consolidation.• Monitoring Rates Transmission scheduled Jobs and Tasks.• Played the lead role for the three member team.• Involved in quality audits and used quality related tools called etracker and prolite.Environment: VB 6.0, VB.NET, SQL Database, PERL, JAVA, Batch ProgrammingProgrammer AnalystBLACKSTONE GROUP TECHNOLOGIESJuly 2004 to December 2006Software EngineerBLACKSTONE GROUP TECHNOLOGIES - Chennai, Tamil NaduJuly 2004 to December 2006Projects: EimcoEimco is a Manufacturing company, which produces Industrial Equipment like Filters, Reactor Clarifier, Spiral Classifier and Aerators Etc. for the various industries both local and international market. An Integrated Information System that maintains and controls all the activities of the company right from enquiries, sale orders to design, inventory, production to delivery and financial accounting to after sales services etc.• Developed Visual Basic Forms according to the design documents.• Written stored procedures using T-SQL in Microsoft SQL Server 2000 database.• Interacting with Project Managers and Directors for requirements.• Participated in the review meetings.• Designed Reports using Data Reports.• Involved in bug fixing, maintenance and enhancements.Environment: .Net Framework 1.1, ASP.NET, Vb.net, SQL Database, Visual Studio 2000, VSS,""• Specialties: Microsoft Azure, Azure Internals, Azure Stack, Azure SQL, Azure Cosmos Python, PowerShell, Dynamics CRM and Apps, Knowledge Management, Reporting Services, Private Cloud/Hybrid Cloud Setup and Usage Scenarios, Virtualization• Basics: AWS key terminology understanding. Migrations methodologies from On Prem to Azure, AWS to Azure and Other platforms.• Strong Hands-on Experience in using Microsoft Technologies like ASP.NET, C#.NET, VB.NET, SQL Server, WCF, MVC, Message Queue, Entity Framework, Web API, COM, Crystal Reports, Oracle 10g, 11g, DTS, SSIS, SSAS,SSRS, SQL Performance tuning, VB 6.0, VBA, HTML,XML,MVC, Linq, COM+ and Web Services etc.• Skilled in Software estimation using Work Breakdown Structure, Function points, Story points etc. and also developing Request for Proposal, Proof of Concepts.• Git, Mercurial, JIRA, agile methods, NUnit, MS Test, and MSbuild: Led the initial effort to move from ad-hoc tooling and processes to a more predictable and scalable set of code-support packages.• Proven track record to work & manage geographically distributed teams/ large team / multiple teams of more than 10-12 members.""";;;
"Sr. DevOps/Cloud Engineer SQS and SNS services in AWS cloud - Baltimore, MDMarch 2017 to PresentRoles & Responsibilities:• Managing Cloud Services using AWS Cloud Formation, which helped developers and businesses an easy way to create a collection of, related AWS resources and provision them in an orderly and predictable fashion.• Launching Amazon EC2 Cloud Instances using Amazon Images (Linux/ Ubuntu) and Configuring launched instances with respect to specific applications.• Maintained the user accounts (IAM), RDS, Route 53, VPC, RDB, Dynamo DB, SES, SQS and SNS services in AWS cloud.• Wrote AWS Lambda functions in python for AWS's Lambda which invokes python scripts to perform various transformations and analytics on large data sets in EMR clusters.• Experienced in using AWS Elastic Beanstalk as Platform as a service (PaaS) to manage the AWS cloud environment.• Collaborated in the automation of AWS infrastructure via Terraform and Jenkins - software and services configuration via chef cookbooks.• Responsible for day to day Build and deployments in Dev, QA, pre-production and production environments. Implemented AWS high-availability using AWS Elastic Load Balancing (ELB), which performed balance across instances in multiple availability zones.• Responsible for building scalable distributed data solutions using Hadoop Eco System.• Implemented a centralized logging system using log stash configured as an ELK stack (Elastic search, Log stash, and Kibana to monitor system logs, AWS Cloud Watch, VPC Flow logs, Cloud Trail Events, changes in S3 etc.• Maintained DNS records using Route53 to Improve Fault Tolerant Connections and using Load balancer, Security groups and NACLS.• Created snapshots and Amazon machine images (AMI) of the instances for backup and creating clone instance.• Built and configured a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud (VPC), Public and Private Subnets, Security Groups, Route Tables, Elastic Load Balancer.• Configured AWS cloud infrastructure as code using Terraform and continuous deployment through Jenkins.• Built and managed a large deployment of Red Hat Linux instances systems with Ansible, Terraform Automation and provision virtual servers using vagrant and kitchen in Oracle VM virtual box, provisioned servers in Amazon EC2.• Installed & maintained XEN & VMware servers with multiple VM's running a multi VLAN Physical & VM environment.• Developed an Azure based high performance compute environment to support the massive computational requirements of client congressional redistricting Azure application.• Built a presentation to present the design of hosting architecture on Windows Azure.• Solutions Consultant responsible to be primary SME on Azure services including SaaS, PaaS and IaaS while contributing architecture decisions and tasks for ongoing migration efforts.• Focused on containerization and immutable infrastructure. Docker has been core to this experience, along with Mesos, Marathon and Kubernetes.• Provide highly durable and available data by using S3 data store, versioning, lifecycle policies, and create AMIs for mission critical production servers for backup.• Extensive experience monitoring the servers using Nagios, ELK, Cacti and New Relic.• Configured Docker containers for Branching purpose and deployed using Elastic Beanstalk.• Experience in Setting up Chef Workstation, Bootstrapped instances using Chef and integrating with Auto Scaling.• Experienced with Ansible playbooks for virtual and physical instance provisioning, configuration management, patching and software deployment.• Implemented Ansible to manage all existing servers and automated build/configuration of new servers.• Implemented Continuous Integration using Jenkins and GIT from scratch.• Implementing multi-tier application provisioning in Open Stack cloud, integrating it with Jenkins and SonarQube.• Developed build scripts using ANT/MAVEN and Gradle as the build tools for the creation of build artifacts like war or ear files.• Dealt with errors in pom.xml file to obtain appropriate builds using maven build tool.• Used sub modules in the GIT and educated users working with sub modules in GIT.• Developed and scheduled bash shell scripts for various activities (deployed environment verification, running database scripts, file manipulations, Subversion (SVN) etc.)• Worked with different bug tools like JIRA, IBM Clear Quest.• Hands on experience with IAM to set up user roles with corresponding user and group policies using JSON.• Designed Methodologies to troubleshoot based on the issues and documented all the procedures to educate team members.• Implemented, integrated and managed Perforce as well as instituting accurate and automated build and release methodologies for Binary compilation for Apache HTTP/HTTPS, Tomcat, PHP and MySQL.• Experience with threat modeling, especially for web application and web APIs.• Working knowledge of using WebSphere App servers, Tomcat in building and deploying applications.• Build high performance web services, using languages such as python.• Experienced in build and deployment of Java applications on to different environments such as QA, UAT and Production.Environment/Tools: EC2, Elastic Load Balancing, Elastic Bean Stalk, ECS, CloudFront, CloudFormation, Elastic Cache, CloudWatch, Route 53, Redshift, Lambda and Dynamo DB, LAMP, Nagios, Terraform, Kubernetes, Docker, Tomcat, WebSphere, Nexus, Chef, Ansible, Jenkins, Maven, Bash scripts, SVN, and GITSr. DevOps EngineerHCSC - Richardson, TXJanuary 2016 to February 2017Roles & Responsibilities:• Created the end to end CI/CD pipeline from scratch for application and API's for automating the deployment process.• Implemented continuous integration using Jenkins and configured various plugins. Also used GIT as a Source Code Manager, Maven as a Build Tool, SonarQube and Art factory.• Deployed the code, various Web Application and API's onto the Cloud Foundry (PREDIX)• Created and managed shell scripts for the automation of build and deployment process.• Used sub modules in GIT and trained the new users on working with sub modules in GIT.• Configured and installed monitoring tool Checkmarx an • d Logstash on the servers.• Educated Development teams on GIT, Jenkins, AWS, PREDIX Cloud Foundry and whole CI/CD Pipeline process.• Developed organizational units in Active Directory and managed user security with group policies.• Managed user accounts on Linux platform by creating Active Directory user groups and giving permissions to the individual users and for the group users to the dev and production servers.• Worked on cloud based servers such as AWS and Cloud Foundry.• Responsible for Sprint planning sessions and Daily Stand-up meetings.• Wrote Rally User Stories and broke those stories into smaller pieces to complete the stories within the allocated sprints.• Worked in both Agile and Kanban environments.• Documented all the process of CI/CD Pipeline to make sure that all the steps are completed successfully and for feature reference of Dev teams.• Worked as a cyber-security leader in daily sprint standups, providing ownership for all aspects of the security life cycle in the product release.• Provided cyber security technical thought leadership, injecting secure coding standards and best practices into daily scrums.• Mentoring and skill set knowledge transfers to Scrum team members.• Review and modify Agile user stories and epics to ensure correct authentication, authorization, and logging.• Worked on Physical to Cloud Migration in AWS.• Partner with other IT and business teams to develop secure technical solutions.• Supported MVPs through hands-on technical security knowledge, integration, and development/coding.• Deploy and monitor scalable infrastructure on Amazon web services (AWS) & configuration management using puppet.• Worked with a team of architects and developers, operational leads, and functional owners to plan and implement security technical features.• Understood how new technologies impact the current environment.• Adopted of new technologies and drive the implementation into the environment.• Worked in a fast-paced, dynamic environment with shifting priorities comfortable with change and actively driving improvements.Environment/Tools: Jenkins, SonarQube, Art factory, GIT, AWS, Predix, Cloud Foundry, Akana, Mashery, Rally, Maven, Checkmarx, PostgreSQL, Tomcat, Shell Scripting.DevOps EngineerSealed Air - Charlotte, NCJanuary 2015 to December 2015Roles & Responsibilities:• Contributed to new physical and virtual data center infrastructure design and implementation.• Worked on installation, configuration and maintenance Debian, Redhat Enterprise Linux, CentOS and SUSE Servers at multiple Data Centers.• Configured RedHat Kickstart for installing multiple production servers.• Installation, Configuration and administration of VMware.• Deploy and monitor scalable infrastructure on Amazon web services (AWS) & configuration management using puppet.• Educated Development teams on GIT, Jenkins, AWS, PREDIX Cloud Foundry and whole CI/CD Pipeline process.• Designed Puppet Modules to manage configurations and automate installation process.• Experience working with production servers at multiple data centers.• Worked on Physical to Cloud Migration in AWS.• Experience in migration of consumer data from one production server to another production server over the network with the help of Bash and Perl scripting.• Installed and configured monitoring tools Nagios for monitoring the network bandwidth and the hard drives status.• Designed Puppet Modules to manage configurations and automate installation process.• Set up Kickstart for new bare metal environment.• Set up Puppet customized monitoring with Nagios, &PNP4Nagios Graphs for both legacy and new environments.• Developed automation scripting in Python (core) using Puppet to deploy and manage Java applications across Linux servers.• Worked on Version control setups like GIT and integration tools Jenkins• Set up Factor and VMware Perl SDK for custom Web-UI-based reports for VMs.• Set up PostgreSQL database servers for Web Server environment.• Set up LDAP authorization & NFS mounted /home directories for users.• Bootstrapping automation scripting for bare metal and virtual servers.• Used VMware VRealize automation to deliver services to their lines of business.Environment/Tools: RHEL 6/7, CENTOS 6/7, Ubuntu, SuSE SLES, Solaris x86, VMware ESX 5, VMware Perl SDK, Dell Blade Servers, Dell R910 servers, Dell M620 servers, M420 servers, Puppet, Python, Perl, PHP, Ruby, Open LDAP, Lighttpd, Apache Httpd, Apache Tomcat, Nagios, JIRA, Fisheye, Confluence Administration, AWS, VMware VRealize automation.DevOps EngineerData Centers - San Diego, CAOctober 2013 to December 2014Roles & Responsibilities:• Contributed to new physical and virtual data center infrastructure design and implementation.• Worked on installation, configuration and maintenance Debian, Redhat Enterprise Linux, CentOS and SUSE Servers at multiple Data Centers.• Configured RedHat Kickstart for installing multiple production servers.• Installation, Configuration and administration of VMware.• Deploy and monitor scalable infrastructure on Amazon web services (AWS) & configuration management using puppet.• Designed Puppet Modules to manage configurations and automate installation process.• Experience working with production servers at multiple data centers.• Worked on Physical to Cloud Migration in AWS.• Experience in migration of consumer data from one production server to another production server over the network with the help of Bash and Perl scripting.• Installed and configured monitoring tools Nagios for monitoring the network bandwidth and the hard drives status.• Designed Puppet Modules to manage configurations and automate installation process.• Set up Kickstart for new bare metal environment.• Set up Puppet customized monitoring with Nagios, &PNP4Nagios Graphs for both legacy and new environments.• Developed automation scripting in Python (core) using Puppet to deploy and manage Java applications across Linux servers.• Worked on Version control setups like GIT and integration tools Jenkins• Set up Factor and VMware Perl SDK for custom Web-UI-based reports for VMs.• Set up PostgreSQL database servers for Web Server environment.• Set up LDAP authorization & NFS mounted /home directories for users.• Bootstrapping automation scripting for bare metal and virtual servers.• Used VMware VRealize automation to deliver services to their lines of business.Environment/Tools: RHEL 6/7, CENTOS 6/7, Ubuntu, SuSE SLES, Solaris x86, VMware ESX 5, VMware Perl SDK, Dell Blade Servers, Dell R910 servers, Dell M620 servers, M420 servers, Puppet, Python, Perl, PHP, Ruby, Open LDAP, Lighttpd, Apache Httpd, Apache Tomcat, Nagios, JIRA, Fisheye, Confluence Administration, AWS, VMware VRealize automationSystem Admin/Build Release EngineerUnited Health Group - Samba, Jammu and KashmirJuly 2010 to September 2013Roles & Responsibilities:* Managed Linux based network spread over all branches.* Maintaining integrated network of Linux& Windows 2000 servers with clients of Windows 9x, Windows 2000, Windows XP & Linux clients.* Servers Setup and Managed: DNS, NIS, DHCP, Squid, Samba, VPN (CIPE), FTP, NFS, Firewall (security), Postgresql DB, LAMP Stack.* Performing administrative tasks using shell scripts and command line tool like sed and awk.* Managed PostGreSQL Database. Regular Backups/Restore processes are done whenever needed* User management tasks creating Users, Groups, Assigning general permissions and special permissions (Quota, ACL etc.)* Budgeting, capacity planning and sizing of Infrastructure.* Worked on Linux, LAMP&tomcat Administration for building and managing high traffic sites over physical and cloud environment (Apache Web Farm, CPanel, Load Balancer, Reverse proxy, PHP, MySQL Replication/Cluster, and Memcached), Managed Version control using Subversion.* Amazon Cloud Computing - Amazon Web Services (AWS, EC2, S3, Auto scaling, Elastic Load Balancing, Cloud Watch, Cloud Front, RDS, EBS, Route 53 etc..)* Nagios for 24X7 automated monitoring.* Configured payment gateway on Linux, php-bridge and java.* HA Proxy, Keep alived, NginX, CPanel, PHPMyAdmin, Webmin, Sarg, AWStats, DenyHosts, HIDS, Acunetix Vulnerability Scanner, Snort, MySQL Slap.* FTP, Proxy (Allow/Deny internet access to users on time, IP and sites basis, bandwidth management), VMware Desktop Virtualization.* Installing and configuring different types of applications like VtigerCRM, mantis bug tracker, eventum bug tracker, Drupal etc.* Shell scripts for adding/deleting/modifying server users, creating backup files for user's data and servers required files.Environment/Tools: Jenkins, Maven, GIT, MS build, UAT, E2E, SCM, Java, puppet, MySQL, Linux (Ubuntu), Git, Bash.Cloud EngineerDevOps - Samba, Jammu and KashmirAugust 2008 to July 2010Roles & Responsibilities:* Installing, tuning, troubleshooting and patching of Red Hat Enterprise Linux servers.* Monitoring server performance and troubleshooting server related problems to SNMP.* Scheduled various regular, periodic, future and queue tasks by using Crontabs.* Setting up of NFS environment. Taking care of user accounts/groups using NFS Management.* Submission of reports such as Routine performs analysis, Capacity analysis, and Security audit analysis to customer for necessary planned changes.* Resolving TCP/IP network access problems for the clients. Develop, Maintain, update various scripts for services (start, stop, restart, recycle) UNIX based shell.* Hands-on experience installing and configuring SSH (Secure Shell) encryption to access on Ubuntu and Red Hat Linux securely.* Installation, configuration, support and security implementation on SSH, NFS, SAMBA, DHCP, DNS, HTTPD services.* Administration of NFS, DNS, NTP, Automounts, send mail and Print servers as per the client requirement.* Expertise in virtualization using VMware ESX server 3.5, 4.0 VMware workstation, virtual box and XEN, RED HAT enterprise virtualization suite.* Upgrading Linux kernel with latest releases on RHEL servers.* Worked on Linux Kick-start OS integration, DDNS, DHCP, SMTP, Samba, NFS, FTP, SFTP, SSH, LDAP integration.Environment/Tools: RHEL, Linux, UNIX, IDS, DNS, AIX, SAN, YUM, User and Group management, Jumpstart, Shell scripting, GSX/VMware, Tomcat.,""TECHNICAL SKILLSAmazon Web Services: EC2, ELB, S3, VPC, RDS, IAM, CloudFormation, CloudFront, CloudWatch, Cloud Trial, SNS, SQS, SWF, EBS, Lambda, EMR, Dynamo DB, Redshift, AMI Elastic Beanstalk, Route53, Aurora.SCM Tools: Subversion, Bit Bucket, GIT, Clear Case, Perforce.Build tools: Ant, Maven, and Gradle.Cloud Platforms: AWS, Azure, Open Stack, GCP.Continuous Integration: Jenkins, Hudson, Bamboo, Team City, Octopus.Configuration Management Tools: Chef, Ansible, Puppet, SaltStack.Tracking Tools:Jira, Remedy, Clear Quest, Bugzilla, Zabbix, and Rally, Fisheye.Containers: Docker, Kubernetes, Docker Swarm, Mesos.Virtualization: Oracle Virtual Box, VMware, Vagrant.Scripting languages: Shell scripting, Python, Ruby, Perl, Bash.Programming Languages: C, C++, Java, JSON, and XML.Databases: Oracle, MS SQL Server, MySQL, And NoSQL, PostgreSQLWeb/Application Servers: WebLogic, WebSphere, JBoss, Apache Tomcat, TFS, IIS, And Nginx.Operating System: Linux (Red hat, Centos, Ubuntu, SUSE), UNIX (HP-UX, Solaris, IBM AIX) and Windows.Methodologies: Agile, Scrum, Kanban, ITIL and Waterfall.Monitoring Tools: Splunk, Nagios, and ELK.""";;;
"Cloud Engineer World Wide Express - Dallas, TXDecember 2018 to Present·       Handled operations and maintenance support for AWS cloud resources which includes launching, maintaining and troubleshooting various aws services like EC2 instances, S3 buckets, Virtual Private Clouds (VPC), Elastic Load Balancers (ELB) and Relational Database Services (RDS).·       Deployed Nexus server through the terraform script automating the deployment of HA infra for nexus with appropriate IAM roles. Creating an auto scaling group which is deploying instances across AZ and which will be accessible through ALB one will be internet facing while the other one will be internal ALB, . Nexus server will be accessible thru route 53 DNS configured which will reach out to the ALB that is attached on top of the server provisioned by the auto scaling group.·       Worked with Security groups, NACL’s, subnets, VPCs.·       Responsible for source code management in Bitbucket. Used Bitbucket Server for secure, fast, enterprise-grade controls, like fine-grained permissions, pipeline and powerful management features.·       Deployed Amazon workspaces through the Ansible playbooks in the form of YAML scripting. All the access is given to the workspaces so that no need of VPN or any other access to connect from anywhere. ·        Automated the cloud deployments using terraform and AWS CloudFormation templates from scratch as an effort of migration.·       Worked in an agile environment for continuous integration/continuous delivery pipeline by integrating Jenkins, Bitbucket and terraform.·       worked with identity providers integrating it with AWS SFTP using AWS API Gateway method with a RESTful interface for authorization, which will be invoked by Lambda to provide serverless authentication and file transfer·       Worked with The RESTful interfaces and must contain a single method that authenticates and authorizes the users for access to Amazon S3. ·       Worked with the PagerDuty, CloudWatch event rules, SNS, SQS, and CloudWatch alarm in process to monitoring health states of ec2 and sftp servers.·       Worked with the Postman to create users for SFTP to in AWS Cognito.Platform: Ubuntu, RHEL, WindowsTools:  Nexus, Terraform, AWS transfer for SFTP, CloudWatch, PagerDuty, Postman, Bitbucket, JIRA, Jenkins, LastPass, Ansible, Amazon Workspaces, other services of AWS.Cloud: AWSLanguages/Scripting: python, Bash, Go, YMLSr. Cloud /Devops EngineerCarnival Cruise line Entertainment - Miami, FLApril 2017 to PresentResponsibilities:• Worked on Azure Cloud Services, PaaS, Azure Data Factory, Azure SQL Data Warehouse, Power BI, Azure Blob Storage, Web API, VM creation, ARM Templates, Python scripts, IaaS, Lift & Shift, storage, network and database.• Azure cloud Infrastructure design and implementation utilizing ARM templates Created users and groups using IAM and assigned individual policies to each group. Creating Azure Backup vault and protecting required VMs to take the VM level backups.• Migration of an on premise SQL DB to Azure SQL using BACPAC. Using Azure SQL Server Migration Assistant (SSMA) to analyze on premise DB and verify compatibility for migration.• Migrating existing v1 (Classic) Azure infrastructure into v2 (ARM), scripting and templating the whole end to end process as much as possible so that it is customizable for each area being migrated.• Worked on escalated tasks related to interconnectivity issues and complex cloud-based identity management in Azure and user authentication, service interruptions with Virtual Machines (their host nodes) and associated virtual storage (Blobs, Tables, Queues) in Azure.• Strong Experience on Administration and Troubleshooting of Azure IAAS Components (VM, Storage, VNET, OMS, NSG, Site to Site VPN, RBAC, Load Balancers, Availability Sets).• Having good understanding of Docker Configuration Management tool, Installed Docker Registry for local upload and download of Docker images and even from Docker hub. Extensively used Docker for virtualization, Ship, Run and Deploy the application securely for fasten the Build/Release Engineering.• Involved in developing micro services integrated with VSTS for CI/CD by automating the build/release process using Git as source control.• Used Pods, Master and Minion in Kubernetes. Master serves RESTful Kubernetes API that validates and configures Pod, Service, and Replication Controller in Kubernetes.• Extensively used on containerization and immutable infrastructure. Docker has been core to this experience, along with Mesos, Marathon, and Kubernetes.• Created and troubleshoot Ansible scripts and Kubernetes YAML files to deploy SCM/CI/CD applications automatically and Idempotent to reduce time costs.• Implemented Continuous Deployment and environment provisioning using Ansible by installing packages on remote agentless nodes through Ansible Playbooks with Ansible Roles.• Used Ansible and Ansible Tower as Configuration management tool, to automate repetitive tasks, quickly deploys critical applications, and proactively manages changes in the Azure environment.• Configured various WebSphere and Tomcat, JBOSS resources JDBC providers, JDBC data sources, connection pools, URL, JMS, Queue Connection Factories, Queues, listener ports, Activation specification, which uses the Message Driven Beans to trigger the Queues.• Designing, supporting and maintaining Splunk cluster infrastructure in a highly available, geo-redundant configuration.• Involved in creating Dynatrace and Splunk dashboards for business defined KPI's and performance dashboards for applications performance monitoring using application insights and Dynatrace SAAS.• Worked with Agile practices using CI/CD pipelines, with Jenkins (Continuous Integration), Nexus for Maven Repository, Maven Builds, Artifactory, Junit testing, Ansible module tests and deployments using multiple Jenkins plugins in Azure Environment.• Configured Continuous Integration by setting up Build and test automation Jobs in Jenkins by pointing to Orchestration and UI layer Repositories in GitHub.• Integrated Git, Jenkins and Maven in accomplishing continuous integration and configured Jenkins with Poll SCM build trigger.• Automated continuous delivery based on business need, end to end installation, configuration, deployment of EAR applications on JBoss AS servers hosted in Open stack servers using Jenkins integration using Maven, bash, Ansible.• Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of Opens tack Nodes and Test Playbooks on Azure instances using Python.• Deployed built artifacts to WebSphere application server using Python. Writing Python script to start/stop web logic servers/cluster and deployment of code and used Python for automation.• Vigorously worked on Ansible playbooks, inventories, created custom playbooks written in YAML language, encrypted the data using Ansible Vault and maintained role-based access control by using Ansible Tower. Created Ansible supported YAML Scripts to restart JBoss, Tomcat and Jetty servers through GUI.• Experience in using JIRA as Issue Tracking Tool or the Review Management Tool and configured JIRA on hosted and local instances for issue tracking, workflow collaboration, and tool-chain automation and created analytical matrices reports, dash boards for release services based on JIRA tickets.• Converted existing Terraform modules that had version conflicts to utilize cloud formation during Terraform deployments to enable more control or missing capabilities.• Worked on Terraform to automate the deployment process onto Azure and created development, test, and production environments for the necessary software development project, and worked with Terraform scripts for instance provisioning and configuration management.Environment: Azure, Ubuntu, Linux, Splunk, Ansible, Maven, Git, JIRA, Python, Docker, Terraform, Jenkins, SaaS, Zabbix, WebSphere, Kubernetes, JBOSS.Sr. Cloud /Devops EngineerLowe's - Morrisville, NCFebruary 2016 to March 2017Responsibilities:• Designing and deploying a multitude of applications utilizing almost all the AWS stack (Including EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS, IAM) focusing on high-availability, fault tolerance, and auto scaling in AWS Cloud formation.• Designed AWS Cloud Formation templates to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates.• Used the AWS-CLI to suspend an AWS Lambda function to make processing Amazon Kinesis stream, then to resume it again to the process.• Monitored and manage d the cloud infrastructure within AWS and Google cloud infrastructure. Configured the AWS DNS to route the traffic between AWS and GCP configured each tenANT on the platform.• Implemented Security groups for inbound/outbound access, network ACLs for controlling traffic through subnets, Internet Gateways, NAT instances and Route Tables to direct the network traffic and to ensure secure zones for organizations in AWS public cloud.• Collaborate in the automation of AWS infrastructure via Terraform and Jenkins - software and services configuration via puppet manifest. Develop CI/CD system with Jenkins on Google's Kubernetes container environment, utilizing Kubernetes and Docker for the runtime environment for the CI/CD system to build and test and deploy.• Designing distributed private cloud system solution using Kubernetes (Docker) on CoreOS. Automated various infrastructure activities like Continuous Deployment, Application Server setup, Stack monitoring using Ansible playbooks and has Integrated Ansible with Jenkins.• Worked closely with developers, analysts, to build up CI/CD pipeline throughout Jenkins, JFROG Artifacts Repository, Docker Image, AWS Image Registry, AWS Elastic Container Service, AWS Micro services, Docker Swarm, Kubernetes.• Experienced in using Docker for virtualization, containerizing, and deploying the applications securely to fasten the Build and Release Engineering, performed automation tasks using Docker Hub, Docker Engine, Docker Machine, Docker Compose and Docker Registry.• Worked on Jenkins as a full cycle continuous delivery tool involving package creation, distribution and deployment onto Tomcat application servers via Shell scripts embedded into Jenkins jobs.• Developed automation scripting in Shell using Chef to deploy and manage Java applications across Linux servers and used Chef to configure and mange infrastructure. Wrote cookbooks to automate the configuration setups.•  Implemented Chef Recipes for Deployment on build on internal Data Centre Servers. Also re-used and modified same Chef Recipes to create a Deployment directly into AWS EC2 instances.• Used ANT and Shell scripts to automate the Build and deployment process to deploying the web services. Used services deploy command for building the web services. Used ANT for few modules.• Proficient in building deployable Artifacts (War, Jar, Ear, Zip, and Tar) from source code and maintained by using ANT (Build.xml) and Gradle (Build.gradle). And worked with Groovy Scripts to Automate Configuration in Jenkins.• PowerShell scripts to calculate array volume percentage utilization to avoid the manual calculation when the array shows that the volume size has to be increased.• Kernel tuning, writing Shell scripts for system maintenance and file management and written Perl scripting to take backup Oracle database.• Worked on Branching, Tagging and Release Activities on Version Control Tools (GIT) and Setting up the GIT repos for Bamboo build job.• Design, build and manage the ELK (ElasticSearch Logstash Kibana) cluster for centralized logging and search functionalities for the App.• Implemented a centralized logging system using log stash configured as an ELK stack to monitor system logs, VPC Flow logs, Cloud Trail Events, changes in S3 etc.• Expertise in integrating Terraform with Ansible, Packer to create and Version the AWS Infrastructure, designing, automating, implementing and sustainment of Amazon machine images (AMI) across the AWS Cloud environment.• Used Terraform to create, change and improve production infrastructure and maintained versioning infrastructure safely and efficiently by custom in-house solutions.• Worked efficiently on managing the RAID, File system through LVM and creating and managing Logical Volume Manager in Red hat Linux.• Used JIRA as ticket tracking and work flow tool and involved in setting up JIRA as defect tracking system and configured various workflows, customizations and plugins for the JIRA bug/issue tracker.Environment: AWS, Ubuntu Linux, ANT, Jenkins, Chef, Docker, Kubernetes, Zabbix, WebLogic, WebSphere, JBOSS, JIRA Apache and Nginx, ELK, Shell.DevOps EngineerBoardwalk Pipeline - Owensboro, KYJanuary 2014 to December 2015Responsibilities:• Involved in designing and deploying a large application utilizing almost all the AWS stack (Including EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS, IAM) focusing on high availability, fault tolerance, and auto-scaling in AWS Cloud Formation.• Designed AWS Cloud Formation templates to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates.• Experience in Debugging APIs using Nagios logs and made performance analysis through AppDynamics for Resource Monitoring/Network Monitoring/Log Trace Monitoring.• Written multiple cookbooks in Chef. Implemented environments, roles, and data bags in Chef for better environment management.• Experience with AWS instances spanning across Dev, Test and Pre-Production and Cloud Automation through Open Source Devops tools like Ansible, Jenkins & Docker.• Writing JSON templates for Cloud formation and ruby scripts for Chef Automation and contributing to our repository on GITHUB (sub version control).• Written Chef Cookbooks for various DB configurations to modularize and optimize end product configuration, converting production support scripts to Chef Recipes and AWS server provisioning using Chef Recipes.• Set up Jenkins server and build jobs to provide continuous automated builds based on polling the Git source control system during the day and periodic scheduled builds overnight to support development needs using Jenkins, Git, Junit and Maven.• Creating a fully Automated Build and Deployment Platform and coordinating code build promotions and orchestrated deployments using Jenkins/Hudson and GitHub.• Managed build and deployment scripts using Ruby in CHEF, triggered the jobs using Jenkins to move from one environment to across all the environments.• Defined dependencies and plugins in Maven pom.xml for various activities and integrated Maven with GIT to manage and deploy project related tags.• Implemented the use of Nagios tool for monitoring and analyzing the network loads on the individual machines by enforcing custom Nagios to exhibit various metrics using Shell scripting and add-ons.• Used Jenkins/RTC and GIT dependency management system to deploy snapshot by using the Shell scripting commands and release artifacts to Nexus to share artifacts across projects and environments.• By using red hat volume manager created the file systems and performing the health check on regular basis for all Linux servers.• Responsible for OS patching, security patching, firmware upgrade and all upgrades on Red Hat Linux servers using Satellite server and Troubleshooting Day-to-Day issues on various servers with different platforms.• Managed in setting up JIRA as defect tracking system and configured various workflows, customizations and plugins and used JIRA in deployment of Routers, Switches, Hubs, Firewalls, load balancers, VPN Concentrators.Environment: AWS, Chef, Docker, Maven, Subversion, GIT, Shell, Ruby, Nexus, WebLogic, Sonar, Jenkins, Rest, BASH, Rest Solaris, JIRA, UNIX, Nagios.Build and Release EngineerCSS Corp - Chennai, Tamil NaduAugust 2012 to December 2013Responsibilities:• Expertise in using built tool ANT for the building of deployable artifacts such as jar & war from source code.• Used Nexus for periodic archiving and storage of the source code for disaster recovery, sharing artifacts and handling dependency management within the company.• Installed Jenkins/Plugins for GIT Repository, Setup SCM Polling for Immediate Build with ANT and ANT Repository (Nexus Artifactory) and Deployed the EARs and WARs in TOMCAT Application server using ANT script as a CI/CD Process.•  Integration of Automated Build with Deployment Pipeline. Installed puppet Server and clients to pick up the build from Jenkins repository and deploy in target environments (Integration, QA, and Production).• Worked with Build & Release team to enhance the current process to implement a better software packaging and delivery by automation using Jenkins & puppet.• Established Puppet Best practices approaches to systems deployment with other tools and managing Puppet as a unit of software deployment and independently version controlled.• Implemented a Continuous Deployment pipeline with Jenkins, BitBucket, ANT, Jfrog Artifactory, and application servers like Apache, Nginx.• Build scripts using ANT build tools in Jenkins to move from one environment to other environments also used ANT as a dependency management tool to manage all the dependencies that are required.• Managed Git repository, code merging & production deployments. Assisted developers with, applying appropriate branching, establishing labeling conventions using Subversion, Git source control.• Install/configure/maintain the Suse Linux /Solaris servers, NIS, DNS, NFS, Mailing List, and Send mail, apache, FTP, SSHD.• Involved in setting up JIRA as defect tracking system and configured various workflows, customizations and plugins for the JIRA bug/issue tracker.Environment: Red hat Linux 5 /6, GIT, SVN, CI/CD, JIRA, ANT, Puppet Crontab, Nagios, Dynatrace, Tomcat Application Server, apache web servers, WebSphere.Linux AdministratorNEO Technologies - Chennai, Tamil NaduJune 2011 to July 2012Responsibilities:• Worked on changing the application run time process using Shell and Python scripts for WebLogicconfiguration and Shell scripts for database configuration.• Developed Cron jobs and Shell Scripts (Shell, Python) for automating administration tasks like file system management, process management, backup and restore.• Worked on installation, upgradation, configuration and maintenance of Red Hat Linux, Unix, Ubuntu, CentOS, Fedora, SUSE, Windows 2008 Servers and also Involved in creating new users, groups and setup their home directories and appropriate access restrictions to software, directories, and files.• Involved in deployment and maintenance of Red hat Linux, Windows Server 2008 and ESX/ESXi servers and app software in across the network mostly Dell, HP and IBM hardware.• Involved in configuration and administration of DNS, NIS, NIS+, DHCP, FTP, samba Servers. Security layers like SSL, SSH, HTTPS, SFTP.• Experience on Kernel Patching with different distributions and checking Kernel parameters for better performance & tuning.• Experience with Active Directory, GPO's, DHCP, DNS, IP, Sub Nets, VPNs, VLAN, Network routing, firewalls, LAN/WAN switching and Backup & Recovery, File & Print Server, IIS (Web Server), FTP, Terminal Server.• Involved in troubleshooting Production Server Problems related to web applications, send mail, disk space, filesystem, DNS and network connectivity and Worked on creating and managing the Virtual Memory and swap space on Linux Servers.Environment: VSphere 4.0, ESX 5.0/4.1, Virtual Sphere, VMotion, VMware DRS Clusters, Solaris 8,9,10, Red hat Linux 5,6, VCS, 3.0, Python, Solaris Volume Manager, Oracle 9i/10g. Sun Ultra Enterprise Servers (E450, E420R, E250)Linux System AdministratorALLSEC Technologies - Chennai, Tamil NaduJune 2010 to May 2011Responsibilities:• Installed, configured, troubleshoot, secured and supported Red Hat 5/6, Cent 3/4/5 and SUSE Linux9/10 servers and product servers.• Experience in installing, configuring and troubleshooting Apache 2.2.x web server on Redhat Linux and Sun Java System Web Server 6.x, 7.• Used extensively JQuery & JavaScript for client-side validations and access data within the HTML controls.• Experience as Red Hat Enterprise Linux Systems Administrator and performed support role for applications on mission critical Enterprise Networks and Multi-server environment.• Creating and maintaining users, profiles, security, rights, disk space, LVMs and process monitoring, worked with Red Hat Package Manager (RPM) and YUM, Job Scheduling using Cron.•  Experience in providing day-to-day user administration like adding/deleting users in local and global groups on Red Hat Linux platform and managing user's queries.• Experience installing and configuring SSH (secure Shell) encryption to access on Ubuntu and Red hat Linux securely and also Create, administer, and maintain user Accounts with stipulated Permissions, group login IDs, security passwords, etc. on Linux server platforms.• Develop tools/scripts to automate integration with other IT tools in support of accurate asset management, cyber reporting capabilities and to manage licenses.• Configured Kickstart Server in Linux 5.x, 6.x and JumpStart Server in Solaris 9, 10 and build severs using Kickstart and JumpStart server.Environment: Red Hat Linux, CentOS, Fedora, SUSE, Windows 2003, Apache, DNS, SSH, Telnet, NTP, ESX/ESXi servers.,""Technical SkillsOperating Systems	Red Hat Enterprise Linux 5/6/7, CentOS, OEL, SUSE Linux 11/12, HP-UX, Solaris, AIX, Windows Server 2008/2012 R2Build/Automation Tools	ANT, Maven, AnthillPro, uDeploy, Bamboo, Jenkins CI/CD, Docker, Kubernetes, Build forgeDatabases	MySQL, MongoDB, SQL Server, Cassandra, Couch dBScripting/Programming Languages	BASH, PERL, Shell, Python, RubyWeb/App Server Tools	Apache HTTP, Nginx, JBoss, Oracle WebLogic Server, WebSphere, TomcatMonitoring Tool	Zabbix, Splunk, Nagios, Dynatrace, Blue stripeTicketing Tools /Project Tracking   Service NOW, JIRA, CONFLUENCE, HPSMVersion Control Tools	GIT, SVN, BitBucket, GitLab, IBM Rational Clear caseVirtualization Tools	VMware ESXi, vCenter.  Server, Docker, Pivotal, Vagrant, Cloud FoundryConfiguration Management Tools	Ansible, Chef, Puppet, Salt-StackCloud Platforms	AWS, Microsoft Azure, OpenStackBug Tracking tools	JIRA, Service Now, BMC Remedy""";;;
"DevOps/Cloud Engineer MAYO CLINIC - Rochester, MNJanuary 2018 to Present* Proficient with Multi AZ Components in AWS like VPC, Subnet, Internet Gateway, Route Tables, Security Groups, NACL, AMI, EC2, IAM, RDS with Replication, S3 for Object and Static Webpages, Auto Scaling of Micro Services hosted on ECS, ELB and ALB to load balance and health check.* Installed application on AWS EC2 instances and configured the storage on S3 buckets, creating policies and the IAM role based polices and Created monitors, alarms for EC2 hosts using Cloud Watch and enabled notification service through SNS.* Designed AWS Cloud Formation templates(CFT) to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates and Migrated applications to the AWS cloud. Deployed applications on AWS by using Elastic Beanstalk.* Knowledge in managing multiple corporate applications into GitHub code management repositories and creating user level of access for related GitHubproject directories to the code changes.* Developed Cloud Formation Templates (CFT) in JSON and YAML format using Cloud formation designer console to setup various AWS resources such as EC2, VPC, S3, IAM and RDS.* Implemented a Continuous Delivery pipeline withDocker, Jenkins and GitHub and AWS, along with docker container creation process for each GitHub branch gets started on Jenkins as Continuous Integration (CI) server.* Configured AWSservices such as Auto-Scaling to build flexible and high-scalable systems that can handle heavy loads. Implemented Dynamic scale of EC2 instances to automatically increase number of EC2 instances during a demand spike.* Developed Terraform scripts which integrates numerous services on AWS like EC2 instances for different computational needs, RDS to configure SQL databases, DynamoDB to configure NoSQL databases like MongoDB, Cassandra, and SNS for Notifications of critical issues.* Wrote multiple programs in Python to monitor virtual machine usage data using VMWare API calls and Created script in Python for calling REST APIs.* Wrote a program to use REST API calls to interface with backup server, and parse output reports of an Excel file in Python to monitor customer backup usages.* Utilized AWS Beanstalk for conveying and scaling Web Applications and administrations created with PHP, Node.js, Python, Ruby and Docker on Application servers like Apache, WebSphere, WebLogic, JBoss.* Created Python scripts to totally automate AWS services which includes Web servers, ELB, Cloud Front distribution, Database, EC2 and Database Security Groups, S3 Bucket and application configuration, created scripts of single servers, or joins web servers to stacks.* Implemented the automated Nagios in Ops environment for alerts and Email notifications using Python script and executed them through Chef.* Managed Openshift container platform, that provides a self-service for users, also automated the software delivery process to achieve continuous integration, delivery and deployment.* Experienced in working with components of AWS with Terraform, creating and managing the AWScomponents EC2, Security groups, VPC, ELB.Chef is used as the provisioning tool along with Terraform.* Hands-on with Terraform key features such as Execution plans, Resource Graphs, Change Automation,IaaS and used Auto scaling configuration templates for launching amazon EC2 instances while deploying Microservices.* Utilized Python and bash with BOTO3 to supplement automation provided by Ansibleand Terraform for EBS volumes backing AMI's and scheduling Lambda functions for routine AWS tasks.Written Terraform scripts to automate multi-region AWS provisioning.* Worked in all areas of Jenkins setting up CI for new branches, build automation, plugin management and securing Jenkins and setting up master/slave configurations.* Used OpsGenie as a dispatcher with Cloudwatch integration.* Monitored performance of the applications and analyzed log information using ELK (Elasticsearch, Logstash, Kibana) Stack. Configured ELK stack in conjunction with AWS and using Logstash to output data to AWS S3.* Experienced in installation, configuration and management of HTTP, NGINX, NTP, NFS, FTP, DHCP, DNS and configured the Firewall rules to enable service communication with different applications.* Built Continuous Integration process to run static code analysis tests, to ensure that the code is well maintained and secured, also minimize security vulnerabilities with holistic and layered approach with secure infrastructure, application architecture, continuous validation and monitoring.* Maintained JIRA team Confluence System Engineering pages that included: Process Flow Management, Team Requirements, Roles and Responsibilities, and COP User Metrics Participated is customer weekly JIRA progress updates.JEPPESEN- Denver, COIndustry:Aviation	AUG 2015 - DEC 2017Cloud Engineer * Experience on design and configure multitude applications using most of the AWS stack (VPC, EC2, Route53, S3 buckets, RDS, Dynamo DB, SNS, SQS, IAM, EBS) focusing on High-Availability, Fault Tolerance and Auto-Scaling.* Configured Security groups for inbound/outbound access, network ACLs for controlling traffic through subnets, Internet Gateways, NAT instances and Route Tables to direct the network traffic and to ensure secure zones for organizations in AWS public cloud.* Collaborated in the automation of AWS infrastructure via Terraform, Ansible, and Jenkinssoftware and services configuration via Chef cookbooks.* Automate of Environment Builds (provision and configuration management) by developing the Chef Recipes and Cookbooks in Ruby by integrating with GitHub, Jenkins and AWS.* Integrating various Version control tools, build tools, nexus and deployment methodologies (scripting) into Jenkins to create an end to end orchestration build cycles.* Provisioned the highly available EC2 instances using Terraform and Cloud Formation templates(CFT), wrote new plugins to support new functionality in Terraform and involved in using terraform migrate legacy and monolithic systems to AWS.*  Utilized Terraform in AWS VPC to automatically setup and modify settings by interfacing with control layer.* Used Chef to manage Web applications, Environments configuration Files, Users and Mount points. Integrated Terraform with Chef, Packer to create and Version the AWS Infrastructure.* Developed CI/CD system with Jenkins on Kubernetes container environment, utilizing Kubernetes and Docker for the runtime environment for the CI/CD system to build and test and deploy.* Used Git for source code version control and integrated with Jenkins for CI/CD pipeline, code quality tracking and user management with build tools Maven and Gradle.* Configured the Kubernetes provider with Terraform which is used to interact with resources supported by Kubernetes to create several services such as Config Map, Namespace, Volume, Auto scaler, etc.* Integrated GitHub, Bitbucket (Git based) with Jenkinsby configuring Web hooks, Installed and Configured Junit plugin to perform unit testing on the source code, Sonarqube to perform code coverage and checking the duplication of a code, build tools like Maven/Gradle/Ant to build the artifacts and upload it on to Binary repository tools like Nexus and Artifactory.* Implemented LAMP stack image in multitier AWS instances in different subnets in Amazon VPC, attached NACL's andSecurity Groupsto maintain high security.* Worked on building and deploying Java code through Jenkins to automate builds and deployments, as well as troubleshooted build issues in Jenkins, performance and generating metrics on master's performance along with jobs usage.* Created Ansibleplaybooks for various automation purposes like file copy, permission changes, configuration changes, path specific folder creation, etc. and written playbook using Ansible modules such as yum, Copy, File, get_url, git, ping, service, template, debug, synchronize.* Integrated Jenkins with Packer to build the AMIs with latest version of the war file and Middleware like Tomcat, WebSphere, WebLogic etc.* Developed Ansible playbooks with various MySQL, MS SQL modules to run SQL Database migration scripts to perform A/B testing with the newly deployed applications in the Staging environment. WebSphere, WebLogic defined in Packer.json file and later triggered the Terraform scripts to create the stack on the AWS cloud environment.* Configured Jenkins to automatically handle deployment and creation of Ansible playbooks in YAML format to spin up and configure application servers like tomcat, WebSphere, WebLogic.* Installed and configured Ansible plugin with Jenkins, developed Ansible custom modules to automate various regular maintenance work on AWS Cloud environment.* Developed Chef cookbooks to Install and configure Tomcat, WebSphere, WebLogic servers on the AWS EC2 instances to create development and test environments. Version controlled the cookbooks using GitHuband tested the cookbooks using Test Kitchen, Chef Solo, Chef Spec.* Worked on Python scripts to automate AWS services which include web servers, EC2, ELB, S3 bucket, Cloud front Distribution, database security groups and application configuration.* Implemented Boto3 python script to integrate the application, library of the Amazon services like Compute (Amazon EC2), Storage (Amazon S3) and Amazon DB. Configured the Boto3 script to have dynamically generated by JSON model to elaborate APIs.* Implemented auto server build management, monitoring and deployment using Puppet, andNagiosandConfigure scheduled downtime for non-prod servers for optimizing AWS pricing.* Implemented Puppet dashboard for quick visual snapshot of important system information and to deliver valuable reports and created a puppet database for storing information about every node, resource, relationship, users and information about entire infrastructure.* Implemented and managed Puppetmaster server and experience in updating and creating modules and delivering them to Puppetclients and managing SSL certificate.* Implemented Splunk Dashboards, searches and reporting to support various internal clients in Security, IT Operations and Application Development. Build performance dashboards through Splunk, Extra hop, writing Java script and customized scripts and worked with internal clients to develop requirements, relationships and value metrics.Build/Release EngineerADP - Pune, MaharashtraApril 2013 to August 2015* Developed AWS Lambda functions to trigger the creation of new instances on AWS, deploy the new war file and to create the AMI. Developed Cloud formation templates which use the new AMI to do the Immutable deployments on to AWS by updating the stack, verifying the change set and trigger the stack creation.* Integrated Jenkins with GIT and Maven to create a pipeline of building and deploying the artifacts by pulling Puppet manifests from the version control GIT using webhookand storing them into Nexus/Artifactory.* Used configuration management tool Puppet to write manifests to maintain consistent configuration across all the servers to avoid configuration drift by installing specific client requested packages.* Deployed and administrated scalable infrastructure on Amazon web services (AWS) using configuration management tool chef for development and test environments.* Good knowledge in Implementation, configuration, maintenance of open LDAP server and application configured with Apache/Tomcat/Nginx, samba & send mail, Web sphere application servers and postfix mail server for user authentication.* Configured and maintained GIT source code tool and created branches, tags and merged in GIT repository and triggered push and pull requests from Jenkins. Automated the weekly deployments using CI tool Jenkins with integrated GIT version control system to automate the code check-out process.* Automated deployment of Web and Application servers like WebSphere, IIS, Apache, WebLogic, JBoss and Tomcat on public and private cloud using CI/CD tools.* Provisioned build environment for various products in Linux, Ubuntu, SUN Solaris, AIX environments and implemented the Release practice and responsible for pushing builds into DEV/ QA / SIT / UAT.* Installed and configured Apache Tomcat and MySQL database for the application team and performed planned weekly and monthly maintenance task on the servers.* Highly experienced with Windows OS administration and clustering support, VMware related planning, and scoping of physical servers that could be converted to virtualized instances such as Exchange 2007/2010 mailbox servers, Windows based Oracle Database servers and Active Directory servers.VMware EngineerMRL Posnet LTD - Hyderabad, TelanganaMay 2011 to March 2013* Deployed and configured VMware ESXi and designed templates to provision VMs and Implemented ESXi hosts utilizing vCenter Server. Created templates for cloning of virtual machines using VMware Virtual Client and migrating servers between ESXi hosts.* Configured the network details using vSphere client and installed required software in RHEL environment. Integrated, configured and deployed new patches, upgrades, bug fixes on both physical and virtual Red Hat Linux servers using YUM server and satellite server.* Performed initial validation of Avoid software products on virtual servers. Focusing on VMware vSphere and Hyper-V hypervisors (primarily VMware). Working with other groups to maintain validation.* Good understanding of VMware Networking concepts like building vSwitches, with several types of port groups and experienced in Patch Management of ESXi Hosts using VMware Update Manager.* Experience in the V2V and P2V migration of Physical servers to VMware ESXi hosts and worked with datacenter support team and vendor to perform physical server hardware upgrade and replacement activity.* Configured the vSphere Virtual Machine File System to give high performance cluster file system for ESXivirtual machines.* Installed and configured hardware RAID card to achieve high availability and fault tolerance in event of disk failure using different RAID methods like Raid 01, RAID 5 and RAID 1.* Created, monitored and managed VMware snapshots and SnapMirror to restore the VMs to a consistent state from the corrupt/failed state.* Configured Logical Volume manager to create, extend and maintain volumes and check the partitions of the disk space.* Provided and maintained user access in VMware virtual Center, configuring mail alert for any failure in HA, DRS, CPU and memory.* Automated the planned patching process for server validations (reboot time, uptime, etc.) after monthly security updates. Troubleshooted data and network issues of over 600 Windows Servers utilizing multiple technologies to include SQL, Exchange, DHCP, DNS, DFS, IIS, FTP, SharePoint, Domain Controllers, and Active Directory.* Provided Remote Support and administration on network for internal and external clients using tools like Microsoft Remote Desktop Connection (RDP).* Configured RAID 1, RAID 01 and RAID 5 to avoid system/application downtime in the event of disk failure.* Good knowledge on performance monitoring tools TOP, NETSTAT, SAR, IOSTAT to keep track of CPU, memory, disk and network devices status.* Expert in using filter tool AWK, SED, GREP, EGREP and FGREP.* Troubleshooting OS/Hardware related issues and monitor server health on a day-to-day basis to maintained maximum uptime and high performance for Enterprise Production, Development, and QA environment servers.,""TECHNICAL SKILLSOperating Systems	RHEL/CentOS 5.x/6.x/7.x, Ubuntu/Debian/Fedora, SUN Solaris 7/8/9/10, IBM AIX, Windows Server 2003/2008/2012Cloud	AWS, AZURE, Google Cloud Engine (GCE)Scripting	Bash, Shell, Ruby, PowerShell, Python, Perl, YAMLBuild/Automation Tools	Ansible, Chef, Puppet, Jenkins, Maven, Ant, GradleDatabases	MySQL, SQL Server, MongoDB, PostgreSQL, CassandraBug Tracking Tools	JIRA, RemedyVersion Control Tools	GIT, GitHub, BitBucket, GitLab, Subversion (SVN), TFSWeb/App Server	Apache, Nginx, IIS, TFS, Tomcat, WebSphere Application ServerWeb Technologies/ Programming Languages   Servlets, JDBC, JSP, XML, HTML, .Net, Java Script, Java/J2EE, C, C++, Perl scripting, Python, Shell scripting, Ruby, YAML""";;;
"Cloud Engineer United Airlines - Houston, TXJanuary 2018 to Present Roles & Responsibilities: •   Dealt with Azure IaaS & PaaS - Virtual Machines, Cloud Services, Resource Groups, and Express Route, VPN, LoadBalancing, and Application gateways, Auto-scaling, Traffic Manager, Azure Web Apps, Web Roles, Worker Roles,Azure SQL and Azure Storage.•   Worked on Designing and maintaining containerized microservices and configuring/maintaining private container registry on Microsoft Azure for Hosting Images and using Windows Active Directory to secure an Azure ActiveDirectory AD domain services managed the domain with LDAP's.•   Configured Azure/Duo Multi-Factor Authentication as a part of the Azure AD Premium to securely authenticate users. Experience in providing high availability for IaaS VMs and PaaS role instances for access from other services in the VNet with Azure Internal Load Balancer.•   Configured Hybrid Cloud setup on GCP using VPN with two different regions and used Google Cloud console to create and manage GCP and GKE workloads.•   Worked on GCP services like compute engine, cloud load balancing, cloud storage, cloud SQL, stack driver monitoring and cloud deployment manager. Established failover and auto-scaling for all critical applications by usingHA Proxy/Nginx for Load Balancing in GCP. Configured monitoring of uptime and performance for all production systems by GCP Stack driver.•   Worked on providing highly available and fault tolerant applications and utilizing orchestration technologies such as Google Kubernetes Engine and Apache Mesos working on Google Cloud Platform (GCP).•   Used Terraform to automate VPCs, ELBs, Security groups, SQS queues, S3 buckets. Managed different infrastructure resources like Cloud, VMWare, Bare Metal Servers and Docker containers.•   Created reusable infrastructure using Terragrunt and built Terragrunt project to manage Terraform configuration fileDRY while working with multiple Terraforms modules.•   Worked with Ansible for Orchestration of Deployments for various servers and managed Ansible Playbooks with Ansible modules, implemented CD automation using Ansible, also involved in managing existing Tomcat Web server and automated the configuration of new servers.•   Worked on Implementing continuous deployment and environment provisioning using Ansible by installing packages on remote agentless nodes through Ansible playbooks with Ansible roles. Used file modules in Ansible playbooks to copy, remove, and modify the files on agentless remote servers from Ansible control server.•   Worked to setup Jenkins as a service inside the Kubernetes cluster to reduce the failover downtime to minutes and to automate the Docker containers deployment without using configuration management tool.•   Worked on Installing and configured Kubernetes for Orchestration of Docker Images and Cluster Container management on Cloud. Kubernetes to manage containerized applications using its nodes, Config Maps selector services and deployed application containers as Pods.•   Worked with Scheduling, deploying, managing container replicas onto a node cluster using Kubernetes and experienced in creating Kubernetes clusters work with frameworks running on the same cluster resources.•   Extensively worked on Jenkins for continuous integration and for End-to-End automation for all build and deployments. Set up Continuous Integration for major releases in Jenkin. Knowledge and experience in creatingJenkins Pipeline.•   Worked on Jenkins, Octopus, Teamcity, and Bamboo by installing configuring and maintaining the purpose of CI and End-to-End automation for all build and deployments implementing CI/CD for database using Jenkins.Configuring Jenkins job to spin up infrastructure using Terraform scripts •   Worked on Ansible Playbooks with Python, SSH as the Wrapper to Manage Configurations of AWS Nodes and TestPlaybooks on AWS instances using Python. Run Ansible Scripts to provision Dev servers.•   Engineered Splunk to build, configure and maintain heterogeneous environments and have in-depth knowledge of log analysis generated by various systems including security products.•   Build and deploy Java code through Jenkins and Code coverage analysis using SonarQube. Run quality checks usingSonarQube& upload it to Nexus repository.•   Writing PowerShell scripts as TFS Build steps to implement multiple business rules. These rules call REST APIs to readGit pull requests, read and update work items, trigger builds, and abort builds if rules are not met. These are consumed by all build definitions and Git repos using submodules.•   Worked on PowerShell to execute commands/scripts, installed remote server administration tools using Powershell, and PowerCLI.Environment: Azure, GCP, Ansible, Terraform, Docker, Kubernetes, Git, Bitbucket, Confluence, Jira SpinnakerJenkins, Maven, Nexus, Python, Shell script, Bash.DevOps EngineerAWSJanuary 2017 to December 2017Roles & Responsibilities: •   Automated provisioning of infrastructure for our environments building AWS CloudFormation stacks from the resources VPC, EC2, S3, RDS, Dynamo DB, IAM, EBS, Route53, SNS, SES, SQS, CloudWatch, Security Group, AutoScaling.•   Used security groups, network ACLs, Internet Gateways, NAT instances and Route tables to ensure a secure zone for organizations in AWS public cloud.•   Worked on Creating EC2 instances in VPC and installed applications. Worked on Identity Access Management and Created users, groups and assigned roles based on their duties.•   Worked on Creating NAT and Proxy instances in AWS and manage route tables, EIP's and NACLs. Configuring of Virtual Private Cloud (VPC) with networking of subnets containing servers.•   Worked on Lambda functions in python for AWS Lambda and invoked python scripts for data transformations and analytics on large data sets in EMR clusters and AWS Kinesis data streams and configuration management tools such as Kafka.•   Worked on integrating AWS DynamoDB using AWS Lambda to store the values the items and backup the DynamoDB streams.•   Configured and deployed several hypervisors and VMs running Openstack for DevOps, testing and production environments.•   Troubleshooting any part of the lifecycle services within the Openstack including log files, message queues, database, computer hardware, and network connectivity.•   Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of Openstack Nodes and TestPlaybooks on AWS instances using Python.•   Automated configuration management and deployments using Ansible playbooks and YAML. Created AnsiblePlaybooks to provision Apache Web servers, Tomcat servers, Nginx, Apache Spark and other applications.•   Worked on Docker to containerize the Application and all its dependencies by writing Docker file, Docker-Compose files, and Docker container snapshots, managing Docker volumes, and deployed Docker Swarm using Ansible.•   Created additional Docker Slave Nodes for Jenkins using custom Docker Images and pulled them to Cloud. Worked on all major components of Docker like Docker Daemon, Hub, Images, Registry and Swarm.•   Implemented and building tools such as Maven in order to automate and enhance the overall operational environment. Developed build and deployment scripts using Maven as build tool in Jenkins to move from one environment to other environments.•   Experienced in authoring pom.xml files, perform releases with Maven release plugin, and manage Artifacts in NEXUSRepository.•   Responsible for Continuous Integration (CI) and Continuous Delivery (CD) process implementation-using Jenkins along with Python and Shell scripts to automate routine jobs.•   Responsible for installing Jenkins master and slave nodes and configure Jenkins builds for continuous integration and delivery. Set up and configure the Jenkins for application deployment.•   Installed and configured GIT and GITHUB. Implemented and maintained the branching and build/release strategies utilizing GIT.•   Automated build and deployment process using Bash, Python, and Shell scripts with focus on DevOps tools, CI/CD in Jenkins.•   Written shell scripts with Bash, Python to automate tasks like provisioning servers, installing, configuring packages and deploying applications on multiple servers in the Prod & Non-prod environments.•   Automated Datadog Dashboards and assisted internal users for Splunk in designing and maintaining production quality dashboards.•   Worked with Nagios for Windows Active Directory & LDAP and Data consolidation for LDAP users. Monitored system performance using Nagios, maintained Nagios servers and added new services & servers.Environment: AWS, Git, Maven, Jenkins, Linux, Jira, chef, Ansible, Docker, Splunk, python, EC2, S3, RDS, EBS, ELB,Opswork, Nexus, Bash, Unix/Linux, Nagios, Datadog..DevOps EngineerDura Automotive Systems - Auburn Hills, MIFebruary 2016 to December 2016Responsibilities: •   Build AWS infrastructure using resources VPC, EC2, S3, RDS, Dynamo DB, IAM, EBS, Route53, SNS, SES, SQS, CloudWatch, Cloud Trail, Security Group, Auto Scaling and RDS using Terraform and Cloud formation templates.•   Implemented ETL process to ingest analytical data stored in S3 into a Redshift data Warehouse cluster using AWSLambda Microservices and Configured & forwarded the data of the ELB Access logs &VPC flow logs to S3 buckets.•   Worked on Terraform for automating VPCs, ELBs, security groups, SQS queues, S3buckets, and continuing to replace the rest of our infrastructure. Using Terraform as a tool, Managed different infrastructure resources Cloud, VMware,Bare Metal Servers, and Docker containers.•   Involved in using Terraform to migrate legacy and monolithic systems to Amazon Web Services and provisioned the highly available EC2 Instances using Terraform and cloud formation and wrote new plugins to support new functionality in Terraform.•   Worked with Ansible for Orchestration of Deployments for various servers and managed Ansible Playbooks with Ansible modules, implemented CD automation using Ansible, also involved in managing existing Tomcat Web server and automated the configuration of new servers.•   Integrated Ansible Tower with Jenkins to quickly deploy critical applications managed changes and provided encryption needed for task files with Ansible Vault.•   Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installed and configured Kubernetes.•   Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes, created pods and managed using Kubernetes.•   Managed Kubernetes environment and deployed docker based applications using Spinnaker and Jenkins. And worked on Spinnaker to integrate AWS infrastructure for creating the continuous deployment pipelines.•   Deployed and configured Atlassian tools like Jira, Confluence and Bitbucket for both hosting and issue tracking for local instances, workflow collaboration, and tool-chain automation. Installed Jenkins on a Linux, created master and slave configuration, and drove all microservices builds out to the Docker registry. Build scripts using Maven in Jenkins to move from one environment to other.•   Creating and Implementing branching and merging strategy with multiple branches and used Git and Bitbucket as source code management repository to keep track of version changes.•   Deployed and configured Elastic search, Logstash and Kibana (ELK) for log analytics, full-text search, application monitoring in integration with AWSLambda and CloudWatch.•   Engineered Splunk to build, configure and maintain heterogeneous environments and have in-depth knowledge of log analysis generated by various systems including security products.•	Configured Jira as defect tracking system and configured various workflows, customizations and plug-ins for the Jira bug/issue tracker.•	Build and deploy Java code through Jenkins and Code coverage analysis using SonarQube. Run quality checks usingSonarQube & upload it to Nexus repository.Environment: AWS (EC2, ECS, VPC, ELB, S3, RDS, Cloud watch, and Route 53), Ansible, Terraform, Docker,Kubernetes, Git, Bitbucket, ELK, Confluence, Jira, Spinnaker, Jenkins, Maven, Nexus, AWS, Shell script, Bash.DevOps EngineerUSAA - Plano, TXAugust 2015 to January 2016Responsibilities: •   Provide support for customer deployments, including automation to create repeatable processes using Jenkins.•   Possessing strong knowledge in Ant and Maven build tools and implementing it with Jenkins with AWS services.•   Worked on architecting and configuring secure VPC through private and public networks in AWS.•   Monitored AWS resources set a notification alarm in case of trouble through CloudWatch.•   Created and managed cloud VMs with AWS EC2 command line clients and AWS management console.•   Written multiple manifests and also customized facts for efficient management of the Saltclients.•	Creating snapshots and Amazon Machine Images (AMIs) of the instances for backup and creating clone instances.•   Worked on AmazonVPC resources such as subnets, network access control lists, and security groups.•   Worked on launching Amazon EC2 Cloud Instances using Amazon Images (Linux/ Ubuntu) and Configuring launched instances with respect to specific applications.•   Worked with AWSservices (EC2, S3, RDS, EBS, VPC, IAM, Cloud formation, Auto scaling).•   Worked on Cloud automation using AWS Cloud Formation templates and Terraform.•   Automate infrastructure creation, deployment and recovery using Ansible/Salt, Docker, and Terraform & Jenkins.•   Design, build and automate the AWS infrastructure (VPC, EC2, Networking, EMR, RDS, S3, etc.) usingTerraform/Cloud Formation.•   Strong Server Build skills and building client/server services like NFS, DNS, DHCP, HTTP/HTTPS, SSH, LAMP, VNC,Sendmail, and Qmail.•   Automating backups by shell for Linux and PowerShell scripts for windows to transfer data in S3 bucket.•   Strong in building Object Oriented applications using Java, python, Terraform, writing ShellScripts on UNIX. Rewrite existing Java application in Python&Terraform module to deliver certain format of data.Build & Release EngineerMachine Images, Maven, Salt, CentOS.IMarch 2013 to July 2015Build & Release EngineerSonata Software Limited -HYD, INDIA	March 2013 - JULY 2015Responsibilities: •   Developed and supported the Software Release Management and procedures. Performed all necessary day- to-day Subversion/CVS support for different projects. Responsible for design and maintenance of theSubversion/CVS Repositories, views, and the access control strategies.•   Used Jenkins innovatively to automate most of the build related tasks. Improved throughput and efficiency of build system by providing EO/managers rights to trigger required build.•   Configured and maintained Jenkins to implement the CI process and integrated the tool with Ant and Maven to schedule the builds. Created the branches in Subversion and Perforce to implement the parallel development process.•   Managed build and deployment using Ant, Bamboo, SCM tools and managed maven project dependencies by creating parent-child relationships between projects.•   Involved in migration of Bamboo server and Artifactory server and Upgrade of Bamboo & ArtifactorySystem AdministratorShellJune 2012 to March 2013scripts.System AdministratorDR.REDDY'S - HYD, INDIA	JUNE 2012-March 2013Responsibilities: •   Wrote intelligent custom health checks using Nagios to reduce notification noise and automate service restarts.•   Integrated Nagios Event Handlers such as logging event information to a database and restarting failed Service with Nagios to proactively fix problems.•   Installation, integration and management of data backup/recovery solutions. Management and configuration of VMware machines running Oracle/Sun Solaris X86/64, Red Hat Enterprise Linux and Oracle Linux server.•   Configured VMware on a clustered environment, implemented migration of virtual machines using VMotion,Virtualized Windows servers using VMware Converter and Platespin Power Convert.•   Administration of UNIX servers like AIX and Sun Solaris in both test and production environment and appliedPatches. Created and modified user, groups with SUDO permission.•   Managing CRON jobs, batch processing and job scheduling. Troubleshooting the network with the help of Netstat, ping, nslookup and traceroute tools.•   Performed monitoring of Linux systems using tools such as top, netstat, vmstat.•   Scripted routine tasks to run in an automated fashion using bash and Perl.•   Troubleshoot Network, memory, CPU, swap and File system issues, TCP/IP, NFS, DNS, and SMTP in Linux and Solaris servers.Environment: UNIX ISO/IEC 9945:2008, WebSphere 7.0, MySQL Server 5.5, VMware Workstation 7.0, Bash, Perl,Nagios.,""Technical Skills:Cloud Platform	AWS, Microsoft Azure, GCP, Open stack.Scripting	Bash/Shell, Perl, Python, Ruby.Configuration Management	Ansible, Chef, PuppetDatabase	Oracle, DB2, MySQL, MongoDB 7 SQL Server, MS SQLBuild Tools	ANT, MAVEN, make file, Hudson, and Code DeployCI/CD	Jenkins, BAMBOOContainer Tools	Docker, Kubernetes, Docker Swarm.Version Control Tools: Subversion (SVN), Clear case, GIT, GIT Hub, Perforce, Code Commit.Web Servers: Apache, Tomcat, Web Sphere, Nix, JBOSS, WebSphere.Languages/Scripts	C, HTML, Shell, Bash, PHP, Python, PHP, Ruby and PerlWeb Technologies	HTML, CSS, Java Script, JQuery, Bootstrap, XML, JSON, XSD, XSL, XPATH.Monitoring tools	Nagios, Splunk ,New Relic, App Dynamics and cloud watchBug Tracking Tools	J IRA, Remedy, HP Quality Center, Bugzilla.""";;;
IT Cloud Services Manager Centura Health - Englewood, COApril 2016 to Present Responsible and accountable for the strategic and tactical server and infrastructure systems environment maintained by a team of Cloud Services Engineers. These systems include Microsoft Infrastructure, Citrix Infrastructure, compute, virtualization, storage, and Epic Client Systems.- Hired and trained supervisors to manage operations of Microsoft Infrastructure and Epic Client systems teams- Managed partnerships and technology roadmaps with major vendors (e.g. Microsoft, Citrix, VMware, etc)- Proposed operation and capital items for budget, managed actual spending and expenses- Defined key performance indicators and tracked performance metrics per team- Composed business proposals and financial analysis for IT operations projectsSystems Operations SupervisorCentura Health - Englewood, COJune 2013 to April 2016Provided supervision, escalation, resource scheduling, and coordination for two Infrastructure Operations engineering teams.- Hired and trained twelve full time and nine contract Infrastructure Operations engineers- Implemented career management plans and training goals for each team member- Redesigned onboarding process to speed up integration of new hires- Maintained roles and responsibilities and after-hour maintenance window schedule- Acted as Manager on Duty for frequent overnight maintenance windowsDirector of OperationsCMIT Solutions of Denver - Denver, COJanuary 2011 to May 2013Provided IT support, infrastructure guidance and budget advice with managed IT services for small to mid-sized businesses in the Denver area:- Account manager, project manager, technical lead, and primary engineer for multiple small business clients- Streamlined workflow to increase efficiency (e.g. tracked effective hourly rates for managed services clients)- Implemented staff management processes to increase productivity (quarterly reviews, career plans, revenue incentives)- Upgraded cloud monitoring and management systems (Continuum and Autotask)- Technical escalation for staff, architecture planning and IT roadmaps for clientsIT ConsultantXantrion - Oakland, CAOctober 2005 to December 2010Primary engineer and account manager of managed IT services for small to mid-sized businesses in the San Francisco Bay Area with national branch offices:- Designed, installed, and configured all elements of a SMB infrastructure for Windows (Active Directory, DNS, DHCP), applications (SQL servers, IIS web servers), messaging (Exchange and spam filtering) networking (switches, routers, firewalls, internet circuits), remote access (terminal servers, Blackberry servers, VPN clients, OWA/Activesync), and virtualization (VMWare vSphere Essentials Plus solutions)- Scoped, quoted, and priced I.T. projects ranging from server and application installs to complete network redesigns- Configured, monitored, tested, and troubleshot Backup Exec and Livevault backups- Designed, implemented, and successfully executed disaster recovery (complete site to site failover for all critical systems)- Insured compliance with financial and medical audit protocols (SAS 70, SAS 94, HIPAA)Regional Network AdministratorImagemax, Inc - Hayward, CAMarch 2005 to October 2005Network systems administrator for four Western offices of a national document scanning company:- Designed, configured, and installed domain services per site (Active Directory, DNS, DHCP, WINS, security and printing).   Managed and upgraded 3Com and Cisco network switches and Netscreen firewalls- Performed site-based and regional HIPAA compliance audits, implemented domain security plan, implementing endpoint protection and patch management processIS Support TechnicianTotality Corporation - San Francisco, CAOctober 2003 to March 2005Network systems administrator for managed service provider serving national e-commerce clients:- Administered and supported Microsoft domain infrastructure: Servers, Active Directory, DNS, DHCP, and WINS- Monthly research, testing, and deployment of OS and application patches via Software Update Services (SUS)- Administered Symantec Antivirus, Postini mail-filtering service, and defense-in-depth security infrastructureSenior Technical Support AnalystAutomatic Data Processing, Brokerage Services Group - Jersey City, NJJune 2001 to August 2003Network engineer for service bureau of financial clearinghouse serving international financial clients:- Integrated client network connections into ADP infrastructure to provide access to hosted applications- Proposed, designed, and implemented internal infrastructure upgrades- Consulted with clients (Bank of America, WestLB) and exchanges (AMEX, NYSE) on network design and integration- Supported 80 core routers, 200 edge routers, supporting infrastructure, and network monitoring- Coordinated and maintained edge device port-filters, firewall rule sets, and associated documentationIS Support TechnicianTotality Corporation - New York, NYMay 2000 to June 2001Network Systems and telecom technician for 200-person remote offices of Bay Area-based managed service provider:- Supported Microsoft operating systems, Microsoft Office applications, web browsers, and system management utilities- Performed hardware support for laptops, desktops, servers, switches, data racks, and telecom systemsSystems AnalystGoldman Sachs, Investment Banking Division, Technology Support Group - New York, NYJuly 1999 to May 2000Systems analyst and first level support of a global network for an international investment bank:- Provided OS Support for Windows NT 4.0 Workstations and Servers, and Exchange 5.5 messaging server- Maintained and supported applications, connectivity, roaming profiles, and domain accounts for a 11,000-user networkNetwork TechnicianOffice of Academic Computing, Cornell Medical Center - New York, NYAugust 1998 to July 1999Network technician for multi-platform academic and medical network:- Maintained and supported network connectivity and network accounts for hospital and medical school,I am an IT professional focused on customer satisfaction and service delivery.  My management skills were honed in high pressure environments.  I possess clear communication abilities and an instinct for organizational analysis.  I emphasize knowledge sharing to improve team performance.;;;
"Cloud Architect/Engineer Lead Hitachi Vantara Federal - Arlington, VAOctober 2018 to PresentDARPA} • Worked as cloud architect/cloud engineer lead on a cloud migration project, migrating 80 Windows and RHEL applications from VMWare to AWS following the DOD Secure Cloud Computing Architecture • Used Terraform to build out architecture and create a layered automated deployment framework for workload applications • Solutioned a high availability transit VPC framework with Palo Alto firewalls to support security and routing to multiple VPCs • Worked with team members to build out monitoring, logging, backup and restore for cloud resources to meet security requirements prior to migrationConsultantCritical Technics LLC - Arlington, VAJanuary 2018 to PresentArlington, VAMy cloud and DevOps consulting LLC. I write winning technical solutions for government contractors. I also develop automated solutions to give companies a head start on their next project while significantly cutting costs.See more at https://www.criticaltechnics.comSenior Software EngineerCapital One - Vienna, VAMay 2018 to October 2018• Worked on a team of DevOps engineers to plan, deploy, and maintain critical business applications in production and non-production AWS environments 2 • Designed and implemented appropriate environments for those applications, and engineered suitable release management procedures and provided production support • Automated the provisioning of environments with Ansible and Docker • Made gradual improvements to application stack using infrastructure-as-code best practices with Ansible and Terraform • Participated in the design, development, testing, and release of new capabilities and features with a focus on release and production support • Configured monitoring dashboards and alerts with Datadog as well as logging queries with Splunk • Performed security scans with Qualys and remediated findings by updating Bash scripts and Ansible templates • Ported elements of application stack from EC2 to Docker Images deployed using the Hashistack including Nomad, Vault, Consul, and Consul-template • Developed and enabled continuous integration/continuous deployment (CI/CD) for system componentsDirector of IT / DevOps Engineer LeadMicroHealth - Vienna, VAJanuary 2017 to May 2018Defense Health Agency} • Oversaw technology operations including network management, security, service desk support, hardware and software management, and enterprise systems • Developed processes and performed training and tabletop exercises to acquire cybersecurity and quality management related certifications (ISO 9001, ISO 27001, CMMI-SVC-3) • Built out enterprise cloud infrastructure following the AWS well-architected framework • Provided cloud engineering support and CI/CD pipeline development for multiple DHA and VA contractsDevOps Engineer LeadPlanned Systems International - Vienna, VAJanuary 2016 to January 2017• Provided system engineering, cloud engineering, and DevOps engineering support for development of a DOD case management application • Performed system design and architectural activities, including updating DODAF views and SDD documentation • Designed and implemented network and cloud infrastructure for DoD to VA application interoperability using RESTful web services, two-way SSL authentication, and VPN tunneling • Designed and built out CI/CD Pipeline for a Java application including but not limited to: automated software quality code checking with Sonarqube, automated application builds with Maven and Jenkins upon code check-in to Subversion, automated deployments with Jenkins and Weblogic, automated vulnerability scans and reports with OpenVAS and Nessus, automated regression testing with Selenium, implemented version control and artifact management with Subversion and Artifactory implemented monitoring and alerts with OSSEC HIDS and Zabbix, and set up alert webhooks inRocketChat and Redmine • Hardened all systems in accordance with RHEL6 STIGs using Ansible for configuration management and validated security compliance • Created 'golden images' to act as secure baseline for application deploymentSystem Administrator / Test Automation EngineerValytics - McLean, VAJune 2015 to January 2016Defense Health Agency} •   Automated test scripts for native and web applications with HP UFT for the DOD MHS GENESIS EHR •   Performed web application penetration testing and created demos with Burpsuite •   Performed unit and regression testing on multiple DHA contracts •   Installed, configured, and maintained laptops, operating systems, applications, and supporting peripherals •   Implemented and upgraded and patches for various operating systems •   Set up VOIP phones •   Assisted with network hardware, servers, and software installation, troubleshooting and support •   Added new users to Active Directory domain and set permissions •   Configured Cisco VPN for remote users •   Set up webmail accounts for new users •   Performed asset management and inventory of existing and new IT assets •   Configured web browsers and operating systems to work with legacy web applications for software testing •   Conducted phone and in-person interviews for new hires and provided recommendationsGraduate Teaching Assistant / Adjunct ProfessorColorado State University - Fort Collins, COSeptember 2010 to May 2014•   Provided academic support for 200 undergraduate students per semester.•   Provided IT support for course instructor for classroom presentation hardware and software.•   Managed course technology and proactively monitored students' academic progress.•   Held regular office hours to meet with academically struggling students to develop goals, provide guidance, and build benchmarks for improvement.•   Planned and administered review sessions and supplemental workshops on academic writing, research, and test-taking strategies.•   Wrote tests and quizzes and graded papers to evaluate the performance of students in the completion of course requirements.•   Designed and delivered undergraduate lectures on state, regional, and international politics.•   Worked with faculty and department heads in assessing search committee candidates for new faculty hires.,""Skills•   Cloud Engineering	•   IT Leadership and Governance•   DevOps Engineering	•   System Engineering•   Cloud ArchitectureToolsAnsible, Apache, AppDynamics, Artifactory, AWS, Azure Active Directory, Bash, BurpSuite, Docker,Drupal, Elasticache, GitHub, GitLab, Grafana, HP UFT/QTP, JBOSS, Jenkins, Jira, Kibana, Linux(RHEL/CentOS/Debian/Ubuntu), Logstash, Mac OSX, Maven, MySQL, Nessus, Nginx, Oracle WebLogic,Office 365, OpenVAS, OpenVPN, OSSEC, Palo Alto, PostgreSQL, Prometheus, Qualys, Redmine,RocketChat, SoapUI, Selenium, SonarQube, Subversion, Terraform, Tomcat, Visio, Visual Studio Code,VMWare, Windows, Wordpress, Zabbix""";;;
"Lead DevOps Cloud Engineer DTCC - Dallas, TXJuly 2017 to Present Responsibilities• Worked on multiple DevOps and Cloud tools that achieve Key Performance Indicators. Coordinating with implementation team, to build and engineer services for Linux and Windows OS on cloud (AWS) platforms. Provisioned Instances, Storages & monitoring Services and CI/CD pipeline through Jenkins.• Managed AWS infrastructure and automation with CLI and API. Deployed multiple resources simultaneously, using Terraform templates in AWS.• Performed various tasks from taking crucial automation implementation decisions to handling the team code library.• Involved in designing and deploying multitude applications utilizing almost all AWS stack (Including EC2, S3, AMI, Route53, RDS, SNS, SQS, IAM) focusing on high-availability, fault tolerance, and Auto-Scaling in Terraform scripting.• Launched and configured of Amazon EC2 Cloud Servers using AMI's.• Developing reusable automation stack for AWS resources like Lambda, EMR, Elastic Beanstalk, Auto scaled ec2, RDS Database (MySQL, Aurora & RDS PostgreSQL).• Built an end to end pipeline for AWS Infrastructure deployment as (IaaS). Which supports multi environment deployments and one touch automation.• Deployed API Gateway for different applications using Swagger (JSON) integrated with other AWS services like Lambda and s3 static website.• Used API Gateway with IAM Authorizer and IP Authorizers to authorize any external or internal client requests.• Developed and deployed different IAM Services like roles, policies and Encryption keys using Terraform, Cloud Formation and AWS CLI.• Using Groovy DSL wrote numerous pipeline scripts for automation of Infrastructure as well as Application development code to build and deploy• By integrating different scripting languages like Python, Bash and DSL made a Jenkins Pipeline to deploy any AWS resource.• Developed Lambda function using Python to automate the process of adding dynamic routes to the subnet route table for AWS resources in private subnet to reach out to Public endpoints.• Configured Git, build scripts using ANT and MAVEN build tools with Jenkins and schedule jobs using POLL SCM option and integrated to automate the code checkout process.• Developed code to create SSM Parameter store, also integrated it with a SNS topic Subscription to notify team about sensitive information changes automatically• Troubleshooting connectivity issues using AWS cloud config.• Implemented best practices for Infra-as-code and Automation deployments.• Built Application development code and stored in Nexus as artifacts.• Worked on supporting application based on Hive, Spark and using Zeppelin Interface.• Used CloudWatch to ship the AWS EC2, Lambda and EC2 logs to be stored.• Worked with Python code to develop code for SAML Assume role to avoid keys for AWS Account access.• Deployed PostgreSQL database framework to create schema, tables, role and privileges in RDS DatabasesUsing Jenkins pipeline and Terraform.• Developed an automated stack to create hosted zones per VPC to create Route 53 record sets for application.• Route53 is implemented to create record sets for DNS Names for Internal Load Balancers, API Gateway and s3 static websites• Different DR Solutions are architected and implemented to have cross regional availability as well as High availability• Worked and supported on various Java, Python and node.js applications• Worked closely with different team like networking and DBA to achieve end-to-end automation of AWS infrastructureEnvironment: AWS EC2, S3, AMI, EMR, Beanstalk, API Gateway, ACM, Route53, RDS, IAM, VPC, Terraform, CloudFormation, ELB, Lambda, Jenkins, Git, ANT, Maven, Nexus, Shell, Python.Lead DevOps Cloud EngineerDTCC - Minnetonka, MNJuly 2017 to July 2018Responsibilities• Built an end to end pipeline for AWS Infrastructure deployment as (IaaS). Which supports multi environment deployments.• Developed reusable automation stack for AWS resources like Lambda, Elastic Beanstalk, auto scaled EC2, RDS Database (Aurora & RDS PostgreSQL).• Built an end to end pipeline for AWS Infrastructure deployment as (IaaS). Which supports multi environment deployments and one touch automation.• Deployed API Gateway for different applications using Swagger integrated with other AWS services like Lambda and s3 static website.• Used API Gateway with IAM Authorizer and IP Authorizers to authorize any external or internal client requests with traffic up to 1 million requests per hour.• Creation, Installation, and administration of Red Hat Virtual machines in VMware Environment.• Involved in Architect, build and maintain Highly Available secure multi-zone AWS cloud infrastructure utilizing Chef and Ansible with AWS Cloud Formation and Jenkins for continuous integration.• Installed Jenkins on a Linux machine and created a master and slave configuration to implement multiple parallel builds through a build farm.• Continuous integration with Jenkins. Continuously evaluate and recommend improvement to CI/CD processes.• Architected & Implemented security to meet PCI requirements, using VPC Public/Private subnets, Security Groups, NACLs, IAM roles, policies, VPN, WAF, Cloud Trail etc. to pass penetration testing against infrastructure• Maintained Chef Configuration management spanning several environments in VMware and the AWS cloud. • Installed and Implemented Ansible configuration management system.• Migrating a production infrastructure into an Amazon Web Services utilizing AWS Cloud formation, Code Deploy, Chef and EBS.• Experienced working with Ansible tower. Integrating Ansible tower with Jenkins to deploy code to different servers• Implemented Terraform modules for deployment of applications across multiple cloud providers.• Working with DevOps practices by AWS, Elastic Beanstalk & Docker with Kubernetes.• Integrated Docker container orchestration framework using Kubernetes by creating pods, config Maps and deployments.• Lunching and Debugging Docker container, Installing/setup Docker host in environment, Integrating Docker and Mesos, to monitor container status.• Experience working on several Docker components like Docker Engine, Docker-Hub, Docker-Compose and Docker Registry.• Designing Ansible Playbooks for zero-downtime installation, upgrade, downgrade, and uninstall processes. (MongoDB, Redis, MySQL and PostgreSQL).• Writing Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS Nodes and Test Playbooks on AWS instances using Python.• Used Ansible playbooks to setup Continuous Delivery pipeline. This primarily consists of a Jenkins to run packages and various supporting software components such as Maven.• Creating inventory in Ansible for automating the continuous deployment and wrote playbooks using YAML scripting.• Used Amazon S3 to backup database instances periodically to save snapshots of data.• Used Cloud Watch logs to move application logs to S3 and create alarms raised by applications.• Used Amazon Route53 to manage DNS zones and give public DNS names to elastic load balancers.• Utilized Ansible and AWS lambda, elastic cache and cloud watch logs to automate the creation of log aggregation pipeline with Elasticsearch, Logstash, Kibana stack (ELK stack) to send all our team's logs coming into cloud watch, to process them and send them off to Elasticsearch.• Using Groovy DSL wrote numerous pipeline scripts for automation of Infrastructure as well as Application development code to build and deploy• By integrating different scripting languages like Python, Bash and DSL made a Jenkins Pipeline to deploy any AWS resource.• Worked on Project-Generator which creates Jenkins file and seed jobs in Jenkins and Rundeck jobs with job definitions. In this webhooks also configured when the commits done in Bitbucket and jobs are triggered in Jenkins.• Developed code to create SSM Parameter store, also integrated it with a SNS topic Subscription to notify team about sensitive information changes automatically• Troubleshooting connectivity issues using AWS cloud config.• Implemented best practices for Infra-as-code and Automation deployments.• Built Application development code and stored in Nexus as artifacts.• Used MAVEN, GRADLE as build tools on Java projects for the development of build artifacts on the source code and conducted SVN to GIT migrationEnvironment: AWS EC2, S3, AMI, EMR, Beanstalk, API Gateway, ACM, Route53, RDS, IAM, VPC, Terraform, Cloud Formation, ELB, Lambda, Jenkins, Git, ANT, Maven, Nexus, Shell, Python.DevOps AWS EngineerAMEX - NYMarch 2016 to June 2017Responsibilities• Designed and managed public/private cloud infrastructures using Amazon Web Services (AWS) which include EC2, S3, Cloud Front, Elastic File System, RDS, VPC, Direct Connect, Route53, Cloud Watch, Cloud Trail, Cloud Formation, and IAM which allowed automated operations.• Creating S3 bucket and furthermore overseeing strategies for S3 bucket and Utilized S3 bucket and Glacier for storage and backup on AWS.• Creating Cloud Watch alerts for instances and utilizing them in Auto-scaling launch configurations.• Implemented and maintained the monitoring and alerting of production and corporate servers/storage using AWS Cloud Watch.• Created customized AMIs based on already existing AWS EC2 instances by using create image functionality, hence using this snapshot for disaster recovery.• Worked on AWS cloud watch for monitoring the application infrastructure and used AWS email services for notifying & configured S3 versioning and lifecycle policies to and backup files and archive files in Glacier.• Dockized CI/CD tools (JENKINS and GIT lab).• Implemented a Continuous Delivery pipeline with Docker and AWS.• Experience with container-based deployments using Docker, working with Docker images, Docker HUB and Docker registries.• Worked on creation of Docker containers and Docker consoles for managing the application life cycle.• Used Docker as a new level of simplicity to defining and creating applications or services by encapsulating them in containers.• Used Docker containers for eliminating a source of friction between development and operations.• Used Docker machine as a virtualization between systems.• Automated application deployment in the cloud using Docker technology using Elastic Container Service scheduler.• Worked on Kubernetes to provide platform as service on private and public cloud in VMware Cloud.• Integrated Kubernetes with network, storage, and security to provide comprehensive infrastructure and orchestrated container across multiple hosts.• Worked on Deployment Automation of all microservices to pull image from private Docker registry and deploy to Kubernetes Cluster.• Utilized Configuration Management Tool Chef to create and manage Chef Cookbooks using recipes to automate system operations.• Highly involved in Configuring, monitoring and multi-platform servers by defining Chef Server from workstation to manage and configure Chef Nodes.• Implemented environments, roles, and data bags in Chef for better environment management.• Design and document CI/CD tools configuration management.• Responsible for orchestrating CI/CD processes by responding to Git triggers, human input, and dependency chains and environment setup.• Implemented Jenkins CICD Pipeline flow for different projects by creating multiple stages like build, integration, test, stage and production.• Generating the Jenkins Pipeline Framework and right Jenkins file to create Build, Test and Deployment Pipeline across different applications environments.• Establishing and maintaining of setup to Build and deploy the application to the Cloud AWS.• Implemented CI and CD for database using Jenkins and GIT plugins.Environment: AWS EC2, S3, AMI, IAM, VPC, Cloud Formation, ELB, Jenkins, Git, ANT, Maven, Docker, Kubernetes, Chef, Nexus, Shell, Python.DevOps EngineerVerizon - Tampa, FLJanuary 2014 to February 2016Responsibilities• Actively involved in architecture of DevOps platform and cloud solutions.• Collaborated with Development and Support teams to setup a Continuous Delivery environment with the use of Docker and continuous build and delivery tools.• Coordinating the resources by working closely with Project Manager's for the release and Project Manager for all the Operational Projects.• Worked on Managing the Private Cloud Environment using Puppet.• Build Automation and Build Pipe Development using Jenkins and ANT.• Developed automation framework for Application Deployments to the cloud environments.• Designed Puppet Modules to manage configurations and automate installation process.• Automated centralized configuration using Puppet.• Worked on migration from Datacenter to AWS.• Working for DevOps Platform team responsible for specialization areas related to Puppet for Cloud Automation.• Implemented rapid-provisioning and life-cycle management for Ubuntu Linux using Amazon EC2, Puppet and custom Ruby/Bash scripts.• Managed and optimize the Continuous Delivery tools like Jenkins.• Automate Continuous Build and Deploy Scripts for Hudson/Jenkins Continuous Integration tool.• Develop Custom Scripts to monitor repositories, Server storage.• Experienced with RESTful API's of Elastic Search to analyze, search and visualize real-time data.• Scripting & automating tasks using Python for backup, monitoring and file processing.• Upgrading Production Environment servers for Stability and Security.• Installed and configured Puppet and BIND for internal infrastructure within the company.• Implemented Nagios monitoring solution for mission critical servers.• Worked on creation of custom Docker container images, tagging and pushing the images.• Worked on creating the Docker containers and Docker consoles for managing the application life cycle.• Branching, Tagging, Release Activities on Version Control Tools: SVN and GIT.• Experienced network based services including DNS, Syslog, NTP, SSH. Utilized Netstat, Dig, Traceroute, Nmap, iPerf and Rsync.• Provide stable build environments for product development.• Accumulated application and system logs into Log Stash for centralized monitoring, querying and reporting.• Continuously updating documentation for internal knowledge base of support team and IT team.Environment: Jenkins, GIT, ANT, MAVEN, Docker, AWS (EC2, S3), Chef, Python Scripts, UNIX, JIRA, Apache, Nagios.Unix/Linux System AdministratorCA Technologies - Hyderabad, TelanganaMarch 2012 to December 2013Responsibilities• Installed SUSE Linux on Cisco Hardware for SAP HANA deployment.• Experience with Linux installation, configuration management and patch administration as member of a production support team.• Strong knowledge of Linux Kernel configuration, performance monitoring, and tuning.• Good knowledge of LVM, which include creating PVs, VGs, LVs and file systems and trouble shooting.• Configuration and maintenance of common applications such as NFS, DHCP, NTP, SSH, DNS, and SNMP.• Strong knowledge of large-scale Linux deployment methodologies, kernel configuration, performance monitoring, and tuning.• Experience with SAN/DATA Centre Migration and Consolidation implementations.• Experienced in Strong Consolidation/Migration in an ENTERPRISE environment.• Involved in complete Administration tasks on UNIX, Red Hat Linux and Solaris and documentation for the projects executed.• Responsible for installation, configuration and administration of sun Solaris 9 and Red Hat enterprise Linux on X86 architecture.• Installed required software patches and software.• Used RPMs to install, update, verify, query and erase packages from Linux Servers.• Configured Kick start server to Install Red Hat Linux on multiple machines.• Experience using Kick start and modified Kick start based on server profiles and hardware specifications.Environment: VMWare, Oracle Virtual, RHEL, Solaris, NFS, DHCP, NTP, SSH, DNS, SNMP.,""TECHNICAL SKILLSAWSEC2, ELB, EBS, Route 53, IAM, S3, AMI, Cloud Watch, Cloud Front, RDS, ELK (elastic search, log stash and Kabana), Lambda, VPC, Glacier, SQS, DynamoDB, IoT, API Gateway, EMR, AWS Code deployLanguages	Python, Terraform, Cloud Formation, Bash Shell Scripting, RubyVersion Control Tools	GitHub, Bitbucket, SVN, CVSContinues Integration Tools	Jenkins, HudsonDatabase	Oracle, MySQL, MSSQL, NOSQL, PostgreSQL, Aurora, MongoDBContainerization Tools	Docker, CentOS, KubernetesBuild Utility Tools	Maven, ANTOther Tools and Services	VMware, Virtual Box, Jira, Rally, Nagios, Service NowConfiguration Management Tools   Chef, Puppet, AnsibleWeb Servers	Apache, Tomcat, WebSphereOperation system	Windows, Linux (RHEL, RedHat, CentOS), Ubuntu""";;;
"Sr. AWS DevOps/Cloud Engineer Germania Insurance - Brenham, TXOctober 2017 to PresentRoles & Responsibilities: • Provisioning infrastructure on AWS EC2/VPC/S3/SQS/SNS based automation through Cloud Formation, Terraform, Python Boto and Bash Scripts.• Created automation and deployment templates for relational and non-relational databases including MS-SQL, MySQL, Cassandra and MongoDB for different micro-services.• Created AWS cloud formation templates to create organization AWS network from scratch with custom-sized VPC, subnets, NAT gateways, internet gateways, Route tables, ACL's EC2 instances, ELB's, security groups.• Worked on with tagging standards for proper identification and ownership of EC2 instances and other AWS Services like Cloud Front, cloud watch, Elastic beanstalk, RDS, Red Shift, S3, Route53, SNS, SQS, Cloud Trail.• Managing a team of DevOps engineer for infrastructure support on AWS cloud. Creating Cloud Formation scripts for hosting software on AWS Cloud.• Automating the installation of software through Power Shell scripts and CM tools.• Worked on Azure infrastructure management (Azure Web Roles, Worker Roles, SQL Azure, Azure Storage, Azure AD Licenses and Office 365).• Dealt with Windows Azure IaaS - Virtual Networks, Virtual Machines, Cloud Services, Resource Groups, Express Route, Traffic Manager, VPN, Load Balancing, Application Gateways, AutoScaling.• Converted existing Terraform modules that had version conflicts to utilize cloud formation during Terraform deployments to enable more control or missing capabilities.• Used Docker in swam mode and Kubernetes for container orchestration, by writing Docker files and setting up the automated build on Docker HUB.• Building/Maintaining Docker container clusters managed by Kubernetes Linux, Bash, GIT, Docker, on GCP.• Utilized Kubernetes and Docker for the runtime environment of the CI/CD system to build, test deploy.• Implemented a production ready, load balanced, highly available, fault tolerant AWS infrastructure and Microservices container orchestration.• Implemented a Continuous Delivery pipeline with Docker, Jenkins, GitHub and AWS AMI's. Whenever a new GitHub branch gets started, Jenkins server automatically attempts to build a new Docker container from it, the Docker container leverages Linux containers from the baked AMI.• Design, installation, configuration and administration of Linux 5, 6 and 7 servers and support of OpenShift Enterprise and non-OpenShift support.• Implemented Chef Recipes for Deployment on build for internal Data Centre Servers.• Also, re-used and modified same Chef Recipes to create a Deployment directly into Amazon EC2 Instances.• Used Ansible Tower, which provides an easy-to-use dashboard and role based access control, so that it's easier to allow individual teams access to use Ansible for their deployments.• Spun up core services according to demand with custom Python, Ruby scripts and Ansible playbooks.• Automate the installation of ELK agent (file beat) with Ansible playbook.• Deployed and configured Elastic Search, LogStash and Kibana (ELK) for log analytics, full text search, application monitoring in integration with AWS Lambda and Cloud Watch. Established DevOps culture based on Docker and Kubernetes tools.• Automated applications and MySQL container deployment in Docker using Python and monitor them using Nagios.• Configured Nginx for proxy RESTful API calls to micro-services in Docker containers.• Installing, upgrading and configuring SUN Solaris 9/10 on Sun Servers using Jumpstart and Red Hat Linux 5.x Servers using Kickstart.• Worked on Data Encryption (Client-Side and Server-Side) and securing data at rest and in transit for data in S3, ELB, EBS, RDS, EMR, and Red Shift using Key Management Service (KMS).• Created Python scripts to totally automate AWS services which includes web servers, ELB, Cloud Front distribution, database, EC2 and database security groups, S3 bucket and application configuration, this script creates stacks, single servers, or joins web servers to stacks.• Involved in creating and documenting POC for helping migrate the current application to micro service architecture (the architecture included Docker as the container technology with Kubernates and worked on with REST API).• Design and implementation of VMware VRealize suite and SAN/NAS implementation and management.• Implement VMware VRealize to proactively detect and remediate issues and ensure performance and availability, from applications through the entire infrastructure stack and across multi-cloud environments.Environment: AWS, NoSQL, MS SQL, MySQL, Git, Jenkins, Chef, VMware VRealize,  Docker (Daemon), Kubernetes, Pivotal Cloud Foundry (PCF), Terraform, Python, shell script, Maven, Ansible, ANT, Cassandra, MongoDB, Cloud Front, Cloud Watch, Cloud Trail, Cloud Formation, Java, PHP, Node.js, Elk, Bugzilla, IBM WebSphere Nagios, GCP, Red Hat Linux, Mpstat, Vmstat, IoStat, NetStat, Nfsstat, Packer, Sonar, Nexus, JIRA, Vagrant, AzureDevOps EngineerPapa John's - Louisville, KYJanuary 2016 to October 2017Roles & Responsibilities: • Worked closely with the Development Team in the design phase and developed Use case diagrams using Rational Rose.• Used Node.js uses as event-driven, non-blocking I/O model that makes it lightweight and efficient.• Ran Python scripts to totally automate AWS services which includes web servers, ELB, Cloud Front distribution, database, EC2 and database security groups, S3 bucket and application configuration, this script creates stacks, single servers, or joins web servers to stacks.• Implemented & maintained the branching and build/release strategies utilizing Subversion /GIT.• Implemented a new CI/CD pipeline with application containerized deployment using container orchestration tools like Docker and Kubernetes.• Setup and configure the CI/CD process using Bitbucket Data Center, Jenkins, Docker, RHEL Satellite 7.0 and OpenSCAP as image scanning tool for vulnerabilities.• Installing Bitbucket Data Center on premise to merge the existing Stash/Bitbucket servers of individual companies in the organization to one source of platform for code repositories.• Supporting the development team to provision the server and integrate with the system and CI/CD setup.• Used tools like JIRA for Bug tracking/created tickets, generated reports on different bugs and tickets.• Responsible for design and maintenance of the Subversion/GIT Repositories, views, and the access control strategies.• Involved in periodic archiving and storage of the source code for disaster recovery.• Worked closely with developers to pinpoint and provide early warnings of common build failures.• Used ANT and MAVEN as build tools on Java projects for the development of build artifacts on the source code.• Automated the build and release management process including monitoring changes between releases.• Deployed the Java applications into web application servers like Web logic.• Involved in Video management, video analytics ,manipulation and distribution applications • Developed scripts for deployment of customer environments into AWS using Bash, Python and created scripts which integrated with Amazon API to control instance operations.• Executed user administration and maintenance tasks including creating users and groups, reports and queries.• Worked as a system administrator for the build and deployments process on the enterprise server.• Documented project's software release management procedures with input decisions.• Developed, maintained, and distributed release notes for each scheduled release.• Provided periodic feedback of status and scheduling issues to the management.• Kept track of all the releases and request of the developers through Infrastructure management tool.• Used the continuous integration tool Anthill Pro to automate the daily processes.• Created views and appropriate meta-data, performed merges, and executed builds on a pool of dedicated build machines.Environment: Bitbucket, GIT, AWS, Jenkins, Java/J2EE, ANT, MAVEN, JIRA, Ruby, LINUX, XML, Windows XP, Windows Server 2003, Web logic, MY SQL, Node.js, Perl Scripts, Shell ScriptsDevOps / Build & Release EngineerJohn Deere - Des Moines, IAAugust 2014 to December 2015Roles & Responsibilities: • Designed and Developed Jenkins Build deployments.• Managed Nexus Maven repositories to download the artifacts during the build.• Branching and merging code lines in the GIT and resolved all the conflicts raised during the merges.• Used GIT as Version Control System for two applications. Managed development streams and integration streams.• Designed and developed build Korn shell and Perl scripts.• Wrote maven pom.xml and build.xml for build scripts.• Used Maven Nexus Repository to upload the build artifacts after a successful build.• Installed and administered tools like Jenkins, Jira, Confluence and Fisheye.• Trained teams on using Confluence for the document and collaboration activities.• Written Perl/Shell scripts for deployments to servers.• Used JMeter and Selenium for load testing and Front End performance testing.• Used Behat for User Acceptance Testing for the Website • Deployed the build artifacts into environments like QA, UAT & Production according to the build life cycle.• Worked on Develops automated tools that produce repeatable, auditable software builds and deployments across all environments and a variety of platforms • Provided the reports using Bean shell scripting in Anthill Pro.• Wrote WLST scripts and integrated with Anthill Pro to automate the deployment activities to various environments.Environment: GIT, Jenkins, Java/J2EE, ANT, MAVEN, JIRA, Ruby, LINUX, XML, Windows XP, Windows Server 2003/2008, MY SQL, Perl Scripts, Shell ScriptsBuild & Release EngineerTime Warner Cable, NYFebruary 2013 to July 2014Roles & Responsibilities: • Maintained and administered GIT source code tool.• Participated in weekly release meetings with Technology stakeholders to identify and mitigate potential risks associated with the releases.• Installed subversion server on RedHat (Rhel) Linux boxes. Created subversion repositories, imported projects into newly created subversion repositories as per the standard directory layout.• Created various branches for each purpose, Merged from development branch to release branch, created tags for releases.• Interacted with client teams to understand client deployment requests.• Used JIRA to track issues and Change Management.• Integrated JIRA with SVN and created automated release Notes using Perl Scripts.• Coordinate with the Development, Database Administration, QA, and IT Operations teams to ensure there are no resource conflicts.• Used ticketing tools like JIRA/ Bug tracking / created tickets, generated reports on different bugs and tickets.• Solved blocked and unassigned tickets.• Worked closely with Project Managers to understand the code/configuration release scope and how to confirm a release was successful.• Developed build and deployment scripts using ANT and MAVEN as build tools in Jenkins to move from one environment to other environments.• Provided end-user training for all Subversion (SVN) users to effectively use the tool.• Built and Deployed Java/J2EE to a web application server in an Agile continuous integration environment and automated the whole process.• Labelling activities in TFS once deployment is done.• Created and maintained the Shell/Perl deployment scripts for po5 web application servers.Environment: Subversion (SVN), Jenkins, ANT, MAVEN, Web Logic, SQL server 2005, TFS 2010, Perl Scripts, Shell Scripts, XML, UNIXUnix/Linux /Systems AdministratorCitiGroup - Irving, TXMarch 2011 to January 2013Roles & Responsibilities: • Installation, configuration and administration of (Rhel) RedHat Linux servers and support for Servers.• Installation, maintenance and regular upgrades of Red Hat Linux Servers using kick start based network installation • Provided 24x7 System Administration support for Red Hat Linux 3.x, 4.xservers and resolved trouble tickets on shift rotation basis.• Provide the support of building the server, patching, user administration tasks, deployment, software installation, performance tuning and troubleshooting and KVM.• Managing Compaq and Linux workstations and servers.• Installation of patches and other software packages • Designing, implementing and managing Linux environment for Incident & Patch Management.• Disk and File system management through Solstice Disk Suite on Solaris and other logical volume manager for other flavor of UNIX.• Monitoring system performance, tune-up kernel parameter, adding /removing /administering hosts, users, disks on DNS / NIS domain.• Configuration of Hardware and Software RAID on Digital & Sun Servers • Installation of Oracle Patches, java applications and Troubleshooting, Creating and modifying application related objects, Creating Profiles, Users, Roles and maintaining system security.• Administrative tasks such as System Startup/shutdown, Backup strategy, Printing, Documentation, User Management, Security, Network management, dumb terminals and devices carried out.• Installation and configuration of Oracle 7.x/8.x.• Implemented NFS, DNS and NIS under SUN systems.• Worked on different VMware products like VMware workstation, GSX/VMware server, VMware player, and VMware Converter and ESX server 3.XEnvironment: Red Hat Linux 2.6.x, SunFire, SunStorEdge L280, SunStorEdge A1000, A5000, JBODs Compaq servers, Solstice Disk Suite, Oracle 7.x/8.x,VMware,""• IT Professional with 9 years of experience in Cloud implementations [AWS, Azure], extensive expertise on code compilation, packaging, building, debugging, automating, managing, tuning and deploying code across multiple environments.• Highly skilled in administration which includes AWS Cloud Services, (EC2, Auto Scaling, S3, EBS, ELB, Elastic IP, RDS, SNS, SQS, SES, Glacier, IAM, VPC, Direct Connect, CloudFront, Cloud Formation, Route53,Red shift, Kinesis ,Lambda, Systems Manager Cloud Watch, Cloud Trail and Security Groups).• Strong experience on DevOps/Agile operations process and expertise in areas like (Unit test automation, Build & Release automation, Environment Management, Service Management, Incident Management and Change Management).• Expertise in creating and maintain Jenkins pipelines to drive all Microservices builds out to the Docker registry and then deployed to Kubernetes, Created Pods and managed using Kubernetes.• Good knowledge in Mesos providing the fine-grained resource allocations for pods across nodes in a cluster and making Kubernetes play nicely with other frameworks running on the same cluster resources.• Hands-on experience in Bamboo/Octopus to distribute applications to all remote machines, connection strings, configuring IIS in parallel.• Experience in branching, tagging and maintaining the version across the environments using SCM tools like GIT, Bitbucket, Subversion (SVN) and TFS on Linux and windows platforms.• Strong experience on bootstrapping and maintaining AWS using Chef on complex hybrid IT infrastructure nodes through the VPN and Jump/Bastion Servers.• Experience supporting Chef Environment with 200+ servers and involved in developing manifests and familiarity with Salt Stack• Excellent at defining Chef Server and workstation to manage and configure nodes.• Experience in migrating on premise infrastructure to cloud platforms like Aws/Azure/Rackspace/Pivotal Cloud Foundry (PCF) and virtualization using (VMware, VMware ESX, Xen) and infrastructure orchestration using containerization technologies like Docker and Kubernetes.• Experience in load balancing and  monitoring System/Application Logs of server using DataDog, Splunk, Nginx, Nagios, Kibana, ELK, LogStash to detect Production issues.• Integrated pagerduty, service now with monitoring services and tools.• Good experience on Python Scripting in various projects for automating tasks.• Good experience and understanding of SAN (SAN arrays, HITACHI, EMC) technology including zoning, disk creation on various systems, maintaining and configuring various fiber switches and storages, Shell scripting (Ksh, bash) to automate system administrative jobs.• Experience in introducing, designing, adjusting, testing and conveying applications on Apache Webserver, Nginx and Application servers, for example, Tomcat, JBoss.• Good knowledge of NGINX in using as a reverse proxy and load balancer to manage incoming traffic and distribute it to slower upstream servers - anything from legacy database servers to Microservices.Technical competencies:Cloud Technologies: Open Stack, AWS (VPC, EC2, EMR, S3, EBS, ELB, RDS, SNS, Config, SQS, Glacier, IAM, VPC, Cloud Formation, , Route53,Red shift, Kinesis ,Lambda, Systems Manager Cloud Watch, Cloud Trail) Microsoft Azure, Spinnaker, Rackspace, pivotal cloud Foundry (PCF)Operating Systems: UNIX, red hat Linux (Rhel), OpenShift, Ubuntu, Windows 98/NT/XP/Vista/7/8,SCM Tools: Subversion, GIT, BitBucket, TFSBuild Tools: Ant, MavenCI/CD Tools: Jenkins, Hudson, Bamboo, Octopus, U Deploy, X Deploy, CircleCI, SemaphoreContainerization: Docker, Kubernetes, MesosConfiguration Management: Chef, AnsibleBug tracker & Testing: JIRA, Bugzilla, Junit, Test Flight and Test RailRepositories: Nexus, ArtifactoryWeb Service Tools: JBOSS, Apache Tomcat, IntelliJ IDEA, Oracle Web logic, IBM WebSphere, IIS Server, and Nginx VMwareLanguages/Utilities: Shell Script, ANT Script, Batch Script, Ruby, Perl, NodeJS, C, C++, Objective C, Python, Java, J2EENetworking: TCP/IP, NIS, NFS, DNS, DHCP, Cisco Routers/Switches, WAN, SMTP, LAN, FTP/TFTPDatabases: SQL Server, MySQL, Oracle, DB2, TeradataMonitoring & Profiling Tools: DataDog, Splunk, DynaTrace JProfiler, Kibana, Logstash""";;;
"DevOps/Cloud EngineerMAYO CLINIC - Rochester, MNJanuary 2017 to Present* Proficient with Multi AZ Components in AWS like VPC, Subnet, Internet Gateway, Route Tables, Security Groups, NACL, AMI, EC2, IAM, RDS with Replication, S3 for Object and Static Webpages, Auto Scaling of Micro Services hosted on ECS, ELB and ALB to load balance and health check.* Installed application on AWS EC2 instances and configured the storage on S3 buckets, creating policies and the IAM role based polices and Created monitors, alarms for EC2 hosts using Cloud Watch and enabled notification service through SNS.* Designed AWS Cloud Formation templates(CFT) to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates and Migrated applications to the AWS cloud. Deployed applications on AWS by using Elastic Beanstalk.* Knowledge in managing multiple corporate applications into GitHub code management repositories and creating user level of access for related GitHubproject directories to the code changes.* Developed Cloud Formation Templates (CFT) in JSON and YAML format using Cloud formation designer console to setup various AWS resources such as EC2, VPC, S3, IAM and RDS.* Implemented a Continuous Delivery pipeline withDocker, Jenkins and GitHub and AWS, along with docker container creation process for each GitHub branch gets started on Jenkins as Continuous Integration (CI) server.* Configured AWSservices such as Auto-Scaling to build flexible and high-scalable systems that can handle heavy loads. Implemented Dynamic scale of EC2 instances to automatically increase number of EC2 instances during a demand spike.* Developed Terraform scripts which integrates numerous services on AWS like EC2 instances for different computational needs, RDS to configure SQL databases, DynamoDB to configure NoSQL databases like MongoDB, Cassandra, and SNS for Notifications of critical issues.* Wrote multiple programs in Python to monitor virtual machine usage data using VMWare API calls and Created script in Python for calling REST APIs.* Wrote a program to use REST API calls to interface with backup server, and parse output reports of an Excel file in Python to monitor customer backup usages.* Utilized AWS Beanstalk for conveying and scaling Web Applications and administrations created with PHP, Node.js, Python, Ruby and Docker on Application servers like Apache, WebSphere, WebLogic, JBoss.* Created Python scripts to totally automate AWS services which includes Web servers, ELB, Cloud Front distribution, Database, EC2 and Database Security Groups, S3 Bucket and application configuration, created scripts of single servers, or joins web servers to stacks.* Implemented the automated Nagios in Ops environment for alerts and Email notifications using Python script and executed them through Chef.* Managed Openshift container platform, that provides a self-service for users, also automated the software delivery process to achieve continuous integration, delivery and deployment.* Experienced in working with components of AWS with Terraform, creating and managing the AWScomponents EC2, Security groups, VPC, ELB.Chef is used as the provisioning tool along with Terraform.* Hands-on with Terraform key features such as Execution plans, Resource Graphs, Change Automation,IaaS and used Auto scaling configuration templates for launching amazon EC2 instances while deploying Microservices.* Utilized Python and bash with BOTO3 to supplement automation provided by Ansibleand Terraform for EBS volumes backing AMI's and scheduling Lambda functions for routine AWS tasks.Written Terraform scripts to automate multi-region AWS provisioning.* Worked in all areas of Jenkins setting up CI for new branches, build automation, plugin management and securing Jenkins and setting up master/slave configurations.* Used OpsGenie as a dispatcher with Cloudwatch integration.* Monitored performance of the applications and analyzed log information using ELK (Elasticsearch, Logstash, Kibana) Stack. Configured ELK stack in conjunction with AWS and using Logstash to output data to AWS S3.* Experienced in installation, configuration and management of HTTP, NGINX, NTP, NFS, FTP, DHCP, DNS and configured the Firewall rules to enable service communication with different applications.* Built Continuous Integration process to run static code analysis tests, to ensure that the code is well maintained and secured, also minimize security vulnerabilities with holistic and layered approach with secure infrastructure, application architecture, continuous validation and monitoring.* Maintained JIRA team Confluence System Engineering pages that included: Process Flow Management, Team Requirements, Roles and Responsibilities, and COP User Metrics Participated is customer weekly JIRA progress updates.JEPPESEN- Denver, COIndustry:Aviation	AUG 2015 - DEC 2016Cloud Engineer * Experience on design and configure multitude applications using most of the AWS stack (VPC, EC2, Route53, S3 buckets, RDS, Dynamo DB, SNS, SQS, IAM, EBS) focusing on High-Availability, Fault Tolerance and Auto-Scaling.* Configured Security groups for inbound/outbound access, network ACLs for controlling traffic through subnets, Internet Gateways, NAT instances and Route Tables to direct the network traffic and to ensure secure zones for organizations in AWS public cloud.* Collaborated in the automation of AWS infrastructure via Terraform, Ansible, and Jenkinssoftware and services configuration via Chef cookbooks.* Automate of Environment Builds (provision and configuration management) by developing the Chef Recipes and Cookbooks in Ruby by integrating with GitHub, Jenkins and AWS.* Integrating various Version control tools, build tools, nexus and deployment methodologies (scripting) into Jenkins to create an end to end orchestration build cycles.* Provisioned the highly available EC2 instances using Terraform and Cloud Formation templates(CFT), wrote new plugins to support new functionality in Terraform and involved in using terraform migrate legacy and monolithic systems to AWS.*  Utilized Terraform in AWS VPC to automatically setup and modify settings by interfacing with control layer.* Used Chef to manage Web applications, Environments configuration Files, Users and Mount points. Integrated Terraform with Chef, Packer to create and Version the AWS Infrastructure.* Developed CI/CD system with Jenkins on Kubernetes container environment, utilizing Kubernetes and Docker for the runtime environment for the CI/CD system to build and test and deploy.* Used Git for source code version control and integrated with Jenkins for CI/CD pipeline, code quality tracking and user management with build tools Maven and Gradle.* Configured the Kubernetes provider with Terraform which is used to interact with resources supported by Kubernetes to create several services such as Config Map, Namespace, Volume, Auto scaler, etc.* Integrated GitHub, Bitbucket (Git based) with Jenkinsby configuring Web hooks, Installed and Configured Junit plugin to perform unit testing on the source code, Sonarqube to perform code coverage and checking the duplication of a code, build tools like Maven/Gradle/Ant to build the artifacts and upload it on to Binary repository tools like Nexus and Artifactory.* Implemented LAMP stack image in multitier AWS instances in different subnets in Amazon VPC, attached NACL's andSecurity Groupsto maintain high security.* Worked on building and deploying Java code through Jenkins to automate builds and deployments, as well as troubleshooted build issues in Jenkins, performance and generating metrics on master's performance along with jobs usage.* Created Ansibleplaybooks for various automation purposes like file copy, permission changes, configuration changes, path specific folder creation, etc. and written playbook using Ansible modules such as yum, Copy, File, get_url, git, ping, service, template, debug, synchronize.* Integrated Jenkins with Packer to build the AMIs with latest version of the war file and Middleware like Tomcat, WebSphere, WebLogic etc.* Developed Ansible playbooks with various MySQL, MS SQL modules to run SQL Database migration scripts to perform A/B testing with the newly deployed applications in the Staging environment. WebSphere, WebLogic defined in Packer.json file and later triggered the Terraform scripts to create the stack on the AWS cloud environment.* Configured Jenkins to automatically handle deployment and creation of Ansible playbooks in YAML format to spin up and configure application servers like tomcat, WebSphere, WebLogic.* Installed and configured Ansible plugin with Jenkins, developed Ansible custom modules to automate various regular maintenance work on AWS Cloud environment.* Developed Chef cookbooks to Install and configure Tomcat, WebSphere, WebLogic servers on the AWS EC2 instances to create development and test environments. Version controlled the cookbooks using GitHuband tested the cookbooks using Test Kitchen, Chef Solo, Chef Spec.* Worked on Python scripts to automate AWS services which include web servers, EC2, ELB, S3 bucket, Cloud front Distribution, database security groups and application configuration.* Implemented Boto3 python script to integrate the application, library of the Amazon services like Compute (Amazon EC2), Storage (Amazon S3) and Amazon DB. Configured the Boto3 script to have dynamically generated by JSON model to elaborate APIs.* Implemented auto server build management, monitoring and deployment using Puppet, andNagiosandConfigure scheduled downtime for non-prod servers for optimizing AWS pricing.* Implemented Puppet dashboard for quick visual snapshot of important system information and to deliver valuable reports and created a puppet database for storing information about every node, resource, relationship, users and information about entire infrastructure.* Implemented and managed Puppetmaster server and experience in updating and creating modules and delivering them to Puppetclients and managing SSL certificate.* Implemented Splunk Dashboards, searches and reporting to support various internal clients in Security, IT Operations and Application Development. Build performance dashboards through Splunk, Extra hop, writing Java script and customized scripts and worked with internal clients to develop requirements, relationships and value metrics.Build/Release EngineerADP - Pune, MaharashtraApril 2013 to August 2015* Developed AWS Lambda functions to trigger the creation of new instances on AWS, deploy the new war file and to create the AMI. Developed Cloud formation templates which use the new AMI to do the Immutable deployments on to AWS by updating the stack, verifying the change set and trigger the stack creation.* Integrated Jenkins with GIT and Maven to create a pipeline of building and deploying the artifacts by pulling Puppet manifests from the version control GIT using webhookand storing them into Nexus/Artifactory.* Used configuration management tool Puppet to write manifests to maintain consistent configuration across all the servers to avoid configuration drift by installing specific client requested packages.* Deployed and administrated scalable infrastructure on Amazon web services (AWS) using configuration management tool chef for development and test environments.* Good knowledge in Implementation, configuration, maintenance of open LDAP server and application configured with Apache/Tomcat/Nginx, samba & send mail, Web sphere application servers and postfix mail server for user authentication.* Configured and maintained GIT source code tool and created branches, tags and merged in GIT repository and triggered push and pull requests from Jenkins. Automated the weekly deployments using CI tool Jenkins with integrated GIT version control system to automate the code check-out process.* Automated deployment of Web and Application servers like WebSphere, IIS, Apache, WebLogic, JBoss and Tomcat on public and private cloud using CI/CD tools.* Provisioned build environment for various products in Linux, Ubuntu, SUN Solaris, AIX environments and implemented the Release practice and responsible for pushing builds into DEV/ QA / SIT / UAT.* Installed and configured Apache Tomcat and MySQL database for the application team and performed planned weekly and monthly maintenance task on the servers.* Highly experienced with Windows OS administration and clustering support, VMware related planning, and scoping of physical servers that could be converted to virtualized instances such as Exchange 2007/2010 mailbox servers, Windows based Oracle Database servers and Active Directory servers.VMware EngineerMRL Posnet LTD - Hyderabad, TelanganaMay 2011 to March 2013* Deployed and configured VMware ESXi and designed templates to provision VMs and Implemented ESXi hosts utilizing vCenter Server. Created templates for cloning of virtual machines using VMware Virtual Client and migrating servers between ESXi hosts.* Configured the network details using vSphere client and installed required software in RHEL environment. Integrated, configured and deployed new patches, upgrades, bug fixes on both physical and virtual Red Hat Linux servers using YUM server and satellite server.* Performed initial validation of Avoid software products on virtual servers. Focusing on VMware vSphere and Hyper-V hypervisors (primarily VMware). Working with other groups to maintain validation.* Good understanding of VMware Networking concepts like building vSwitches, with several types of port groups and experienced in Patch Management of ESXi Hosts using VMware Update Manager.* Experience in the V2V and P2V migration of Physical servers to VMware ESXi hosts and worked with datacenter support team and vendor to perform physical server hardware upgrade and replacement activity.* Configured the vSphere Virtual Machine File System to give high performance cluster file system for ESXivirtual machines.* Installed and configured hardware RAID card to achieve high availability and fault tolerance in event of disk failure using different RAID methods like Raid 01, RAID 5 and RAID 1.* Created, monitored and managed VMware snapshots and SnapMirror to restore the VMs to a consistent state from the corrupt/failed state.* Configured Logical Volume manager to create, extend and maintain volumes and check the partitions of the disk space.* Provided and maintained user access in VMware virtual Center, configuring mail alert for any failure in HA, DRS, CPU and memory.* Automated the planned patching process for server validations (reboot time, uptime, etc.) after monthly security updates. Troubleshooted data and network issues of over 600 Windows Servers utilizing multiple technologies to include SQL, Exchange, DHCP, DNS, DFS, IIS, FTP, SharePoint, Domain Controllers, and Active Directory.* Provided Remote Support and administration on network for internal and external clients using tools like Microsoft Remote Desktop Connection (RDP).* Configured RAID 1, RAID 01 and RAID 5 to avoid system/application downtime in the event of disk failure.* Good knowledge on performance monitoring tools TOP, NETSTAT, SAR, IOSTAT to keep track of CPU, memory, disk and network devices status.* Expert in using filter tool AWK, SED, GREP, EGREP and FGREP.* Troubleshooting OS/Hardware related issues and monitor server health on a day-to-day basis to maintained maximum uptime and high performance for Enterprise Production, Development, and QA environment servers.,""TECHNICAL SKILLSOperating Systems	RHEL/CentOS 5.x/6.x/7.x, Ubuntu/Debian/Fedora, SUN Solaris 7/8/9/10, IBM AIX, Windows Server 2003/2008/2012Cloud	AWS, AZURE, Google Cloud Engine (GCE)Scripting	Bash, Shell, Ruby, PowerShell, Python, Perl, YAMLBuild/Automation Tools	Ansible, Chef, Puppet, Jenkins, Maven, Ant, GradleDatabases	MySQL, SQL Server, MongoDB, PostgreSQL, CassandraBug Tracking Tools	JIRA, RemedyVersion Control Tools	GIT, GitHub, BitBucket, GitLab, Subversion (SVN), TFSWeb/App Server	Apache, Nginx, IIS, TFS, Tomcat, WebSphere Application ServerWeb Technologies/ Programming Languages   Servlets, JDBC, JSP, XML, HTML, .Net, Java Script, Java/J2EE, C, C++, Perl scripting, Python, Shell scripting, Ruby, YAML""";;;
"Cloud Engineer SAE InternationalJuly 2018 to Present Responsibilities:• Managing Cloud Services using AWS Cloud Formation, which helped developers and businesses an easy way to create a collection of, related AWS resources and provision them in an orderly and predictable fashion.• Launching Amazon EC2 Cloud Instances using Amazon Images (Linux/ Ubuntu) and Configuring launched instances with respect to specific applications.• Responsible for day to day Build and deployments in Dev, QA, pre-production and production environments. Implemented AWS high-availability using AWS Elastic Load Balancing (ELB), which performed balance across instances in multiple availability zones.• Maintained the user accounts (IAM), RDS, Route 53, VPC, RDB, Dynamo DB, SES, SQS and SNS services in AWS cloud.• Migrating an on-premises application to AWS.• Wrote AWS Lambda functions in python for AWS's Lambda which invokes python scripts to perform various transformations and analytics on large data sets in EMR clusters.• Designed and worked with team to implement ELK (Elastic search, Log stash and Kibana) Stack on AWS.• Maintained DNS records using Route53 to Improve Fault Tolerant Connections and using Load balancer, Security groups and NACLS.• Provide highly durable and available data by using S3 data store, versioning, lifecycle policies, and create AMIs for mission critical production servers for backup.• Expertise in infrastructure development on Amazon Web Services (AWS) cloud platform services stack including Elastic Cloud Compute EC2, S3, EBS, EFS, Elastic Bean Stalk, Route 53, VPC, Cloud Front, Dynamo DB, Red Shift, RDS, Key Management Service (KMS), Identity & Access Management (IAM), Elastic Container Service (ECS), Elastic Load balancing, Cloud Formation, Elastic Cache, SNS, SQS focusing on high availability, fault-tolerance and auto scaling.• Handled migration of on premises applications to cloud and created resources in cloud to enable this. Used all critical AWS tools, used ELBs and Auto-Scaling policies for scalability, elasticity and availability.• Created Hosted Zone and record sets with CNAMES pointing to Application Load balancer in Route 53.• Experience in setting up and configuring the Amazon ECS service and used Amazon IAM to grant fine-grained access to AWS resources to users with MFA enable.• Created micro services using REST protocol with Docker and Kubernetes, Utilized Mesos, Kubernetes and Docker for the runtime environment for the CI/CD system to build, test, and deploy.• Automated deployment using DSL and Groovy scripts.• Created Multi branch Pipeline Jobs for Builds and Deployments, installed several plugins in Jenkins to support multiple tools required for the implementation of projects.• Automated CI/CD pipeline for the monitoring tools Docker containers and written script to test them.• Created Deployment pipeline for the ReactJs application frontend and designed deployment pipeline for Dotnet core application integration with api gateway and lambda functions.• Created S3 bucket for static website hosting by attaching cloud front distribution with SSL certificate to the origin of the bucket endpoint url.• Deployed the build artifacts into JFrog artifactory, Nexus repository for environments like QA, UAT according to the build life cycle.• Debugging Chef Recipes and their execution trying to pull logs into Splunk and monitor deployments.Automated the cloud deployment using Chef, Python and AWS Cloud Formation Templates. Used Chef for unattended bootstrapping in AWS• Managed all the bugs and changes into a production environment using the Version one tracking tool, Nagios & Graphite for System monitoring, Cloud Watch and Cloud Trial for monitoring the cloud environment.• Experience in setting up Baselines, Branching, Patches, Merging and Automation Processes using Shell/bash Scripts• Enabled SSL for the applications with the certificate issued from Amazon certificate Manager.• Established patching on all the virtual machines and EC2 Instances and installed SSM agent for auto patching.• Created ECS Clusters in two AZ's and Pushed docker images into ECR, automated the process of task definition creation and deployed new services into ECS cluster.• Configured Nagios to monitor servers with Chef Automation.• Installing, configuring and managing Continuous integration, Continuous Delivery, Automation and configuration management tools to make the Open shift cloud setup.ENVIRONMENT: AWS, EC2, S3, VPC, ELB, Cloud Watch, Dynamo DB, SNS, SQS, API Gateway, Auto scaling, EBS, RDS, GIT, Linux, LAMP, Nagios, Maven, Apache Tomcat, Shell, Perl and Python, version-one, one-login.Cloud EngineerThermo Fisher scientific - Pittsburgh, PAJanuary 2018 to July 2018Responsibilities:?  Setup and build AWS infrastructure various resources, VPC EC2, S3, IAM, EBS, Security Group, Auto Scaling, and RDS in Cloud Formation JSON templates.? Writing the Ansible play book to automate the infrastructure using Stash Source control.? Worked on Deploying 3 (Dev, Test, and Prod) new environments of the technology FDMEE (An Oracle Hyperion Product) in AWS 8 VMs to accomplish the setup.? Server builds migrate/build servers to the cloud.  Connectivity issues, system maintance, sever migrations, open necessary ports, raise Firewall requests, and resolve access issues for users various requests for builds.? Work on overall refactoring of Ansible code base and continued development of playbooks.? Missing tag remediation of AWS resources (identification/reporting and governance automation with Lambda Cloud Patching (Automox install across the board and systems information reporting - total numbers, OS identification, etc.)? Transitioning all VPC automation to Ansible from Cloud formation AWS Lambda CI framework w/ Jenkins Pipeline? Setting up the Test Environment, writing the Cloud Formation scripts for Production Environment setup.? Setting up the build and deployment automation for Terraform scripts using Jenkins.? Azure Cloud Solutions and Migrations for large infrastructure Migration planning for legacy systems to Cloud Solutions using Azure.? Implemented a continuous delivery pipeline with Dockers, Jenkins and stash whenever a new stash branch gets started.? Configuring DNS (Route53), ELB, general networking principles, firewalls, route tables and route propagations. Create and maintain SSL Security certificate management for enterprise, maintaining certificates across multiple SSL-providers, and integrating certificates into products such as nix, apache, tomcat, AWS -ELB.? Tuning cloud watch to screen assets, for example, EC2, CPU memory, Amazon RDS DB administrations, Dynamo DB.? Setting up AWS direct connect and monitoring private network connection between AWS and corporate data-trace? Lift and shift of an existing on-premises application to AWS, Identifying appropriate use of AWS architectural best practices? Environment & Tools: Groovy, python, Linux, Maven, Nexus, Chef, Ansible, Jenkins, Docker, Nginix, Nagios, stash, AWS EC-2, Route 53, S3, VPC, EMR, SQS, Autoscaling, ELB, Shell Scripts, Unix/ Linux, Datadog, Jira, service now,version-one.Cloud EngineerSamsung Next, California, SanJose, USA - SanJose, California, USNovember 2016 to December 2017Responsibilities:? Worked as part of Micro-services team to develop and deliver Maven projects to deploy on Tomcat.API contracts are documented and rendered using Swagger for QA and BA teams to view.? Load testing SOAP interfaces using SOAP UI, Groovy Script. Used Groovy on SOAP UI to implement many load test implementations. Worked on micro services architecture implementation.? Communicated with other departments by using Web Services with the help of SOAP, WSDL.? Business logic has been implemented using Array list, Map and Sets of Collections API.? Involved in designing and deploying multitude applications utilizing almost all of the AWS stack (Including EC2, Route53, S3, RDS, Dynamo DB, SNS, SQS, IAM) focusing on high-availability, fault tolerance, and auto-scaling in AWS Cloud Formation.? Configured AWS IAM and Security Group in Public and Private Subnets in VPC.? Created AWS Route53 to route traffic between different regions.? Designed AWS Cloud Formation templates to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates.? Implemented automated local user provisioning instances created in AWS cloud.? Setup and build AWS infrastructure various resources, VPC EC2, S3, IAM, EBS, Security Group, Auto Scaling, and RDS in Cloud Formation JSON templates.? Configuring and Networking of Virtual Private Cloud (VPC) Written Cloud Formation templates and deployed AWS resources using it.Professional Achievements:? Solved Recurring Problems: Problem: TCP/IP Connectivity issues with Linux/Windows Servers to AWS EC2 Instances. Solution: Developed a Wrapper Script using Trace Route module utility to understand and determine the packet losses and route congestions which help to find the root cause easily and fixed many TCP/IP Connectivity issues. End Result: By using this wrapper it reduces lot of manual troubleshooting and time.? Solved Consistent connection loss with Virtual Private Network (VPC): Problem: Lot of users are facing problem connecting to AWS VPC via Secure Shell (SSH). Solution: Developed a script which a makes a continuous status calls to System an Instances to make sure VPC is accessible and generates a report if instances are offline or failed state, this script also tries to bounce the instances if it in failure state. End Result: This script helps us to make sure all VPC are accessible all the time.DevOps EngineerProgressive Media Group - Hyderabad, TelanganaNovember 2013 to July 2015Responsibilities:? Installed, managed and deployed Linux Red Hat Enterprise, Ubuntu, Centos and installation of packages and patches for Red Hat Linux Servers.? Installed Workstation, Bootstrapped Nodes, Wrote Recipes, and Cookbooks and uploaded them to Chef-server, Managed On-site OS/Applications/Services/ Packages using Chef as well as AWS for EC2/S3&ELB with Chef Cookbooks.? Developed Chef Cookbooks, and recipes to automate deployment environment configuration.? Experience supporting Chef Environment with 200+ servers and involved in developing manifests.? Migrated over 80% of VMWARE VMs to AWS and Managed Services like EC2, S3 Bucket, Route53, ELB, EBS Etc    with Opscode Chef Cookbooks/Recipes.? Created Bash, shell & python scripts for various Systems Administration tasks to automate repeated processes.? Implemented a continuous delivery pipeline with Dockers, Jenkins and Github whenever a new GitHub branch gets started.? Implemented Multiple Tomcat Instances using Docker engine to run multiple Containerized AppServers.? Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of Open stack Nodes and Test Playbooks on AWS instances using Python.? Proficient in configuring Kick start servers to initiate installation of Red hat Linux on several machines at once.? Applied patches every quarter regularly to meet audit requirements using Oracle Ops Centre, Red Hat Satellite server, Up2Date, YUM, RPM tools.? Giving Customer support for DB2 and Web Sphere Users on AIX and Linux servers Performance Tuning and Management for Linux/AIX server.? Worked on Installation/Configuration/Administrated VMware ESXi 5.1/5.5 & 6.0 and migrated existing servers into VMware Infrastructure? Creating the file systems using Red Hat volume manager and performing the health check on regular basis for all Linux servers.? Scanning the newly assigned LUNs to the servers and assigning them to volume group and increasing the file system using Red Hat volume manager? Mounting &unmounting the netapp storage LUNs to the Red Hat Linux servers and troubleshooting the issues encountered? Planned and performed the upgrades on Linux operating systems and hardware maintenance on HP and POWER servers like increasing memory, disk, replacing failed hardware.? Worked with development teams and business areas to plan future capacity requirements and hold regular meetings to review usage as well as create, revise, and report any new measurements required to manage mainframe or distributed environments.? Doing capacity Assessment for new requests of servers i.e. calculating CPU and Memory for new servers according to the current/future Applications running on the system.Linux AdminSpectro sign software solutions - Hyderabad, TelanganaJuly 2011 to October 2013Responsibilities:? Install and configure Red Hat Enterprise Linux 5.x/6.x operating systems on large distributed environment at multiple Data centers.? Implemented AWS solutions using EC2, S3, RDS, EBS, Elastic Load Balancer, Auto scaling groups, Optimized volumes and EC2 instances.? Configured Elastic Load Balancers with EC2 Auto scaling groups, Created multi AWS VPC instances.? Experience in handling Day-to-Day operation of all servers running Production jobs, Backups, Restores and Report generations.? Set Up puppet master, client and wrote scripts to deploy applications on Dev, QA, and production environment.? Deploy and monitor scalable infrastructure on Amazon web services (AWS) & configuration management using puppet.? Responsible for puppet implementation and maintenance and to develop the puppet manifests in Ruby.? Configured Red Hat Kick start for installing multiple production servers.? Installed and configured DHCP server to give IP leases to production servers.? Management of Red Hat Linux user accounts, groups, directories and file permissions.? Applied the Clustering Topology that meets High Availability and Failover requirement for performance and functionality.? Installation, Configuration and administration of DNS, LDAP, NFS, NIS, NIS+ and Send mail on Red hat Linux/Debian Servers.? Configured, managed ESX VM's with virtual center and VI client.? Worked on server side technologies like JSP, Servlets, EJB, JNDI, JDBC, JMS and RMI, CORBA, XML, HTML, Java Beans on IBM Web sphere Application Server.? Installation and configuration of PostgreSQL database on Red Hat/Debian Servers.? Performed Disk management with the help of LVM (Logical Volume Manager).? Configuration and Administration of Apache Web Server and SSL.? Created and maintained network users, user environment, directories, and security.? Provide the support of building the server, patching, user administration tasks, deployment, software installation, performance tuning and troubleshooting and KVM.? Provided 24/7 on call support on Linux Production Servers. Responsible for maintaining security on Red Hat Linux.,""TECHNICAL SKILLS:Operating Systems	Red Hat Linux ES & Centos OS 4.X, 5.X, 6.X & 7.X, Ubuntu 10.X Solaris 9,10, 11, Windows 2K, XP, 2003, NT, 2008, 2012, and 6, AIX 7, HP-UX 11.23OS Administration	Red Hat 5.X 6.X,7.X Linux administration, Solaris 9, 10 AdministrationScripting Tools	bash, Perl, Python, Ruby, Shell, Groovy, javaScheduling Tools	Autosys, crontabApplication servers	WAS 7.X, 8.X JBoss AS 5.x, 6.x, 7.x and JBoss EAP 5.x, 6.xWeb Servers	Apache (httpd), apache-tomcat, and Apache http serverE-Mail servers	Send mail, Postfix, ZimbraMonitoring	Nagios, ZABBIX, Splunk, Datadog, CloudWatchNetworking	DNS, DHCP, TCP/IP, SMTP, LDAPThird Party Tools	Puppet, Chef, Jenkins, Various DevOps Tools, Git, Github, GitLab,stash,svnVirtualization tools   VMware vsphere, ESX 5.x/6.0""";;;
"Sr cloud Engineer Nortal - Kirkland, WAJuly 2018 to Present• Work with strategic customers as an advisory engineer and developer on engineering solutions of significant scale/volume/complexity on GCP, AWS, Azure• Work with customers development and product management teams to transition and operate cloud based workloads• Develop tools to deploy, manage, monitor and troubleshoot cloud based systems• Work with Engineering Teams to deliver feedback and convey gaps observed from customer engagements• Maintain and develop cookbooks in source control to implement declarative configuration where possible for infrastructure to ensure a controlled and consistent environment• Define the implementation phases and work with teams on execution of agreed upon technical solutions and strategies• Continuously develop/improve working practises and tools to achieve high levels of agility without compromising quality• Develop, maintain and provide technical expertise in order to transfer knowledge, information to clients• Mentor and develop junior team members on Cloud TechnologiesSr Windows EngineerPUGET SOUND ENERGYMarch 2018 to July 2018Hired to provide systems engineering and automation expertise to help the internal team with their DC migration. Worked with various app teams to design UCS/VMware infrastructure in the new DC to meet their application needs. Worked with them to migrate their application and troubleshoot any issues that arouse. Created various script in powershell and python to automate the teams daily task. Helped to evaluate their vCenter deployment and help to improve performance. Provided expertise with UCS & UCS Central design and best practices.Sr Systems EngineerEXPEDIAJune 2015 to March 2018Worked on the Cloud and Virtualization team at Expedia supporting Expedia and all it brands and partners. Our primary virtual environment totaled over 35,000 VM running on 10+ VMware vCenters, and 1500 ESXi hypervisors/UCS blades. Worked to support business initiative to reduce data center footprint by either virtualizing, or working with customers to migrate their cloud ready apps to AWS. Support Windows, Linux OS, troubleshooting, performance tuning, hardening. Execute DevOps, CI/CD monitoring processes and procedures for code deployment. Developed self-service automated infrastructure deployment in Python.• Designed, managed, upgrade VMware vCenter ESXi (5.5, 6.0, 6.5) infrastructures running production, Lab, and Corp workloads. Deployed vRA, vRO, vRops, LogInsight. Developed vRO workflows.• Designed, managed, upgrade multiple UCS environment to meet different application network, IOPs, HA, and resource requirements• Architected large Cisco UCS Central deployment for single pain of glass management. Managed hundreds of UCS Chassis, Fabric Interconnects (6248, 6296, 6332-16UP), Cisco UCS B200 M3, M4 Blades, M5 blade.• Develop useful telemetry, alerts, and response to identify and address reliability risks• Identify, experiment and learn new technologies, ideas, and best practices across the broader engineering community• Design, plan, and execute automated deployments into AWS• Worked on GCP App Engine, Compute Engine, Cloud SQL, and Container Enginee to deploy web sites.• Manage the AWS environments and tools, planning for growth of the AWS resource groups, users, roles, policies, and security• Experience developing solutions using automation tools such as Terraform, Ansible, Chef, Puppet, and System Center• Use CloudFormation tool to create AWS infrastructure with JSON and YAML templates• Use AWS services to build a full stack serverless applications, utilizing DynamoDB table as a backing data store for our serverless applications• Collaborate and provide technical leadership within and across teams• Interacts with customers as required to provide technical support and troubleshooting in response to specific customer requests and problems• Work with automation/configuration management tools such as Jenkins, Puppet, Chef, AnsibleSr Systems EngineerHCL AMERICA/DISNEYFebruary 2015 to June 2015Managed the production infrastructure making sure the VMware virtualization platform meets or exceeds organization goals for availability, capacity, efficiency, scalability and performance by engineering reliability into software and systems. Maintain VMware infrastructure health and hygiene. Setup up monitoring, and dashboards. Deployed and upgraded vCenter from 5.5 to 6.0. Worked to improve automated VM delivery self service pipeline using Ansible and Chef. Used Python for Linux scripting and Automation. Configured HP C7000 blade chassis to host ESX. Troubleshoot windows and Linux networking and performance issues.  Configured new GPO policies, and modified existing ones to meet environmental guidelines. Performed administration, deployment, troubleshooting, performance tuning on Linux CentOS, and RedHat servers. Maintained and create Chef cookbooks.Sr Systems EngineerBANK OF AMERICANovember 2014 to February 2015Hired to support client in migration effort from Windows (Wintel) 2003 to 2008&2012, as well as their migration from ESX 5.0 to 5.5. Configured virtual environment to meet or exceed organization goals for availability, capacity, efficiency, scalability and performance by engineering reliability into software and systems. Built configured and troubleshoot multiple windows 2008 & 2012 servers. Adhered to ITIL procedures. Configured multiple HA & DRS enabled ESXi cluster and Data Store clusters. Troubleshoot ESXi purple screen and failed HA and vMotion.  Interact with network and storage team for proper configuration of ESXi host and VDS and Data Stores. Automate Install of ESXi host using Auto Deploy and Host profiles. Configured virtual environment to meet or exceed organization goals for availability, capacity, efficiency, scalability and performance by engineering reliability into software and systems.VMware EngineerIBMJune 2013 to November 2014Supported client virtual infrastructure of over 15,000 virtual servers and 700 host. Led planning, and project update meetings with upper management and PM. Served as an interface to the project team to troubleshoot and identify any sever/performance issues. Build systems to end Client baseline standards. Support the maintenance and troubleshooting of vCenter, ESX environment daily. Perform Change Management tickets and procedure for changes. Plan and design the virtualized environment based on site system needs. Baseline Systems Performance prior to virtualization/relocation. Served as an interface to the site team to troubleshoot and identify any sever/performance issues. Created monitoring of systems for health and hygeine. Deployed, manage, and troubleshoot Windows, and Linux RedHat/CentOS 5&6 servers.• Virtualization Engineering & Management• VMWare Configuration, Troubleshooting• VMWare Automation, Optimization• VMWare Disaster Recovery and High Availability• vCops/vRealize, VUM, DVS• Design & Build vCenter Clusters and Datacenters• VMWare vMotion, DRS, DPM, SRM•Automate VM deployments• Linux RedHat•Linux Redhat and Windows Server support•PowerShell (PowerCLI), Python Scripting for Automation•SAN Planning and Design, V2V, P2VData Center/VMware System AdministratorDEPARTMENT OF VETERAN'S AFFAIR - Orlando, FLFebruary 2012 to June 2013• Support Daily Data Center Operations including server rack mounting, cabling, network switch port failures, documentation• Support and manage EMC NS120 SAN, Netapp SAN with over 500 TB of storage. Worked with Cisco Nexus 5000, 2000 Fiber channel switches.• Participated on a On Call rotation with other members of the team• Supported Solarwinds for enterprise information technology infrastructure management• Worked with various departments and vendors on multiple projects often as a lead, from conception to conclusion• Provided L2 network support and troubleshooting to the Network Admin on multiple occasions.• Worked with various Windows (Wintel) Servers and server roles, including 2003, 2008, 2008r2, 2012. Active Directory, DNS, Web Services, File Services, Print Services, SQL server, Exchange AD integration.• Provide support for many vendor software to support clinical activities.• Supported VMware vCenter ESXi (4.5,5.0) environments.• Plan and design clusters and Datacenters. Design Backup and recovery plan for VMware.• Deployed over 5 VDI using VMware View 5. Troubleshoot connections in View. Create Master images. Created non-persistent & persistent VDI. Deployed and worked with WYSE ThinApp Clients.• VDI deployment in various clinics and hospitals• Capacity planning and design for VMware infrastructure. VM backup using Commvault technology.• Support Commvault Backup solution for use in tape backup, and disk backup. Maintain documentation of ownership of backups, and backup rotation and retention.• Worked with Microsoft SCCM for server patches and updates, Software deployments.• Utilized SCCM for mass Windows 7 upgrade and deploymentNetwork Systems EngineerBAYSHORE TECHNOLOGIES, INC - Orlando, FLOctober 2011 to February 2012Reported to the Senior Engineer on site. Worked in a Citrix environment to install, test, and published applications to users. Configured WYSE Clients for distribution to home users for use in Citrix. Worked in Citrix Delivery Console to publish apps. Supported ESX host supporting virtual test Citrix environment.System AdminVERIZON BUSINESS - Temple Terrace, FLJune 2011 to September 2011IT TechnicianAT&T INC - Orlando, FLApril 2010 to June 2011IT Help Desk ClerkCONNEXTIONS, INC - Orlando, FLAugust 2009 to April 2010,""HIGHLIGHTS OF IT SKILLS? Infrastructure Design? Cisco USC? TCP/IP, DNS, DHCP and Routing? Git, Chef, Ansible, Jenkins, GitLab CI, Github, Bitbucket? Kubernetes, k8s Operators? Linux (CentOS, RedHat)? AWS, GCP, Azure, IaaS/PaaS? Develop CI/CD pipelines? Configuration Management? Windows 2003,2008 R2,2012? PowerShell, Python, Ruby, Bash, Golang? Agile software development? Database Design & Management? Docker, Mesos? VMware vSphere, ESXi, Citrix XenApp, vRealize? Lifelong learner? Time management""";;;
"Cloud Engineer/ Automation Engineer Jackson National Life Insurance - Lansing, MIJanuary 2017 to Present Responsibilities:• Experienced in provisioning, configuring and troubleshooting of various AWS cloud services, EC2, S3, RDS, ELB, EBS, Auto scaling groups, Cloud watch, Cloud Front and managed IAM accounts (with MFA) and IAM policies to meet security audit and compliance requirements.• Designed Architectural Diagrams for different applications before migrating into Amazon cloud for flexibility, cost- effectiveness, reliability, scalability, high-performance and security and migrated applications to AWS and manage applications on cloud.• Configured Elastic Load Balancer (ELB) including high availability of ELB using various subnets in various availability zones and used Amazon Route53 to manage DNS zones and give public DNS names to Elastic Load Balancers IP's.• Created python scripts for completely automating AWS services including build server, deploying EC2 instances on AWS environment and Data centers, Cloud Front Distribution, Elastic Search and managing database security groups on AWS.• Experience in working with Terraform for automating VPCs, ELBs, security groups, SQS queues, S3 buckets, and integrated Terraform with Jenkins and GIT to achieve continuous integration and test automation framework.• Automated the installation of ELK agent with Ansible playbooks and used Ansible to deploy security tools, manage Web applications, Mount points and Packages.• Experience in working with Docker- docker hub, pulling images from docker hub, running containers based on an image, configuration automation using containers and implementation of several Tomcat/WebSphere instances by using the Docker engine for running many containerized application servers.• Used Terraform scripts to automate future AWS service creations like creating subnets, security groups, route tables and tasks such as encrypting S3 buckets and EBS Volumes backing AMIs.• Experience in installation and configuration of Docker environment, including Docker registry hub using a Docker file. Worked on Docker container images, container snapshots removing images, pushing images and managing Docker volumes. Worked in building and maintaining Docker and Vagrant infrastructure in agile environment.• Created and managed Docker deployment pipeline for Continuous Integration and Continuous Deployment to develop environment and Associated Nginx with Docker for load balancing on high scalable environment for maintaining Continuous Delivery.• Worked on deployment automation of all the microservices to pull image from the private Docker registry and deploy to Docker swarm cluster using Ansible and worked on managing Docker swarm mode various tasks, services and load balancing.• Worked on migrating the current application to micro service architecture in which used docker as the container technology with Kubernetes and worked on with REST API and worked on Docker and Kubernetes on cloud to perform CI/CD on public or private cloud.• Experience in Installing and configuring Kubernetes for Orchestration and Cluster Container management (Kubernetes Cluster) on AWS using Kubernetes Operations (KOPS) and Terraform.• Orchestrated Container applications using Open Shift and Kubernetes for container operations in AWS and worked on creation of Kubernetes Pods and used Kubernetes cluster to maintain Services, Load Balancing and Network policies and provided PAAS on public and private cloud in VMware cloud and improved security using Open shift.• Configured Kubernetes to set up a platform for deploy scale, load balance, scale and operations of Docker containers and configuring a deployment pipeline by implementing Docker containerization with multiple name spaced versions.• Worked on Kubernetes control plane to create API objects to maintain the Kubernetes clusters in their desired state and run the applications on them. Creating number of replicas, using Docker container images, setting up the network and resources typically using CLI.• Experience in building secure, highly scalable and flexible systems that can handle expected and unexpected load bursts, and are able to quickly evolve during development iterations and worked on Implementing and testing various EC2 instances to find out the best IOPS boosting instance for databases like MongoDB and Cassandra• Implemented and automated non-relational databases like MongoDB and Cassandra as well as relational databases like MySQL, PostgreSQL and clusters by creating Ansible Playbooks on AWS and AZURE Cloud and on-premise environments.• Extensive experience working on Ansible, configuring and integrating servers with different environment, cloud and on-premise which includes designing and patching and also creating new server replica that contains all the packages and patches for the environment.• Designing and writing code to develop and configure systems which power Splunk Multi-Tenant Architecture in the organization and creating Applications on Splunk to analyze the Big Data and have strong knowledge on Splunk components like indexer, search head, forwarder, index replication and indexer clusters and deployment server.• Created and wrote shell scripts Bash, Ruby, Python and PowerShell for setting up baselines, branching, merging, and automation processes across the environments using SCM tools like GIT, SVN on Linux and windows platforms and wrote troubleshooting python code for Lambda service.• Used Python and Flask microframework for developing RESTful API followed by creating an endpoint that returns static data (dictionaries). Created a class with few specializations and a few endpoints to insert and retrieve instances of these classes and looking on how to run the API on a Docker container.• Implemented AWS solutions using EC2, S3, RDS, EBS, ELB, Auto scaling groups and created python scripts to automate the backup of the EC2 EBS volumes and configured Cronjobs to create the snapshots of the volumes with the AWS API for EC2 Instances storage.• Deployed AWS Elastic MapReduce using Cloud Formation templates by configuring the EC2 instance type to create custom sized VPC, Subnets, NAT to ensure successful deployment of Web applications and database templates and perform data intensive tasks.• Developed end to end build and deployment automation scripts using MAVEN and associating MAVEN plugins to Jenkins and build the artifacts in pom.xml files and pushed the artifacts to nexus associating the plugins in Jenkins followed by deploying it in Tomcat server.• Worked on source control management with GitHub and GitLab Enterprise level repositories including activities like configure user's access levels, monitor logs, identifying merge conflicts and managing master repository and wrote scripts to back up and restore GitHub repositories and experience in doing checkout with Jenkins for continuous integration.• Designed and configured Gerrit above Git for approving changes restricted to selected users other that the owner. Installed and configured Gerrit client for pushing a commit using different submit types to Gerrit.• Created automated tests in Jenkins to revert products thoroughly with each change and performed parallel automated tests which will release the power of Agile Development and helps to find and fix bugs very easily.• Worked on the Migration of the Jenkins server to Amazon Web Services Cloud and moving of the jobs from the Git and Analyze and resolve conflicts related to merging of source code for GIT followed by the code quality analysis using SonarQube and fix bugs.• Experience in working with AWS deployment services such as AWS Cloud Formation, AWS Elastic Beanstalk and Terraform for efficient deployment of application infrastructure and for automating creation of services like VPCs, ELBs, security groups, subnets, EC2 instances, RDS, SQS queues, S3 buckets, and continuing to replace the rest of our infrastructure• Installing and configuring RHEL 6.x/7.x, CentOS and installation of packages and patches for Red Hat Linux Servers.• Worked on configuring fully automated server build management, monitoring and analyzing network traffic and security appliances for identify instructions, discover infection vectors and compromised accounts using Splunk.• Written new plugins in Nagios to monitor Linux Cluster nodes configured using Red Hat Cluster Suite and worked with implementation team to build and engineer servers on Ubuntu and RHEL Linux.DevOps EngineerCerner - Kansas City, MOJune 2015 to December 2016Responsibilities:• Extensive experience working on AWS cloud services such as EC2, auto-scaling and VPC to build secure, highly scalable, and flexible systems that can handle expected and unexpected load bursts and was responsible for process of configuration management of server migrations to various cloud platforms using EC2, RDS, Cloud Watch and Identity and Access Management• Worked on monitoring and maintenance of AppDynamics and Splunk on-premise and in cloud for better performance of the applications which designed to monitor the performance of applications where they belong to.• Experience in implementing AppDynamics into production solving numerous challenges for clients by providing real-time visibility into the performance of applications as well as business analytics that are critical in the current environment.• Strong knowledge in writing scripting languages like Ruby, Perl, Python, Bash and CF Engine and Web Service like AWS, AZURE. Initiating better configuration of automation and allowing smooth flow in the developed features.• Worked under various methodologies for Software Development Life Cycle (SDLC) management like Agile and Waterfall methodologies throughout the project and involved n weekly and daily basis release management.• Developed and designed build plans using Bamboo to clone continuous integration and continuous deployment (CICD) Bitbucket Repository and include ""SONAR"" scan, ""Veracode"" upload and integrating the automation/execution scripts by a deployment pipeline.• Installed, configured and automated build and deployment processes by configuring build automation, deployment automation CICD techniques using different plugins in Jenkins for continuous integration in AWS pipelining.• Experience in installing and configuring Chef-Server Enterprise On-Premise or WorkStation or Bootstrapped the Nodes using Knife and written Chef Cookbooks and recipes to automate system operations. And build management and deployment is done using chef and Maven.• Configured Jenkins as Continuous Integration server to automate continuous Project Builds and ensure a consistently high-quality build which is generated or performed in periodic schedules.• Installed and configured an automated tool puppet that included the installation and configuration of the puppet master, agent nodes and an admin control workstation. Hands-on experience in writing custom puppet modules for managing different servers and in using Tomcat and Apache webservers for deployment and for hosting tools.• Responsible for creating puppet modules and Manifest files from scratch and experience in editing existing puppet manifests and automated manual installation processes using puppet Also designed and implemented fully automated server build management, monitoring and deployment By Using DevOps Technology with Puppet.• Installed/Configured/Managed Puppet for the automation of Configuration management & Applications. Created Puppet manifests, modules, downloaded pre-written modules from puppet-forge, profiles and roles module to automated system operations and deployed to different servers.• Deployed puppet, puppet master server, puppet dashboard and Puppet DB for configuration management to existing infrastructure. And creating puppet modules and push it to puppet clients.• Proficient in developing web services like SOAP & REST APIs, in python using XML, JSON data formats, Swagger. Designed a set of REST API'S that allows cloud-based device to dynamic register to management server• Experience in configuring Chef Cookbooks for installation of JBOSS, WebLogic, WebSphere Tomcat and Nginx for configuring load balancers for applications with unexpected load bursts.• Automated the Installations of various Web-Servers (Apache HTTPD), Application Servers (Tomcat, WebLogic, WebSphere) and Database Servers (MySQL, MongoDB) using the Configuration management tools like Puppet and developed Configuration Management using puppet for automation and consist configuration and application deployments.• Developed and managed Puppet manifests associating with Operations Team to deal with automation of application installations to various servers and related configuration files.• Worked on configuring Atlassian Tools like JIRA, Bamboo, Crucible, Bitbucket, Fisheye and created projects by Integrating these tools for a streamlined Agile Workflow and Project Collaboration.• Managed users, groups and permissions, configured LDAP and given sudo access in test and development servers. Allowed password less logins for authorized users on servers and great knowledge in administrating DHCP, DNS and NFS services in Linux.• Developed automated processes that run in specific intervals to check disk usage and perform cleanup of file systems on UNIX environments using shell scripting and Cronjob.• Worked on Writing and maintaining scripts, Maintaining Linux servers and firewalls for the security and responsible for doing software upgrades on Juniper routers and switches.• Using Nagios and Splunk, reviewed entire environment and execute initiatives to reduce failures, and improve overall performance, and expand monitoring capabilities.Build and release engineer/ VMware AdministratorFidelity Investments - Durham, NCAugust 2013 to May 2015Responsibilities:• Experience in working on the Project Migrations from TFS 2008 to TFS 2010. TFS Administration, Build and Deployment script generation, performed labeling, Branching, merging and created new build types in TFS, assigned user security levels based on their designation.• Configured and maintained GIT source code tool and created branches, tags and merging in GIT repository and associated it with Jenkins which is a continuous integration server and performed periodic schedules.• Worked on troubleshooting and resolving of build and deployment issues and successfully delivered all builds as decided using tools like MAVEN, ANT, Gradle.• Experience in managing multiple corporate applications into Tortoise SVN and GIT and provided end-users training for all Tortoise SVN, JIRA users to effectively use the tool.• Expertise in working on MAVEN as a build tool on Java applications to develop artifacts which will be saved in Nexus repository by associating the plugins with Jenkins.• Hands-on experienced in working with different applications and application servers, deployed the artifacts from Nexus to Apache Tomcat, JBOSS and WebSphere application servers and Internet Information Services.• Installing and configuring Anthill Pro for providing a complete automation solution and automatic deployment. Build Results are managed in Anthill Pro and deployed using workflows in Anthill Pro.• Coordinated developers with establishing and applying appropriate branching, labeling conventions using GIT source control and Configured Jenkins for doing the build in all the non-production and production environments. Worked extensively on CVS, Subversion as Version Control.• Hands-on experience in designing and running Jenkins CI/CD Pipelines for continuous build and deployment, Installed and administered SVN repository and created roles and privileges to restrict access to the users.• Wrote Python, Perl and Shell scripts for deployments to WebSphere and WebLogic Application servers. Automated creating projects in Jenkins and Nexus repository as release process.• Troubleshooted and successfully resolved LDAP, Site Minder and WAS issues, problem-tickets, worked with developers to identify the root cause and resolve the issue or propose a potential work around.• Deployed application EARs on WebSphere Application Server Network Deployment in QA, Pre-Production and Production environments daily and troubleshoot various configuration and application issues.• Successfully Configured JDBC drivers and Data sources for application servers to test the application against various relational and non-relational databases and was responsible for upgrading the JDBC drivers.• Worked closely with the demands of the Clients and provided consultation by performing POC and setup the Build, Release and Deployment and Release Management and performed Risk analysis, prepared Mitigation strategies & Contingency plans according to the demand.• Worked very close with the development team to review code for compatibility issues, troubleshoot and resolve issues and implement deployment processes and improvements on a continuous and periodic basis.• Worked on VMware ESXi 5.1, 5.5 and 6.0, migration from Physical to Virtual machines and Managing SAN Data stores with iSCSI, NFS. Involved in Migration of VMware to AWS using VMDK Import tools.• Successfully configured and maintained multiple Hyper-V servers with multiple platforms including Windows Server 2012 R2, Windows Server 2008-r2/2012-r2/2016 and Linux servers like RHEL, CentOS• Installation and Configuration of networks, router configuration and wireless router with security, TCP/IP, VPN, Content Filtering, Access Control Lists on router and switches, VLANs (port mapping, naming etc.), and routing IP address in both LAN/WAN and wireless networks.)• Worked in Configuration and Management of vSphere High Availability, VMotion, VAAI, Host Profiles, Network & Storage IO Control, VMFS, Storage Profiles, Resource Utilization, Contention Management and Advanced Performance troubleshooting• Monitored virtual infrastructure by using a DRS and HA cluster. That cluster will pool (and load-balance, to some degree) CPU and memory from all ESXi servers in the cluster. Once placed in a cluster and monitored on cluster memory and CPU utilization.• Used VMware VMotion to eliminate application downtime from planned server maintenance by migrating running virtual machines between hosts.• Experience in performance tuning of VMWare servers and Virtual sessions and management of server's resources between virtual machines.• Experience in Linux OS installation, Software and Patch management and Volume Manager Administration Network OS / SW installation.• Experience in migration activities of Java scripts and Database scripts from Oracle, MS SQL Server and MYSQL into different environments like Development, QA, UAT and Production on Red Hat Enterprise Linux.Systems EngineerOnezero Infotech, Kerala - INMarch 2010 to May 2013Responsibilities:• Responsible for Installation, configuration, Maintenance, Deployments, Update, Monitoring, performance tuning on Linux and experienced in monitoring and debug performance issues on different OS Linux like RHEL and CentOS.• Involved in setting up and configuring Install Server, Configuration Server & Boot Server using PXE booting for Kickstart process & performed Kickstart to install OS on Linux boxes.• Created server profile and managed Network and virtual SAN configuration using Virtual Connect in blade center C7000.• Installed/Configured Red Hat Linux Cluster 5.x version & configured the cluster resources and added storage to cluster disks and decreasing or increasing the disks in the Linux server.• Created groups, created login IDs for large number of servers, added Users ID to a group as a primary or secondary group, removing Users ID from a group as well as adding users in Sudoers file.• Installed, configured and managed ESXi servers using the Vsphere client and Vcenter for managing the multiple ESXi servers• Configured SAN storage on ESXi servers and assigned the LUNs to the virtual machines running on the ESXi hosts.• Upgraded RedHat Linux and Ubuntu on various Servers and workstations. Added necessary patches using patch add utility and scripts. Creating the filesystems using RedHat volume manager and performing the health check on regular basis for all Linux serves. Designed, built, and used python and bash scripts for Active Directory (AD)• Created filesystems using Red Hat volume manager and performed health checks on a regular basis for all the Linux servers and added storage to the cluster disks and managed the filesystem size in RHEL.• Monitoring CPU, memory, iSCSI disks, disk controllers, physical disk, HW and SW RAID, multipath, file systems, network using the tools NAGIOS and BMC Tools.• Experience in implementing and configuring of Volume Management by using Veritas Volume Manager (VxVM), Solaris Volume Manager (SVM) using mirroring the root volume group, and Logical Volume Manager (LVM) with various RAIDS in LINUX.• Created and modified swap files and added swap space and configured RAID levels using volume manager.• Worked on hard disk mirroring and stripe with parity using RAID controllers on RedHat and Solaris servers. Resolved configuration issues and problems related to OS, NFS mounts, LDAP user ids DNS and issues.• Built the RPM packages and updated the RedHat package manager as well as YUM repository and Performed installation, configuration, upgrades, Package administration and support for Linux systems on client side using RPM and YUM.• System administration support involving server build, installation, configuration and implementation on Linux flavours and Solaris and AIX servers. Worked on Disk Partition, mirroring root disk drive, configuring device groups in UNIX/LINUX environment.• Set up and configure small private and corporate network operation systems and infrastructure including servers, routing, switching, DHCP, and DNS. Maintain alerting system regarding network concerns and outages.• Developed Cronjobs and Bash, Shell Scripts for automating administration tasks like file system management, process management, backup and restore.• Performed FTP, SFTP, VSFTP installation and SSH key password less configuration, OS upgrade, Kernel upgrade, SAN stack upgrade, Vulnerability Threat Management patching.,""TECHNICAL SKILLS:Operating Systems	RHEL/CentOS 5.x/6.x/7, Ubuntu/Debian/Fedora, Sun Solaris 7/8/9/10, Windows Server 2008-r2/2012-r2/2016Build/Automation Tools	Ansible, Puppet, Chef, Ant, Maven, Jenkins, Hudson, Team City & BambooLanguages	Shell, Bash, Ruby and Python scriptingDatabases	MySql, MongoDB, Cassandra, PostgreSQL, SQL ServerWeb/App Server	Apache, IIS, HIS, Tomcat, WebSphere, WebLogic, JBossBug Tracking Tools	JIRA, Fisheye, Crucible, Rally, Remedy and IBM Clear Quest, Bugzilla, HP Quality Center.Version Control Tools	Subversion, GIT, Tortoise CVS, Visual SVN, IBM Clear Case, PerforceWeb/Technologies/Programing Languages   Servlets, JDBC, JSP, XML, HTML, .Net, Java Script, Java/J2EE, C, C++, Ruby, Perl scripting, Python, Shell scripting.Cloud technologiesAWS EC2, VPC, EBS, AMI, SNS, RDS, Aurora, Redshift, EBS, CloudWatch, Cloud Formation AWS Config, S3, Lambda, Cloud Trail, IAM. VMw, Azure.""";;;
"Cloud Solution Architect Camelot IT services - Newark, NJPresent Current Project from Sept 2018  Johnson & Johnson IT Services – Rarita, New Jersey Role – VPCx Cloud Architect  Project Scope of Work - J&J has multi Cloud Setup of Azure, AWS, and Google, I work Closely with Engineering Team, DevOps and Support Team for new Implementation, POC and Customer Meeting and escalation. I am also responsible for working on Migration of Server, application architecture and deployment in cloud environments. Cost analysis and Cloud Compliance.And more specific on Microsoft Azure, I have given my Blue Prints for new subscription /Accounts Management for end user and also involve in escalation and work with L3 Support engineer in case of any downtime and for all migration.I Manage pool of Engineer and Support Teams across multiple time Zone for Johnson & Johnson Client Support.Cloud ArchitectMicroexcel Inc - India -USAJanuary 2015 to April 2016Deliverable responsibilities include: High Level Architectural Design, Detailed Architectural Design, Implementation Plan, and process flow, Build Guides, Use Cases, Decision Tree diagrams and Operational Run Guides.Migration of Domain from windows Server 2003 to Server 2012 r2, and DNS Migration from Infoblox to Windows, with a team size of 25 Engineers.Migration of On Premises SQl Serve to Azure PAAS and Migration of Infra from Amazon Ec2 to Azure.With a team Size of 8 EngineerManager ITRunaware Software Pvt. Ltd - Hyderabad, TelanganaJune 2007 to November 2014Highlights:•    Demonstrated excellence in setting-up and delivering Cloud Data Centre for Clients and Lab/UAT Private Cloud Setup Firewall, StorageMgmt., and Network Planning for Private Cloud Setup.•    Handled the procurement of Hardware Software HP, DEL BL /DL and Storage Severs, etc.•    Holds the distinction of handling the Amazon EC2 and Tata Insta Connect Environments for our POC Projects•    Pivotal in planning installation and managing Windows Sever, Citrix App Server, Xen Server for Tab/UAT and Production Environment•    Established the POC environment for the clients in order to cater Saas Platform and Test drive of our product Mos in an effective manner•    Deftly involved in establishing Cloud Data Center in Amazon EC2 for the Saas Product and established complete network for variousdepartment of the Test Team•    Visited USA, London, Sweden for setting up of a Data center and remotely built Hong Kong DC using Rack Space.•    Imparted training to the Interns, New Joiners on our Data Centers / Virtualizations, Project related KTs.•    Pivotal in complete establishment of the present office infrastructure involving set up of data centers, etc.)Wintel EngineerCSC-Computer Science Corporation - Hyderabad, TelanganaJune 2006 to June 2007Highlights:•    Demonstrated excellence in supporting back office servers•    Steered the busy helpdesk & IT team providing support at the Head Office location together with remotely supporting 15 regionalbusiness located throughout England, USAPrevious ExperiencePune as IIS Web Server AdminEDS - Pune, MaharashtraSeptember 2005 to May 2007Sys & Network AdminYeshasvi Venture Services - Hyderabad, TelanganaJanuary 2004 to August 2005Sys AdminInfoneeds India Ltd - Hyderabad, TelanganaJuly 2001 to December 2003Ecommerce Portal AdminSri Jagdamba Pearls Dealer - Hyderabad, TelanganaDecember 2000 to June 2001,""Technical skills•     Virtualization Technologies o Microsoft Hyper V 2012,o Citrix Xen Servers Citrix DDC o      VMware o Azure o Amazon EC2 o Rack Space•     Management & Maintenance of Microsoft Server Operating Systems:o Microsoft Windows 2012R2 o Windows Server 2003 o Windows Servers 2008 R2 including o Active Directory, DNS and DHCPExchange Server 2007and 2010 Setup and Administration with remote access services Outlook Web Access & Outlook MobileAccessWindows SUS for Patch Management of ServerISA Server for Production and Test Beds o Managing MicrosoftVolume License MSDN, Microsoft Open Volume Licenses, KMS andMAC licenses/Servers Management Management of GenuineLicenses companywide Supporting Microsoft DesktopApplications: o Office Professional o Microsoft ProjectProfessional, o VISIO Professional, o MS Groove for HR and AdminTeams o Windows XP Vista & Windows 7•     Using Symantec AV and Packet Trap Utilities to manage remote systems & fault diagnostics in Data Centres and Dev TeamSecurity backup provision using Acronis Image Backups.•     Setup of different Network with Different Subnet for Test teams Corporate Security managed using Netasq IPS / Firewall/Router•     Worked on setting up of Cluster Server and NLBs for SQL DB Servers and Web Servers.•     SAN and NAS Storages for Citrix Xen Servers, VMware and Cluster Environment•     Worked Supported Product Dev Team by Installing Managing and providing Support to Source Control Server -Visual Studio TeamFoundation Server 2008 and 2010•     Used Visual Studio Team Explore as Project Management Tool•     Installed configured Share Point servers WSS 3.0S02 MOSS 2007 for Team Management and In house Office Management and DataCentreRequest Change Management and Test Lab /UAT Private Cloud Management""";;;
"Data Scientist MySupplier - Atlanta, GAJanuary 2018 to PresentDescription: MySupplier provides alternative solutions and global design services for sustainable lighting (LED) solutions to ESCO's and Lighting Contractors. Worked as a Data scientist and utilized various machine learning/statistical algorithms to identify the specific variables affecting sales and set up an implementation plan for future sales quarters to boost up product sales.Responsibilities:? Identified KPI's by creating and customizing models.? Modified processes for accurate data capture across all clients. Obtained key insights to certain business objectives through statistical hypothesis.? Data analysis utilizing SAS to diagnose areas of improvement and increase efficiency.? Utilized Boosted Decision Tree and Bayesian Machine Learning models.? Helped in customer segmentation, product recommendation and allocation planning through predictive models.? Utilized SAS guide for data manipulation, cleaning, modelling and extraction.? Assisted marketing research team by applying various statistical algorithms like logistic regressions, decision trees and NBD on the LED purchase datasets to gain valuable insights.? Reduced the data dimensions and identified KPI's through P-value analysis and correlation resulting in increased sales by 25%.? Utilized Classification and clustering algorithms for textual analytics.? Designed dashboards in Tableau for sales managers to provide them access to key business metrics such as - time to close opportunity and delay-to-contract.? IoT implementation research on sensors and actuator linked with LED's, IoT architecture, Edge Technology, data centric IoT infrastructure, types LED applicable sensors and their functionalities and different IoT sensor manufacturers.Data ScientistSuwanee, GAOctober 2016 to November 2017Description: N4mative is an analytics, sciences and artificial intelligence based organization that offers digital transformation and business solutions to transform customer experience with data. Worked as a Data scientist to provide statistical solutions to their industrial problems, helped boost up revenue through supervised machine learning algorithms and also decreased labor costs through categorical segmentation.Responsibilities:? Predictive analysis of credit scoring - predicting the likeliness of profit or loss based on the decision to extend credit to a new client.? Extraction of data utilizing SQL queries and then data analysis utilizing R.? Exploratory data analysis, handling missing data, data wrangling, feature scaling, outlier analysis and development of algorithms in R.? Used R programming language to graphically analyses the data and perform data mining.? Utilized supervised machine learning algorithms like linear and logistic regressions, random forests, decision tree, SVM and implemented parameters like R-squared and Adjusted R-squared residual splits and misclassification rates to select the champion model.? Analyzed financial accounts and statements - Income Statement, Cash Flows and Balance Sheets of several organizations to recommend retail investors.? Utilized Excel for data pre-processing (Pivot Tables, VLookup etc.) and created ANOVA sheets, regressions and performed hypothesis testing using the data analysis add-on in Excel.? Implemented the exponential gamma model to help predict year-end sales.? Helped improvise decision making on sector growth, company forecasts, assessment of risk factors etc. through insights derived from statistical modelling.? Utilized Tableau to create dashboards and publish visualizations to provide the management with an overall understanding of resource optimization, attaining incremental revenue worth $1.2 million.? Prepared Equity Research and Quarterly Earnings reports for companies under assigned sectors.? Developed category segmentation using R which provides customizable view of market share and led to decreased labor cost.Data ScientistRed House - Alpharetta, GAAugust 2015 to September 2016Description: Red House helps clients achieve results through strategic planning, account-based marketing and content marketing, as well as services such as automation support, content development, creative and analytics. Worked as a Data Scientist help effectively improve the marketing insights and segment targeting for many clients. Utilized various machine learning algorithms to deliver visualized insights about plan of action and existing structure of the market.Responsibilities:? Provided assistance throughout the analytics project lifecycle - data extraction, design and implementation of scalable machine learning algorithms and documentation of the results.? Created rates utilizing statistical analysis which helped determine peak and off-peak time period for sales.? Customer data analysis for further modifying and designing the rates.? Identified root causes of problems and facilitated the implementation of cost-effective solutions with all levels of management.? Implementation of various statistical modelling algorithms like decision trees, linear and logistic regression models, clustering (K means), SVM in SAS. Worked on various data formats.? Also experimented with other algorithms like Random Forests and Principle Component Analysis.? Helped integrate the effort both technical and non-technical resources across the business.? Created word clouds and retrieved data from social networking platforms for text analytics.? Pro-actively analyze data to uncover insights that increase business value and impact.? Provided support for a wide range of analytics projects from ad-hoc requests to large-scale cross-functional engagements.? Prepared Tableau reports for the management team meetings.? Tackled all analytical problems and uncertainty with a good balance of statistical understanding and practical business intuition.Data Scientist (Insights and Analytics)Dallas, TXMay 2014 to June 2015Description: Golin is an organization with a new, progressive form of public relations to reach a profoundly diverse global market. Our approach aligns earned-first, data-driven creative with the customer journey, to deliver maximum impact for our clients. Worked on many PR projects gathering market insights through various machine learning algorithms, maintaining data lineage through SQL queries and helped backtrack errors in data gathering through effective data manipulation. Provided effective insights for certain marketing campaigns based on sample data derived insights. Dealt with data integration and model comparison to effectively identify the demographic segment parameters.Responsibilities:? Reviewed business requirements and analyzed data sources form Excel and SQL Server for design, development, testing, and production rollover of reporting and analysis projects within Tableau Desktop.? Utilized SQL query skills in analyzing and validating the central database processes.? Managed?  the database utilizing SQL to execute queries against large data sets to generate lead lists for new and recurring marketing campaigns.? Utilized Online Analytical Process (OLAP) for day to day basis operation and analysis.? Identify data elements from the source systems, performed data analysis to come up with data cleansing and integration rules.? Performed user acceptance and parallel testing for coding and pricing.? Designed and developed Use Cases, Class Diagrams, Activity Diagrams, Sequence Diagrams and End to End Scenarios using UML.? Handled change request and change management and project managementData AnalystSunoco - Dallas, TXMay 2013 to April 2014Description: Sunoco is a master limited partnership that distributes motor and racing fuels to convenience stores, independent dealers, commercial customers, and distributors located in more than 30 states. Worked as a Data analyst and ran ANNOVA based error tests, experimented with different statistical distributions and basic regression analysis with the automotive industry data. Basic database management utilizing SQL queries for data management and data transfer. Created status reports and delivered action plans.Responsibilities:? Worked as a Data Analyst and performed requirements gathering, business analysis and ensured project coordination.? Collaborated with the Data Analysis team and gathered Data Profiling information? Handled the responsibility for the analysis of business requirements and design implementation of the business solution.? Data Analysis and Data validation through execution of SQL queries.? Worked on Data Mining and data validation to ensure the accuracy of the data.? Detailed data analysis to identify the key facts and dimensions necessary to support the business requirements.? Created action plans to track identified open issues and action items related to the project.? Prepared analytical and status reports and updated the project plan as requiredBusiness Data AnalystMaruti Suzuki India LtdJanuary 2011 to March 2013Description: A subsidiary of Suzuki Motor Corporation, Japan, is India's largest passenger car maker. Worked on the marketing campaign for an automotive vehicle and created a plan of action based on customer feedback data analysis. Also helped with data management issues utilizing SQL for the LMS training system for workers. Also helped track traffic on training video feeds to figure out parameters affecting worker engagement.Responsibilities:? Enabled data reading from various data sources and constituted them into a single CSV file while also updating the content in the database tables, all through developed R programs.? Utilized complex SQL queries with inner and outer joins to retrieve data from multiple tables and create monthly and quarterly reports.? Worked on customer feedback data for automotive vehicles? Utilized SAS Enterprise Miner to run statistical regressions on the data and compare results.? Generated insights on the customer feedback to prepare a marketing plan for a new automotive vehicle? Assisted the groundwork for the ad campaign of the new automotive vehicle? Helped design straight forward visualizations utilizing Tableau and published the dashboards on web and desktop platforms.,""TECHNICAL SKILLS:DATA MODELLING ALGORITHMSNBD, Exponential Gamma, SBG, Poisson, Decision Trees, Linear and Logistic Regressions, Random Forests, SVM, Naive Bayes, Text Mining Bagging & Clustering AnalysisDATA MINING TOOLS   MS Excel, R, SAS Enterprise Miner, Tableau, Rapid Miner, Google Analytics, Google AdWords and MS-SQL ServerPROGRAMMING	SQL, SAS, R, Python, Basic Java C and C++SOFTWARE	SQL Server Management Studio, MS Word, MS PowerPoint, ERWin, Lucid Charts, Visual Paradigm and MS ProjectREPORTING TOOLS	Tableau (Desktop and Server), MS-Excel and SAS BI PlatformMETHODOLOGIES	System Development Life Cycle (SDLC), Agile, Waterfall Model.""";;;
"Data Scientist RELI, IncJuly 2018 to PresentData Scientist responsible for key aspects of operational analytics pertaining to RELI's role as a CMS Risk-Adjustment Data Validation (RADV) consulting contractor. Product development consultant for reporting and analysis proposals. CMS proposal response writer for RELI's responses to data architecture, data science and advanced analytics TO responses.Senior Consultant, Healthcared-wiseData Analytics ConsultantJanuary 2018 to July 2018playing key role in team responsible for building provider web portal, to measure and visualize provider performance as measured by patient health gaps, quality outcome benchmarks, enrollment patterns, and financial performance; for a major Blues plan in the Northeast US. Role includes extensive development in the SAS and JavaScript programming languages.Manager, Corporate AnalyticsInformaticsJuly 2017 to December 2017Data Scientist responsible for measuring, analyzing, understanding, predicting and communicating all key findings related to patient health measurement outcomes and associated costs, for Major Mid-Atlantic Health system associated with one of Maryland's largest Hospital networks.Work included quarterly reporting of primary care outcome measures to Health System's Joint Operating Committee, extensive role in forecasting provider financial performance and incentive target results by group practice, payer and care categories including Risk Adjustment factoring and Medical and RX IBNR estimation across a variety of contractual assumptions; as well as lead in developing Population Health Management COPD and opioid patient program evaluation studies.Senior Consultant/Decision Science AnalystDecision Science PracticeSeptember 2012 to July 2017Responsible for end-to-end project management as well as analytic and technical work for advanced analytics and statistical consulting engagements in US industry, including statement of work language, RFP responses, project documentation and sub-contractor onboarding, as well as the analytic and technical functions such as model building and validation, model programming code (primarily in R, Python and SAS), data visualization (primarily with R and SAP Lumira), machine learning algorithm selection and implementation, forecasting methods, queuing theory models, fraud detection modeling, database implementation of predictive models, and communication of results to C-level executives.Experienced user of SAS, R/RStudio, Python Statistical and Data Science applications; Microsoft Azure; and SAP HANA Cloud, SAP Predictive Analytics software, and related SAP products and services.Projects and results include:• Led and managed the building of a predictive model applied within a large hospital system database, which accurately predicted readmission likelihood for patients, enabling measurably more efficient patient aftercare resource allocation.• Co-developed a predictive model of disability claim allowance likelihood, and discovered Social Security Administration disability claimant appeal resolution time and case outcome drivers. Used the scored predictions to design priority queuing system built from the scored predictions, with estimated reduced claimant wait times, allowing processing of over 100,000 more cases per year.• Co-developed operational prototype to calculate a patient health score, i.e., a credit score-like measure of member's health, for one of the 3 largest health insurers in the US. The new approach proved many times faster than prior method of calculation, and allowed the client to being making the calculation in-house for the first time.• Developed end-to-end customer churn analytics environment for one of the largest satellite internet service providers in the US. This work generated a variety of actionable insights into customer and competitive data, resulting in the customer reaching their annual churn reduction goal in the 1st quarter of the year, and creating bottom line impact to revenue growth.• Various roles: mentorship of  CTL-Cognilytics' global analytics team in Gurgaon, India, including software demonstration webinars and co-authorship of analytics software training materials; creation of use case demonstrations of SAP's Predictive Analytics product for large corporations in the Health Care, Telecommunications and Oil and Gas industries.ManagerInovalon, IncApril 2011 to June 2012Actions, skills and results include:• Developed innovative method to estimate actionable in-year Medicare CMS STAR rating measure rates for major national health plans.• Evaluated and analyzed health outcomes program effectiveness and financial impact to our customers of Inovalon Disease Management products• Improved existing IBNR calculation methodology by creating innovative method directly leading to renewal of a large account• Innovations in data integrity analysis and sales commission modelsDecision Support ConsultantHighmark, IncMay 2000 to April 2011Actions, skills and results include:• Research and Analysis including:? mortality predictive modeling, 'Senior' member unreported morbidity identification regression analysis? matched cohort studies of health impact of Highmark Wellness program and dental coverage? elasticity of Pharmaceutical demand calculation? assisting in the development of a regression model used in the online marketing of Highmark's commercial products for senior members• Financial/Actuarial reporting: SAS programming logic and calculation, and report generation of client financial results, including ROI and trend reduction, for financial performance guarantees created for Highmark's chronically ill patient management program.• Act as lead for departmental projects and consultant to co-workers for SAS programming and statistical analysis.Information Project ManagerBlue Cross Blue Shield of TennesseeJune 1994 to May 2000Actions, skills and results include:• Research and Analysis including: economic analysis of TennCare, Tennessee's statewide Medicaid population• Financial/Actuarial reporting: All calculations for BCBST's annual accreditation Sentinel and Cost and Utilization reports,""Specialties - Healthcare Industry:• Population Health Management- network, provider, patient and facility analytics• Financial forecasting, actuarial trend analysis and consulting for US Health Care Payers• Hospital readmission predictive models implemented in a 12-Facility US hospital system• Analysis of the economic and chronic disease management aspects of the US Medicare population's health trends• Detailed RFP written responses for many large-scale analytics projects at the Private, State and Federal (CMS) levels.Specialties - Other Industries:• Queuing Theory Optimization Methods and Models in the U.S. Social Security Disability Appeals Judicial System• Telecom-Banking fraud detection algorithms• Retail sales advanced analytics forecasting models• Customer sentiment natural language models• Customer churn predictive models• Vehicle fleet management predictive maintenance models""";;;
"Freelance Data Scientist Data Science June 2017 to PresentI Worked with machine learning algorithms to creative predictive models about given data sets. I also managed queries and edited and cleaned Data using SQL and mapreduce.,""SkillsData Management Systems: MySQL, Excel advanced Programming: Java, Python, C++Fluent in all languages Machine Learning Algorithms: Decision trees,Classification, Clustering, and Regression.advanced Strategy and Algorithms: Mapreduce,Unified Modification Language (UML) advanced Soft Skills: Communication and writingAdvanced""";;;
"Data Scientist Telligen TechMarch 2018 to Present• Worked as Data Scientist and used predictive modeling, statistics, Machine Learning, Data Mining, and other aspects of data analytics techniques to collect, explore, and extract insights from structured and unstructured data • Prepared large volumes of structured and unstructured data performed quality checks, cleaning and preprocessing, and performed ETL with Hadoop, Impala, Hive and Pig on HDFS and SQL Server.• Used Spark for test data analytics using MLLib and Analyzed the performance to identify bottlenecks.• Utilized machine learning algorithms such as linear regression, multivariate regression, Naive Bayes, Random Forests, K-means, & KNN for data analysis.• Developed MapReduce/Spark modules for machine learning & predictive analytics in Hadoop on AWS • Implemented end-to-end systems for Data Analytics, Data Automation and integrated with custom visualization tools using R, Mahout, Hadoop and MongoDB.• Advanced Text analytics using Deep learning techniques such as Convolutional neural networks to determine the sentiment of texts.• Accomplished multiple tasks from collecting data to organizing data and interpreting statistical information.• Evaluate the performance of various algorithms/models/strategies based on the real-world data sets.• Interacted with the other departments to understand and identify data needs and requirements and work with other members of the IT organization to deliver data visualization and reporting solutions to address those needs.• Worked on enhancements on PIG Scripts to include more Topics and creation of Pig UDFs to process User Cookies Data.• Performed Exploratory Data Analysis and Data Visualizations using Tableau.Environment - Python 3.3, scipy, Pandas, AWS, Apache Spark, Hadoop, R Studio, SVN, Linux, Eclipse, Shell Scripting, Pig, MySQL, Hive, Impala, Mahout, Tableau.Machine Learning EngineerSoftrams, LeesburgAugust 2016 to February 2018• Performed Data Profiling to learn about user behavior and merged data from multiple data sources.• Performed K-means clustering, Logistic regression, Random forest, Decision Tree, Naive Bias, PCA and Support Vector Machines in Python and R.• Worked on different data formats such as JSON, XML and performed machine learning algorithms in R and Python.• Used pandas, numpy, seaborn, scipy, matplotlib, scikit-learn, NLTK in Python for developing various machine learning algorithms.• Used k-Fold cross validation to evaluate the bank Neural Network. While it turned out to be a low bias, low variance model, its mean accuracy of 83% still left room for improvement.• Grid Search was then used to automate hyperparameter tuning for the bank model. I evaluated performance using different combinations of the parameters used to compile and train the model like optimization function, loss function, batch size, and number of epochs. Accuracy was elevated to 86% while maintaining low bias and low variance.• The RNN accurately predicts the direction the stock price is going, i.e whether it's rising or falling, while also appropriately smoothing out sharp spikes in price, but predictions tend to come in below real-world values. So, I'm currently using Grid Search for hyperparameter tuning to minimize the Root Mean Square Error (RMSE).• Worked on Business forecasting, segmentation analysis and Data mining.• Performed time series analysis using ARIMA model • Worked on R packages to interface with Caffe Deep Learning Framework.• Data Story teller, Mining Data from different Data Source such as SQL Server, Oracle, Cube Database, Web Analytics and Business Object.• Carried out segmentation, conjoint analysis, building predictive models, social network analysis, and integrating secondary and primary data using R and SQL.• Performed time series analysis using Tableau.• Maintain version control of code using GithubEnvironment - Python 3.3, scipy, Pandas, scikit-learn, matplotlib, R Studio, SVN, SQL, Tableau, Oracle, Github.Data Analyst/Data ScientistInautix - New York, NYMarch 2014 to July 2016• Performed data extraction, aggregation, log analysis on real time data using Spark Streaming • Prepare Data Model according to business requirements.• Deployed different predictive models using python Scikit-Learn python framework.• Improved statistical model performance by using leaning curves, feature selection methods and regularization.• Implemented Principal Component Analysis and Liner Discriminate Analysis.• Worked on commercial data from desperate source systems, built data models and transformed data to provide added value in IT applications by streamlining processes, reducing cost, maximizing profits & rolling out business solutions that met one of the objectives.• Wrote simple and advanced SQL queries and scripts to create standard and ad hoc reports for senior managers.• Perform validation on machine learning output from R.• Created models for time-series forecasting, multi-variate analysis, optimizer design and simulation using E-views and R platform.• Eliminate incomplete or unusable data.• Performed Exploratory Data Analysis and Data Visualizations using R, and Tableau.Environment - Python, scipy, Pandas, R Studio, Tableau, SQL, scikit-learn, matplotlib, numpy.Data AnalystIssuetrack, VirginiaFebruary 2013 to February 2014• Responsible for data identification, collection, exploration & cleaning for modeling, participate in model development • Conducted data analyses for company-level predictive models on key performance indicators cross-sectional analysis, industry/macro indicators, customer segmentations and customer cohort analysis by using Python.• Implemented a job which leads an electronic medical record, extract data into Oracle Database and generate an output.• Parsed data, producing concise conclusions from raw data in a clean, well-structured and easily maintainable format. Developed clustering models for customer segmentation using Python.• Created dynamic linear models to perform trend analysis on customer transactional data in Python.• Designed, implemented and automated modeling and analysis procedures on existing and experimentally created data.• Involved with Data Analysis primarily Identifying Data Sets, Source Data, Source Meta Data, Data Definitions and Data Formats.• Used Hive to store data and perform data cleaning for huge datasets.• Extracted data from SQL servers (Oracle SQL) in Excel format.• Analyze the data and provide the insights about the customers using Tableau.Environment - Python 3.3, scipy, Pandas, R Studio, SQL, Oracle, Tableau, matplotlib, numpy.Python DeveloperCenvien Technologies - Hyderabad, TelanganaAugust 2012 to January 2013• Programming in python using libraries like scipy, numpy, pandas.• Performing estimation and requirement analysis for the project timelines.• Generated PDF reports daily using Aspose PDF kit.• Generating property list applications using python.• Designing SQL procedures and Linux shell script for import/export and converting data.• Written SQL queries, store procedures and triggers for MYSQL databases.• Coordinate architects and senior technical staff to identify client's needs and document assumptions.• Building new requirements to move code through user acceptance testing.• Analyze the data and provide the insights about the customers using Tableau and Power BI.Environment - Python 3.3, scipy, Pandas, SQL, numpy, Linux, Tableau, Power BI.SQL DeveloperFactset - Hyderabad, TelanganaFebruary 2012 to July 2012• Developed and designed forms using visual basic with ODBC.• Involved in Creation of database access layer using JDBC and PL/SQL stored procedures.• Developed transformations using jobs like Filter, Join, Lookup, Merge, Hashed file, Aggregator, Transformer and Dataset.• Used MS Excel, MS Access and SQL to write and run various queries.• Recommended structural changes and enhancements to systems and databases.• Worked in dimensional modeling to design the data warehouse.• Created functions, triggers, views and stored procedures using My SQL.• Supported operations with database administration in Oracle RDBMS, Network, Windows XP, and Linux RedHat system administrations.• Analyze the data and provide the insights about the customers using Tableau.Environment - Python 3.3, scipy, Pandas, Linux, MySQL, skilearn, numpy, Tableau.,""Technical SkillsData Sources	HDFS, SQL Server, ExcelProgramming Languages   Python (numpy, pandas, nltk, scikit-learn, matplotlib), R, SQL, Matlab, HadoopData Visualization	R, python, MS Power BI, TableauData Exploration	R, Python, TabpyCloud Platforms	AWSRepository	Github, BitBucket using source tree, EventhubMachine LearningRegression analysis, classification, K-Means Clustering, Bayesian Methods, Decision Trees, Random Forests, Support Vector Machines, neural networks, Collaborative Filtering, KNN, Ensemble Methods.IDE's	Canopy, Spyder, I python Notebook, Jupyter Notebook, R- studio.""";;;
"Data Scientist Wemore Strategic Disrupters - San Jose, CAAugust 2016 to PresentDeveloping machine learning tools to provide industrial solutions.Implemented data models, algorithms to implement machine learning solutions as member of data analyst/data scientist team.Conducted exploratory analysis and feature engineering to fit the best models using SciKit Learn, Python.Optimized clients' product portfolios by evaluating market segmentation data queried from the SQL ServerProposed strategies to increase clients' market shares by performing brand competition data analysis.Project: Market Analysis of Cable Television and Internet Providers• Explored the factors that influence the cancellation of client subscription,• Feature engineered, handled with missing values and created new features by using existed ones,• Used Matplotlib and Seaborn libraries in Python for visualization,• Used PySpark in Python by initializing Spark and loading the Big data to retrieving RDD information, sorting, filtering and sampling the data,• Applied ANOVA, chi-square statistical tests and ensemble methods in order to understand the prediction power and relationship among the categorical features,• Selected influenced features to develop less complex but more robust machine learning models,• Designed Logistics Regression, Random Forest, SVC, and Neural Networks, compared model's performance, and tuned hyper-parameters to get better results,• Developed classification model to make classification whether the client will cancel the service or not.Project: Fenerbahce Football Club Increase Club Income• Predicted the turnout of Fenerbahce games by using various surveys (implicit) and historical games ticket sales data• Optimized settlement plan of Fenerbahce Stadium and raised annual benefits of the club with predicting combine ticket sales• Optimized the fan club goods and raised revenue of the club by classifying the supporters according to their social status and attitudes• For prediction we used linear regression, Random forest regression and SVM using Python.Project: Santander Bank Value Prediction Challenge (Kaggle Competition, Ranked in the Top 10%)• Developed ensemble techniques to predict the value of transactions for potential customersData EngineerBroadridge Financial Solutions - Phoenix, AZDecember 2014 to March 2016,""ANALYSIS OF VARIANCE (2 years), ANOVA (2 years), machine learning (2 years), MS SQL SERVER (2 years), Python. (2 years)""";;;
"Data Scientist NRG Systems, IncAugust 2018 to Present Leading prototype development of meteorological time-series data analysis libraries as well as R&D of machinelearning projects for the wind energy industry.Developed readable, scalable and tested python library to reliably analyze large time-series data-sets from meteorological sensors. (Project 2)Developed a machine learning algorithm to automatically clean wind energy assessment data which replaces the need for a dedicated analyst. (Project 3)Developed innovative technique using unsupervised learning to aid meteorologists in better estimating windenergy resources. (Project 4)Responsible for creating data science interview tests, as well as being the main technical interviewer for a datascientist new hire.Applications and Analysis EngineerNRG Systems, IncJanuary 2017 to August 2018Led data science research opportunities and computational fluid dynamics R&D projects.Developed, published (IEEE), and filed patent on machine learning algorithm to detect faults in machinery to reduce maintenance costs. (Project 1)Designed and patented a novel technique to detect yaw misalignment in wind turbines to improve electricalenergy generation.Developed a python library to process acoustic and vibration signals for prognostics and health management of rotating machinery.Associate Mechanical EngineerNRG Systems, IncFebruary 2015 to January 2017Heavily involved with data science R&D projects and advanced computational fluid dynamics.Developed an incompressible flow CFD rotational model for a wind speed measuring device using open sourceCFD libraries. This model could save thousands of dollars on wind tunnel testing.Supervised and mentored a team of senior engineering students at University of Vermont on a machine conditionmonitoring system using audio technology.,""Patents, Publications and ConferencesNovelty detection of rotating machinery using a non-parametric machine learning approach, Project 1.Paper published (sole author) and presented at IEEE PHM conference 2017.Patent filed Jan 23, 2017 (first author).Techniques for determining yaw misalignment of a wind turbine and system and method using the same.Patent Issued Mar 2, 2017 - US WO 2017035325 A1.A comparative analysis of atmospheric stability metrics and temperature sensors.Podium presentation at AWEA WRA 2017 Conference. (Main contributor and presenter)Best practices for quantifying, interpreting, and utilizing Atmospheric Stability measurements usingstandard wind resource assessment sensors and CFD simulations, Project 4.WindEurope 2018 conference (technical contributor).""";;;
"Data Scientist Okaya - San Francisco, CAJanuary 2017 to PresentResponsibilities:• Lead the full machine learning system implementation process: Collecting data, model design, feature selection, system implementation, and evaluation.• Worked with Machine learning algorithms like Regressions (linear, logistic), SVMs and Decision trees.• Developed a Machine Learning test-bed with different model learning and feature learning algorithms.• By thorough systematic search, demonstrated performance surpassing the state-of-the-art (deep learning)• Used Text Mining and NLP techniques find the sentiment about the organization.• Developed unsupervised machine learning models in the Hadoop/Hive environment on AWS EC2 instance.• Used clustering technique K-Means to identify outliers and to classify unlabeled data.• Worked with data-sets of varying degrees of size and complexity including both structured and unstructured data.• Participated in all phases of Data mining, Data cleaning, Data collection, developing models, Validation, Visualization and Performed Gap analysis.• Used R programming language for graphically critiquing the datasets and to gain insights to interpret the nature of the data.• Implemented Predictive analytics and machine learning algorithms to forecast key metrics in the form of designed dashboards on to AWS (S3/EC2) and Django platform for the company's core business.• Worked on AWS S3 buckets and intra cluster file transfer between PNDA and s3 securely.• Developed predictive models on large scale datasets to address various business problems through leveraging advanced statistical modeling, machine learning and deep learning.• Extensively used Pandas, Numpy, Seaborn, Matplotlib, Scikit-learn, SciPy and NLTK in R for developing various machine learning algorithms.• Built multi-layers Neural Networks to implement Deep Learning by using Tensor flow and Keras.• Perfectly Utilized machine learning algorithms such as linear regression, multivariate regression, Naive Bayes, Random Forests, K-means, & KNN for data analysis.• Researched extensively on the nature of the customers and designed multiple models to perfectly fit the necessity of the client and Performed Extensive Behavioral modeling and Customer Segmentation to discover behavior patterns of customers by using K-means Clustering.• Super Intended usage of open source tools - R Studio (R) and for statistical analysis and building the machine learning models.• Establish a robust process by machine learning (MLbase) to insure the predictive analytics and quality of all algorithms and processes• Ensure operational and optimal execution of production data science routines and processes•  Implemented supervised learning algorithms such as Neural networks, SVM, Decision trees and Naïve Bayes for advanced text analytics.• Performed Data wrangling to clean, transform and reshape the data utilizing Numpy and Pandas library.• Contribute to data mining architectures, modeling standards, reporting, and data analysis methodologies.• Conduct research and make recommendations on data mining products, services, protocols, and standards in support of procurement and development efforts.• Involved in defining the Source to Target data mappings, Business rules, data definitions.• Worked with different data science teams and provided respective data as required on an ad-hoc request basis• Assisted both application engineering and data scientist teams in mutual agreements/provisions of data.Environment: R Studio 3.5.1, AWS S3, NLP, EC2, Neural networks, SVM, Decision trees, MLbase, ad-hoc, MAHOUT, NoSQL, Pl/Sql, MDM,Data ScientistUber - San Francisco, CAAugust 2013 to December 2016Responsibilities:• Responsible for performing Machine-learning techniques regression/classification to predict the outcomes.• Responsible for design and development of advanced R/Python programs to prepare transform and harmonize data sets in preparation for modeling.• Designed and automated the process of score cuts that achieve increased close and good rates using advanced R programming• Managed datasets using Panda data frames and MySQL, queried MYSQL relational database (RDBMS) queries from python using Python-MySQL connector.• Utilized standard Python modules such as csv, itertools and pickle for development.• Analyzed large datasets to answer business questions by generating reports and outcome.• Worked in a team of programmers and data analysts to develop insightful deliverables that support data-driven marketing strategies.• Executed SQL queries from R/Python on complex table configurations.• Retrieving data from database through SQL as per business requirements.• Create, maintain, modify and optimize SQL Server databases.• Manipulation of Data using python Programming.• Adhering to best practices for project support and documentation.• Understanding the business problem, build the hypothesis and validate the same using the data.• Managing the Reporting/Dash boarding for the Key metrics of the business.• Involved in data analysis with using different analytic techniques and modeling techniques.Environment: R, Python, MYSQL, exploratory analysis, feature engineering, Machine Learning, Python (NumPy, SciPy, pandas, scikit-learn, NLTK, NLP), Tableau.Data ScientistScaleapi - San Francisco, CAJanuary 2009 to August 2013Responsibilities:* Worked closely with data scientists to assist on feature engineering, model training frameworks, and model deployments implementing documentation discipline.* Involved with Data Analysis primarily Identifying Data Sets, Source Data, Source Meta Data, Data Definitions and Data Formats.* Worked with the ETL team to document the Transformation Rules for Data Migration from OLTP to Warehouse Environment for reporting purposes.* Performed data testing, tested ETL mappings (Transformation logic), tested stored procedures, and tested the XML messages.* Created Use cases, activity report, logical components to extract business process flows and workflows involved in the project using Rational Rose, UML and Microsoft Visio.* Involved in development and implementation of SSIS, SSRS and SSAS application solutions for various business units across the organization.* Developed mappings to load Fact and Dimension tables, SCD Type 1 and SCD Type 2 dimensions and Incremental loading and unit tested the mappings.* Wrote test cases, developed Test scripts using SQL and PL/SQL for UAT.* Creating or modifying the T-SQL queries as per the business requirements and worked on creating role playing dimensions, fact-less Fact, snowflake and star schemas.,""SKILLSDatabases: MySQL, Oracle, HBase, Amazon Redshift, MS SQL Server 2016/2014/2012/2008 R2/2008.Statistical Methods: Hypothetical testing, ANOVA, Times Series, Confidence Intervals, Bayes Law, Principal Component Analysis (PCA), Dimensionality Reduction, Cross-Validation, Auto-correlationMachine Learning: Regression analysis, Bayesian Method, Decision Tree, Random Forests, Support Vector Machine, Neural Network, Sentiment Analysis, K-means Clustering, KNN and Ensemble MethodReporting Tools: Tableau Suite of Tools 10.x, 9.x, 8.x which includes Desktop, Server and Online, Server Reporting Services (SSRS)Data Visualization Tools: Tableau, Matplotlib, Seaborn, ggplot2, JavaScript Libraries - D3, React, Node, AngularLanguages: Python (2.x/3.x), R, SAS, Excel, SQL, T-SQLProcess Modeling Tools: BPMN, DMN - Signavio, VisioOperating Systems: Windows 98/NT/2000/2003/XP/7/8/10, Linux/ Unix""";;;
"Data Scientist IBM India Private Limited - Mumbai, MaharashtraSeptember 2015 to August 2018Mumbai, India	September 2015 - August 2018Data Scientisto Received Solution Excellence Award for 'Share Expertise' in 2016.o Received Sales Excellence Award for 'Put the Client First' in 2017.? Worked closely with clients to identify business challenges.? Designed and implemented predictive models to exploit patterns in historical data to identify risks and opportunities.? Presented recommendations and influenced the strategic direction of projects.? Implemented timely, accurate and actionable solutions to improve performance.• Insurance - Sentimental analysis on litigation data to help the legal professionals make better litigation strategy decisions.• Telecommunication- Detect clients who are likely to churn and provide the next best action to retain them.• Automobile - Identify anomalies causing engine damage and predict the optimal time for maintenance check of engines.• FMCG - Develop BI dashboards and reports to assess Supply Chain efficiency.• Banking - Determine customers who are likely to overdraft. Create customer segmentation for cross-sell or up-sell opportunities.Data ScientistBrand Idea Consultancy Private Limited - Mumbai, MaharashtraJune 2014 to June 2015Utilize in-built analytical applications to identify trends and relationships between different data sources, draw appropriateconclusions and translate analytical findings into marketing strategies that drive value for FMCG sector.• Build statistical models that help clients to access and analyze data resulting in higher revenues and margins and a bettercustomer experience.Summer InternHDFC Mutual Funds - Asset Management CompanyMay 2013 to July 2013Analysis of Mutual Funds with comparison of schemes and their performance.Administrative AssistantChristian Medical CollegeJune 2010 to June 2011INDVAC 2010 organized by Christian Medical College (CMC) with support from Bill and Melinda Gates foundation and ResearchCouncil of Norway was the first Vaccinology course in India. Single-handedly responsible for the smooth running of the program.,""SKILLSR, SQL, SAS (base certification level) SPSS Modeler, SPSS Statistics, Watson Analytics, STATA, MS-Office""";;;
"Data Scientist Wemore Strategic Disrupters - San Jose, CAAugust 2016 to PresentDeveloping machine learning tools to provide industrial solutions.Implemented data models, algorithms to implement machine learning solutions as member of data analyst/data scientist team.Conducted exploratory analysis and feature engineering to fit the best models using SciKit Learn (SelectKbest, RFE, Chi-sq, LinearSVC), Python.Optimized clients' product portfolios by evaluating market segmentation data queried from the SQL ServerConsulting companies and individuals for their data science problems,Project: Market Analysis of Cable Television and Internet Providers	(Verizon)• Explored the factors that influence the cancellation of client subscription,• Feature engineered, handled with missing values and created new features by using existed ones,• Used Matplotlib and Seaborn libraries in Python for visualization,• Used PySpark in Python by initializing Spark and loading the Big data to retrieving RDD information, sorting, filtering and sampling the data,• Applied ANOVA, chi-square statistical tests and ensemble methods in order to understand the prediction power and relationship among the categorical features,• Selected influenced features to develop less complex but more robust machine learning models,• Designed Logistics Regression, Random Forest, SVC, and Neural Networks, compared model's performance, and tuned hyper-parameters to get better results,• Developed classification model to make classification whether the client will cancel the service or not.Project: Marketing Campaigns of a Portuguese Banking• Explored the factors that influence the prediction of client subscription in depositing,• Feature engineered, handled with missing values and created new features by using existed ones• Used python matplotlib and seaborn libraries for visualization,• Applied ANOVA, chi-square statistical tests in order to understand the prediction power and relationship among the features,• Selected influenced features to develop less complex but more robust machine learning models,• Created Logistics Regression, Random Forest, SVC, and Neural Networks, compared model's performance, and tuned hyper-parameters to get better results,• Improved company's manpower plan and increased the profit by %3 ($600K),Project: Santander Bank Value Prediction Challenge (Kaggle Competition, Ranked in the Top 10%)• Developed ensemble techniques to predict the value of transactions for potential customersData EngineerJeoIT Bilgi Teknolojileri Ltd - Ankara, TRDecember 2014 to March 2016TurkeyTurkish Ministry of Foreign Affairs e-Archiving Project• Participated in Turkey's largest historical archives digitization project whose Phase 1 was successfully completed in 18 months, including a 3-month preliminary work. This phase had 30M pages and used up 4.5 Petabytes of storage.• Designed and built data driven archive applications aimed at optimizing business and operational efficiency.• Performed database design, tuning and optimization on MS SQL Server.• Optimized complex SQL queries, index and database objects.• Processed, cleansed and verified the integrity of data used for analysis.• Followed agile methodologies to manage the life-cycle of the project.Data Architect & Project ManagerErk Yazilim Bilgi Sistemleri Ltd - Istanbul, TRApril 2002 to December 2014TurkeyDesigned and built data driven archive applications aimed at optimizing business and operational efficiency.Managed numerous web projects that have won national and international awards.Providing vision to company in product improvement matters (document digitization, e-commerce, B2B, B2C, web content management, e-government, archive management, open innovation platform).Project: Turkish Presidency Document e-Archiving• Turkey's first major historical and top-secret document digitization project, targeting digitization of 5.000.000 pages and 1 Petabytes of data, was completed on time.• Turkish Presidency's project had numerous stages consisting of document ontology, classification, document scanning, digitization, data entry, data tagging, digital signature, secure sharing platform, searching platform, a new technical approach for Ottoman handwritten document character recognition using NLP, Turkish character recognition.• The assumed role in this project was the project management and data architecture design.• Development and revision management of Content Policy Document with our client team.Software Development SpecialistHEAS A.S - Istanbul, TRSeptember 2000 to February 2002TurkeyPerforming system development activities for the structuring of information technology systems in newly created airportTechnical and administrative management in planning, establishment and operating of systems such as IGCS, SITA, FPL, BRS, METAR, FIDS, ATIS, ATCS, AODB, Finance Systems, Intranet.Developed Intranet, Airport Operational Database Application and Aircraft Maintenance Application.Tools: Oracle, ASP, Delphi, IIS, Windows.Software Development SpecialistYAYSAT A.S - Istanbul, TRNovember 1999 to September 2000TurkeyAnalysis, planning and software coding of book distribution project Software development on Unix shell and Windows with Informix 4GL. Advanced Informix, ORACLE Database performance tuning and database management.Tools: Unix Shell, Informix 4 GL, Informix, Oracle database, ASP, Microsoft Windows, IISSoftware Development SpecialistUniversal Bilgi Teknolojileri Ltd - Istanbul, TRSeptember 1996 to August 1998TurkeyPerforming requirements analysis, software coding of Municipality information systems. Developed document management software. Advanced Informix Database performance tuning and database management.Tools: Unix shell (SCO, IBM AIX, HP), Informix 4 GL, Informix database,""SkillsMachine Learning: Regression analysis, Ridge, Lasso Regression, K-NN, Decision Tree, Support Vector Machine (SVM), Ensembles method like Bagging, Boosting, Stacking, K Means clustering, Deep Learning.Python Libraries: Jupyter Notebook, NumPy, Pandas, Sci-kit, SciPy, TensorFlow, NLTK, Keras, Flask, Pickle.Platforms: Unix, Windows, MacOS.Databases: MySQL, SQL Server, Oracle, Informix.Programming: Python, SQL, Hive, Hadoop, Hue, MapReduce, GitHub/Git | Data Pipeline / ETL Tools: AirflowCloud Services: AWS (S3, EC2, RDS, ECS)Reporting & Visualization Tools: Seaborn, Matplotlib, ggplot2, Tableau Desktop, Tableau Online.Statistics: Hypothetical Testing, ANOVA, Chi-Square, Confidence Intervals, MLE, Principal Component Analysis (PCA), Cross-Validation, Correlation.""";;;
"DATA SCIENTIST CITI AnalyticsMarch 2017 to PresentOnline Offer Personalization Built Machine learning model suite and advanced model stacking to propose 'next logical product based on user online behaviorResulted in 17% increase in online product enrolmentModel Algorithms Used: AdaBoost, XgBoost, Random Forest, Self-organizing Maps, GBM etc.Tools: R-programming, Python.Call center complaints categorization (using NLP)Built content categorization model to allocate complaints to relevant teams for processingAchieved accuracy of 82% & is being deployed for Citi, North AmericaAlgorithms Used: LDA (Latent Dirichlet Allocation), NMF (Non-Negative Matrix Factorization) and DTM (Document Term Matrix)Tools: NLTK, genism (Python libraries)DATA SCIENTIST - CITI Analytics - (MAR'17 - PRESENT)Online Offer Personalization•  Built Machine learning model suite and advanced model stacking to propose 'next logical product based on user online behavior•  Resulted in 17% increase in online product enrolment•  Model Algorithms Used: AdaBoost, XgBoost, Random Forest, Self-organizing Maps, GBM etc.Tools: R-programming, Python.Call center complaints categorization (using NLP)•  Built content categorization model to allocate complaints to relevant teams for processing•  Achieved accuracy of 82% & is being deployed for Citi, North America•  Algorithms Used: LDA (Latent Dirichlet Allocation), NMF (Non-Negative Matrix Factorization) and DTM (Document Term Matrix)Tools: NLTK, genism (Python libraries)Improving the monetization for unsold Ad InventoryBuilt solution to improve the monetization of unsold Ad inventories in different websites and Mobile Apps for the world's largest technology companyProject was taken up for in-house R&D by the clientAlgorithms Used: Random Forest & GBMTools: R-ProgrammingRanking Ad placementsHelped rank display ad placements to increase monetization based time & location of ad in the webpageProject was taken up for in-house R&D by the clientAlgorithms Used: Lasso-Regression, Logistic RegressionTools: R-Programming (caret & mlr), SQL (data pull & data wrangling)Market Cannibalization AnalysisBuilt solution to calculate overlap in product SKUs across two retail giants in the UK during their mergerHelped identify potential cannibalization & redundancy in deployment of resources. The result was also used by anti-trust regulatory authorities.Algorithms Used: Jarro-Winkler, Fuzzy Lookup, Web ScrappingTools: R-Programming (rvest, selenium & tm)Sentiment analysis & topic modelingUsing twitter data built solutions to identify customer sentiments & overall customer experience trends for a global bankIdentified & ranked problem areas faced by customers. Leveraged this information to optimize online ad campaignsAlgorithms Used: SVM (Support Vector Machines), TF-IDF (Term Frequency-Inverse Document Frequency)Tools: R-Programming (e1071 & caret)DECISION SCIENTISTFebruary 2015 to March 2017,""SkillsFeature Engineering, Machine Learning, Natural Language Processing, Deep-learning and Model StackingTechniques: Random Forest, Gradient Boosting Machines, Support vector machines, k-means, Convolution Neural Networks, Self-organizing Maps etc.Tool-set: R-programming, Python, Hive, Datameer, Platfora, Tableau, Revo-R, SQL, Excel, Power BI etc.SkillsFeature Engineering, Machine Learning, Natural Language Processing, Deep-learning and Model StackingTechniques: Random Forest, Gradient Boosting Machines, Support vector machines, k-means, Convolution Neural Networks, Self-organizing Maps etc.Tool-set: R-programming, Python, Hive, Datameer, Platfora, Tableau, Revo-R, SQL, Excel, Power BI etc.""";;;
"Data Scientist BlocPower.io - Brooklyn, NYSeptember 2018 to PresentBrooklyn, NYBlocPower is a leader in energy efficiency and clean energy development business and the development of energy assessment process in New York.Data Scientist	Sep 2018 - Present• Machine Learning: Worked with team in selecting features, building and optimizing classifiers using machine learning techniques to solve different challenges;• Data Collection & Processing: Enhanced data procedures to include information that is relevant for building analytics systems, processed cleaning, and verified the integrity of data used for analysis;• BP Targeting Project: Created model and designed the decision tree to assist company determine the potential clients based on various of data sources by using machine learning skills.• Proposal and Reports: Assisted in reporting and project proposal generation for technologies such as solar, wind, geothermal, CHP and microgrids.• Internal & External Communication: Assisted other departments, such as Finance, Engineering and Marketing departments with their any projects related data analysis.Intern - Data Science in Robotics DeptBrainCo Inc - Boston, MADecember 2017 to March 2018Boston, MABrainCo is a leader in Brain-Machine-Interface Wearable devices. It was founded from the Harvard Innovation Lab with $5.5 million funding.Intern - Data Science in Robotics Dept.	Dec 2017 - Mar 2018• Prostheses and Manipulator Modelling: Worked with engineers to design experiments to test prostheses and fingers' combinations; individually collected motion and muscle sensors' data and built statistical models;• Data Collection: Used shimmer sensory to collect electromyography(EMG) data from our volunteers;Bank of China - Chengdu, CN2018 to 2018• Data Pipeline & Modelling: Collected, managed, analyzed, and plotted over 80,000 pieces of EMG data using Python; The outcome was used to improve the performance of our product and was presented in CES 2018;• Internal & External Communication: Translated technical and marketing materials between Chinese and English; drafted marketing materials and posters about the company's productsBank of China	Chengdu, ChinaIntern - Operation & AdminRisk ModellingJuly 2016 to August 2016helped determine probability distribution of market returns and estimated market risk by VaR models;• Designed credit scorecards and credit loss forecasting models to measure loan loss provisions;,""• Technical Skills: Python, R (packages: ggplot2, GoogleVis, plyr, ClustEval, SigClut), Matlab, SQL, Linux, JavaScript, Python, Microsoft-Office, Google Analytics, SAS";• Mathematics: real analysis, metric, discrete math, linear algebra, linear program, Fourier series, numerical computations, combinatorics;• Statistics: ANOVA, regression analysis, correlation, data mining, data clustering (including k-mean clustering, and Hierarchical clustering), data visualization, probability analysis, computational algorithm;"• Economics: Microeconomic Analysis and Policy, Macroeconomic Analysis and Policy"""
"Data Scientist Optum - Eden Prairie, MNJuly 2017 to PresentEden Prairie, MNCurrently working with Optum, where during my first year I had a chance to experience their Techonology Development Program, which consisted of us going through two job positions to experience them and then picking a permanent role after the one year.Current Role:Data Scientist - Machine Learning - July 2017 - Current • Daily sprint meetings to update on what we have worked on and what we will be working on • Ability to researched key information to complete tasks (Applies to all roles) • Worked on ETL(extract, transform, load) scriptsBusiness AnalystJanuary 2017 to July 2017• Analyzed medical data on a daily basis (Check for anomalies) • Communicated with data sources to find out irregularities in data.• Participated in daily sprint meetings with team • Created standard operating procedures on business analyst position • Worked on tickets in ServiceNow queues (Example: Finding out why a patient did not qualify for a certain benefit)System DeveloperJune 2016 to January 2017• Database Migration - Sybase to MySQL ? Created BASH script to automate migration between Sybase and MySQL • PIF Project - Legacy software used by a client to tracked benefits of customers ? Helped redesigned the tracker to clients expectationsLevel 2 IT ConsultantHusky Tech - Saint Cloud, MNJanuary 2015 to May 2016• Delegated tasks to Level 1 Consultants on a daily basis • Trained Level 1 Consultants on hardware (printers, computers, etc. ), software(drivers, software installation, etc.), and troubleshooting.• Helped deal with any tickets escalated to level 2 queue in RightNow(ticketing system) • Assisted customers with any technical issues over the phone and in person • Used Bomgar (Remote Desktop software) to help customers with any software issues • Troubleshoot computers and equipment in computer labs around St Cloud State campus • Diagnosed and fixed computers: malware/virus clean up, reformat, stress test, installing necessary drivers, and doing any necessary updates • Used Ticketing system, RightNow, to assist customers and update any task givenIT InternHusky Tech - Robbinsdale, MNMay 2015 to August 2015• Assisted customers and other technicians with any technical issues over the phone or in person • Used Ticketing system, ServiceNow, to update on tickets and task, as well as a reference • Troubleshoot computers and any electronics at North Memorial properties in metropolitan area (North Memorial Hospital, Maple Grove Hospital, Maple Grove Sleep Center, Rockford Road Clinic etc.) • Diagnosed and fixed computers: reimaging, stress test (Hiren), installing necessary drivers, updates, registering computers onto the network, printer fix and maintenance • Worked with other departments to resolve issues. Such as working with Network Engineers to configure IP on printers or System Administrators to give employees correct access.• Contributed in weekly team meetings, such as stating issues/bugs on new images being pushed out for computers • Completed Udacity Artificial Intelligence Nanodegree course  - https://github.com/gyang101/udacity ? Sudoku - In this project, we are to write a code to implement two extensions of the Sudoku solver. The first one will be to implement the technique called ""naked twins"". The second one will be to modify the existing code to solve a diagonal Sudoku. ? Isolation - In this project, we are to develop an adversarial search agent to play the game ""Isolation"". Isolation is a deterministic, two-player game of perfect information in which the players alternate turns moving a single piece from one cell to another on a board. Whenever either player occupies a cell, that cell becomes blocked for the remainder of the game. The first player with no remaining legal moves loses, and the opponent is declared the winner. ? Planning - This project includes skeletons for the classes and functions needed to solve deterministic logistics planning problems for an Air Cargo transport system using a planning search agent. With progression search algorithms like and optimal plans for each problem will be computed. ? Recognizer - In this project, we are to build a system that can recognized words communicated using the American Sign Language. Provided with a preprocessed dataset of tracked hand and nose positions my goal is to train a set of Hidden Markov Models using part of this dataset to try and identify individual words from test sequences. ? Dog Project - In this project, using convolutional neural networks we are given an image of a dog and using our algorithms we will identifiy an estimate of the canines breed. If we are given an image of a human it will identify it with the most resembling dog. ? Capstone Facial Recognition - In this project, we combine the knowledge of computer vision techniques and deep learning to build and end-to-end facial recognition system. We are able to indentify points around the eyes, nose, and mouth on any face. • Completed Udacity Machine Learning Nanodegree course - https://confirm.udacity.com/5KSELTJC ? Boston Housing - In this project, we evaluate the performance and predictive power of a model that has been trained and tested on data collected from homes in suburbs of Boston, Massachusetts. A model trained on this data that is seen as a good fit could then be used to make certain predictions about a home  -  in particular, its monetary value ? Finding Donors -  In this project, we will employ several supervised algorithms of our choice to accurately model individuals' income using data collected from the 1994 U.S. Census. We will then choose the best candidate algorithm from preliminary results and further optimize this algorithm to best model the data. Our goal with this implementation is to construct a model that accurately predicts whether an individual makes more than $50,000. This sort of task can arise in a non-profit setting, where organizations survive on donations. ? Creating Customer Segments - In this project, we will analyze a dataset containing data on various customers' annual spending amounts (reported in monetary units) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer. ? Train a Quadcopter how to fly - In this project, we enable quadcopters to autonomously achieve desired control behaviors such as takeoff and landing. We could design these controls with a classic approach (say, by implementing PID controllers). Or, you can use reinforcement learning to build agents that can learn these behaviors on their own. ? Capstone TalkingData AdTracking Fraud Detection Challenge - https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection * Kaggle challenge taken on for my final capstone project. Proposal can be read here: https://github.com/gyang101/udacity/blob/master/MLND/proposal1.pdf,""Skills:• Software: Eclipse/MyEclipse, Anaconda Python, Microsoft Office Softwares, Visio, Project, Visual Studio, Grafana, Chronograf, and Adobe Photoshop• Computer Language: Python, HTML, C++, VB.net , Oracle SQL, MySQL, BASH, KOTLIN• Framework: Agile/Scrum Methodology• Udacity Courses Completed: Introduction to Python Programming, Intro to Hadoop and MapReduce, Programming Foundations with Python, Artificial Intelligence Nanodegree, Machine Learning Nanodegree""";;;
"Data Scientist Point Energy DataNovember 2018 to Present• Integrated and formatted large historical raw data from multiple sources using Python to export structured data, helping company provide better data analytical services for clients and increase 30% profits• Wrote SQL queries to perform data management and storage in Amazon AWS Database• Performed PCA model by R code for higher accuracy in building renewable energy index in commodity market• Established executive dashboard in MS Excel to report the project results and determined impact, trends and opportunities, contributing to 30% profits growth• Managed multiple tasks and projects simultaneously to achieve business goals, such as weather risk management and renewable energy production forecasting• Collaborated with team to provide analytical support and deliver insights to stakeholdersData AnalystLife.io - Stamford, CTSeptember 2018 to December 2018• Wrote SQL to join data tables and extracted information for further statistical analysis• Leveraged 1,200,000 user demographic data to determine what user behaviors impact registration rate• Worked on text mining in SAS Enterprise Miner to summarize successful message strategies• Visualized and interpreted various types of data using Tableau for better understanding of user features.Data Analyst--Customer InformationCITIC Security Company LimitedJanuary 2017 to December 2017• Researched, implemented and evaluated statistical methods and machine learning models, such as logistic regression and decision trees, to support various analytic solutions• Synthesized qualitative and quantitative data to produce forecasting model, resulting in 30% more customer registration rate• Visualized customer data using Tableau for better interpretation of customer features• Analyzed 1,000,000 client portfolios to report the results of the analysis to teams and support key business functions, increasing 20% profitBusiness Analyst Internship - Sales & MarketingIndustrial Bank CO., LTDJune 2015 to August 2015• Conducted exploratory data analysis in Tableau for financial products to analyze sales and marketing trend• Recommended accurate strategic plans based on business requests and identified new business problems/opportunities, contributing to 35% sales growth• Effectively communicated with all level of management to collect business requirements,""RESEARCH PROJECTCampaign Emails Analysis for Life.io Company to optimize activation rates                                 ·  Wrote SQL to join data tables and extracted information for further statistical analysis·  Leveraged 1,200,000 user demographic data to determine what user behaviors impact registration rate ·  Worked on text mining in SAS Enterprise Miner to summarize successful message strategies·  Visualized and interpreted various types of data using Tableau for better understanding of user features.Predictive Model -- Residential Property Pricing, Brooklyn, NY·  Preprocessed 150,000 raw data rows to delete unwanted and redundant variables using SQL queries·  Evaluated predictive models, such as neural network, decision trees and linear regression, choosing best model to deliver best results·  Recommended new marketing and business strategiesPeople’s Happiness Index                                                                                                           · Performed hypothesis test determining what factors are related to happiness or unhappiness· Used R code (glm) to develop logistic regression model and selected variables for higher accuracy rate · Reported analysis results and demonstrated recommendationsBusiness Plan -- Online Transaction Store of Second-hand Goods for University Students     2016 First Prize School-level National Undergraduate ‘Internet+’ Competition                              ·  Designed website content for second-hand transaction·  Wrote whitepaper and design ppt to report the results and future developmentINTEREST + AWARDS2016              First Prize, Gu Zheng Instrument Competition2015              First Prize school-level National Undergraduate ‘Challenge Cup’ Competition.                       Best project for the economy and environment2014              “The Best Debater” in Debate Club             """;;;
"Data Scientist Dell IncJuly 2017 to PresentDescription:Worked as Data Scientist and used Predictive Modeling, Statistics, Machine Learning, Data Mining, and other aspects of Data Analytics and Techniques to collect, explore, and extract insights from structured and unstructured data.Responsibilities:? Responsible for data identification, collection, exploration and cleaning for modeling and development.? Researched, evaluated, architect, and deployed new tools, frameworks, and patterns to build sustainable Big Data Platforms for our clients.? Designed a Request Analysis model using Natural Language Processing (NLP) using NLTK and SpaCy packages in Python.? Classified the image requests such as Image Classification, Image Segmentation using CNN Classifier and Tensor Flows.? Developed a predictive model using Random Forest Regression to predict the upcoming month's claims and possible policy cancellations using XGBoost.? Achieved efficiency of 87.1% in churning problem using XGBoost.? Utilized Machine Learning algorithms such as linear regression, multivariate regression, Naive Bayes, Random Forests, K-means, K-NN for data analysis.? Advanced Text analytics using Deep learning techniques such as Convolution Neural Networks (CNN), Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) using several packages like NLTK and Tensorflow in Python.? Natural Language Processing to understand text content by including reviews, descriptions, and interactions between users on our marketplace.? Developed POC in Spark to Query the dataset.? Understand transaction data and develop Analytics insights using Statistical models using SciPy in Machine learning.? Involved in gathering requirements while uncovering and defining Multiple dimensions.? Extracted data from one or more source files and Databases.? Utilized web scraping techniques like Beautiful Soup in Python to extract and organize competitor data.? Used Spark for test data analytics using MLLib and Analyzed the performance to identify bottlenecks.? Designed data processing pipelines with a combination of the following technologies: Hadoop, MapReduce, Spark, Hive, Kafka, Avro, SQL, and No SQL Data Warehouses.? Converted the unstructured data into structured data using Apache Avro.? Designed predictive models using the machine learning platforms like H2O, Flow UI.? Used the Agile Scrum Methodology to build the different phases of Software development life cycle.? Developed MapReduce/Spark modules for machine learning and Predictive analytics in Hadoop on AWS.? Architected overall master data hub for Data Elements that are used by multiple IT systems.? Defined the architecture and various phases for the implementation of the Transactional and Data Warehouse systems.? Utilized various new Supervised and unsupervised machine learning algorithms/software to perform NLP tasks and compare performances.? Worked with (Tableau) Report Writers to Test, Validate Data Integrity of Reports.? Captured Modeling requirements from Senior Stakeholders to Bench functional requirements for SAS.? Created reports with Crystal Reports and scheduled to run on a daily basis.? Accomplished multiple tasks from collecting data to organizing data and interpreting Statistical Information.? Evaluate the performance of various Algorithms/Models/Strategies based on the Real-world data sets.? Interacted with the other departments to understand and identify data needs and Requirements and work with other members of the IT organization to deliver Data Visualization and Reporting solutions to address those needs.Environment: Jupyter Notebook, Apache Spark, Hive, Kafka, SAS, R Studio Pro, R Studio Server Pro, Microsoft SQL Server, Tableau 10.5, Microsoft Excel.Data ScientistHenkel, ConnecticutJune 2015 to July 2017Description:This project is intended to carry out to identify and predict who can be the defaulters of credit loan based on the applications. The datasets of customer's information such as their demographics, work pattern, residence status, credit to debt ratio, Default Patterns are being used. Segmentation and Logistic regression are the techniques that have been used for creating the probability list of defaulters from the new list.Responsibilities:? Involved in Gathering Requirements while uncovering and defining multiple dimensions.? Extracted data from one or more source files and Databases.? Participated in continuous interaction with Marketing and Finance teams for obtaining the data and data quality.? Accomplished multiple tasks from collecting to organizing data and interpreting statistical information.? Handled Structured and Unstructured data using various tools In Big Data Platform and Python.? Working with cloud-based platform services like AWS Amazon Red Shift for data Storage and retrievals.? Performed the ETL operations using RDMS like MS SQL Server, Oracle for efficient data manipulation.? Unearthed the raw data by doing the Exploratory Data Analysis (Classification, Splitting, Cross-validation) by using Machine Learning packages like Pandas and NumPy in Python and R Studio Pro.? Converted raw data to processed data by merging, finding outliers, errors, trends, missing values and distributions in the data.? Natural Language Processing (NLP) is used for Text Analysis using NLTK packages in Python.? Utilized various techniques like Histogram, Bar plot, Pie-Chart, Scatterplot, Box plots to determine the condition of the data using Matplotlib, Seaborn, and ggplot2 packages.? Conducted data exploration (Dplyr, TidyR) in R and Pandas, NumPy and SciPy in Python to look for Trends, Patterns, Grouping, and Deviations in the data to understand the data diagnostics.? Designed various reports using Pivot - tables, and different charts like Bar plot, Pie plot, Histograms and Identified the financial and non-financial independent attributes that were to be used in modeling.? Developed Segmentation Trees (Optimization, Pruning, Modelling) using Scikit-Learn package to find out a high-risk segment of the population.? Achieved multi-dimensional Segmentation Analysis to discover business rules and finalize the segmentation procedure.? Used Logistic Regression to obtain the probabilities for non-defaulters and defaulters.? Identified Key performance indicators (KPIs) among all the given attributes.? Created and used Repositories using GitHub for free flow of code.? Executed What-if scenario analysis to discover effective, implementable ways of reducing loan defaults.? Built Real Time Data Pipelines and Steaming Apps using Apache Kafka.? Maintained a log of all the iterations performed in R Studio and Python during the data modeling process.? Fashioned scoring model to Score Propensity of loan applicants to default with a high degree of accuracy in capturing defaulters.? Created Interactive Reports and Visualizations for Technical Documentation using Advanced Techniques in Power BI.? Created an interactive ROI dashboard on campaigns expenditure and measuring its efficacy using Tableau and Power BI.? Effective communication between production support and handled multiple tasks with strong interpersonal communication, technical aptitude and learning environment.Environment: Anaconda Navigator (Jupyter Notebook, Spyder), R Studio Pro, R Shiny, Microsoft SQL Server, Amazon Red Shift, Microsoft Excel, Power BI, Tableau 10.5.Sr. Data Analyst/Data ScientistJ.P Morgan & Chase CoFebruary 2014 to March 2015Responsibilities:? Worked with Business users for requirements gathering, business analysis, and project coordination.? Data blending implemented on databases and generated interactive dashboards in Tableau Portal? Worked on data related to enterprise data quality in order to analyze data flow models in JD Edwards's environment.? Researched on Multi-layer classification algorithms as well as building Natural Language Processing model through the ensemble.? Executed and validated data transformations in the target system with SQL.? Published Workbooks by creating user filters so that only appropriate teams can view it.? Work with customers to define reporting needs and implement Tableau reports to satisfy needs? Worked on data cleaning and reshaping, generated segmented subsets using Numpy and Pandas in Python.? Developed Python scripts to automate data sampling process.? Ensured the data integrity by checking for completeness, duplication, accuracy, and consistency.? Worked on model selection based on confusion matrices, minimized the Type II error.? Generated cost-benefit analysis to quantify the model implementation compared with the former situation.? Continuously collected business requirements during the whole project life cycle.? Identified the variables that significantly affect the target.? Used cascaded parameters to generate a report from two different Data Sets.? Involved with Query Optimization to increase the performance of the Report.? Employed Filtered Indexes to improve query performance and reduce the storage and maintenance cost.? Generated data analysis reports using Matplotlib, Tableau, successfully delivered and presented the results for C-level decision makers.? Design and create daily, monthly and ad-hoc reports for BI and Analytics customersProvide recommendations for data presentation within reports/dashboards? Support for end users connected to servers in various departments regarding connection and data access issues.? Involved in defining the business/transformation rules applied to sales and service data.? Played a major role in the production support of SSAS cube and SSIS jobs.? Involved in writing MDX queries and performance optimization of the SSAS cubes.? Implemented Incremental load, used Event Handlers to clean the data from different data sources? Wrote and optimized complex SQL queries involving multiple joins and advanced analytical functions to perform data extraction and merging from large volumes of historical data stored in Oracle 11g, validating the ETL processed data in the target database.? Conducted model optimization and comparison using stepwise function based on AIC value? Data blending implemented on databases and generated interactive dashboards.? Published Workbooks by creating user filters so that only appropriate teams can view it.? Embedded Tableau views into SharePoint? Analyzed the source data and handled efficiently by modifying the data types.? Generated tableau dashboards for sales with forecast and reference lines.? Created SSIS packages to clean and load data to the data warehouse.? Created package to transfer data between OLTP and OLAP databases.? Created SSIS Packages using Pivot Transformation, Fuzzy Lookup, Derived Columns, Condition Split, Term extraction, Aggregate, Execute SQL Task, Data Flow Task, and Execute Package Task etc. to generate underlying data for the reports and to export cleaned data from Excel Spreadsheets, CSV files to the data warehouse.? Applied various machine learning algorithms and statistical modeling like a decision tree, logistic regression, Gradient Boosting Machine to build a predictive model using the scikit-learn package in Python.Environment: Python, Oracle, MS Excel, SSIS, SSAS, Tableau, SQL, ETL, decision tree, logistic regression, Gradient Boosting Machine, scikit-learn, OLAP & OLTP, SQL*Loader.Data Analyst /Research ScientistCDW Corporation - Chicago, ILJanuary 2012 to January 2014Description:Worked closely with the Cross - Functional Research team, Contributed in the extensive research and analysis of the Student Grade Prediction Recommendation System. Achieved in getting 89.7% accuracy and delivering the Proof of Concept to the client within the time.Responsibilities:? Developed a Collaborative Filtered Recommenders system using k-NN user-based Algorithm using Machine Learning techniques in Scikit-learn package of Python.? Accumulated Raw Data and filtered to RDBMS using Amazon Red Shift, MS SQL Server,andOracle Applications.? Extensively Cleansed data, Handled Missing Values, Wrangled Data and Feature Engineered the large dataset using Pandas and Scikit-Learn in Python to structure the data.? Performed Hypothesis tests, Chi-Square test, and ANOVA to identify the significance between data samples using R packages.? Performed Predictive modeling and Statistical analyses of the data using various Regression Techniques like Linear Regression, Decision Tree Regressor, Random Forest Regressor in R and SciPy package to draw insights, patterns, and trends.? Presented Graphs/Charts like Histograms, Boxplots, Bar Diagrams and various plots for the client by using effective visualization tools/packages like Matplotlib, ggplot2, and Tableau.? Tested the developed prototype and implemented in the Large-Scale environment.Environment: Python, R, MS SQL Server, Amazon Red Shift, Oracle, MS Excel, Tableau 10.5, Power BIData AnalystColgate-Palmolive - Karachi, PKJanuary 2007 to January 2012Description:In this Project, Superior analytical abilities were employed and conducted queries in the supply and chain management domain.Responsibilities:? Built and manipulated day to day SQL Queries and reports to audit pay and benefits.? Interpreted complex data, analyzed results using statistical techniques like Parametric and Non-Parametric tests in R, SAS and provided ongoing metrics using Advanced Excel, Microsoft SQL Server to the management.? Used different SAS Procedures such as PROC REPORT, PROC UNIVARIATE, PROC TABULATE, PROC FREQ, PROC MEANS, PROC SUMMARY, PROC TRANSPOSE and Integrated SAS datasets into Excel using Direct Data Exchange.? Used SAS/ODS to format HTML and RTF formats.? Created and maintained Ad-hoc SAS Programs/Macros for the Validation, Extraction, Presentation, Manipulation, Analysis, and Reporting.? Optimized existing codes for efficiency and automation of SAS programs to improve reporting efficiency.? Performed Extract, Transform and Load (ETL) operations and developed packages using SSIS and SSRS to transfer data from OLTP and OLAP databases systems in Data Warehouse.? Visualized Insights and create ad-hoc reports using various techniques in R (ggplot2), Excel and Power BI to the clients to improve strategies and operations.Environment: SAS Enterprise Guide, R Studio Pro, MS SQL Server, SSIS, SSRS, MS Excel, Power BIMS SQL Server/SSIS DeveloperMobilink South - PKJanuary 2005 to January 2007Mobilink Corporation is the biggest telecommunication company in Pakistan and offering a range of wireless communications services for individuals, business and government customers.RESPONSIBILITIES:? Created new database logical and physical design to fit new business requirement and implemented new design into SQL Server 2006.? Successfully migrated old data from SQL Server 2000 to SQL Server 2005 using SSIS Packages.? Used DDL and DML to write triggers, stored procedures to check the data entry.? Created Triggers to enforce data and referential integrity.? Defined Check constraints, Business Rules, Indexes, and Views.? Worked on DTS Package, DTS Import/Export for transferring data from Heterogeneous Database (Oracle and Text format data) to SQL Server.? Data migration (import & export - BCP) from Text to SQL Server? Performance tuning of SQL queries and stored procedures using SQL Profiler and Index Tuning Wizard.? Created indexed generic views to facilitate easy user interface implementation and enforce security on critical customer information.? Filtered bad data from legacy system using complex T-SQL statements, and implemented various constraints and triggers for data consistency.? Created views to facilitate easy user interface implementation, and triggers on them to facilitate consistent data entry into the database.,""TECHNICAL SKILLSData Science Tool	R 3.5.1/3.x, R Shiny, R Studio Pro, R Server Connect Python 3.0, SAS, Minitab, MATLAB.Database	Oracle, MS Access, Microsoft SQL Server 2012/2014, Sybase and DB2, Teradata, HiveMachineLearningClassification and Regression Techniques, Clustering, Supervised and Unsupervised Learning, Time Series and Forecasting, Deep Learning, Reinforcement LearningData Modeling Tools   Erwin, ER Studio, Star-Schema Modeling, Snowflake-Schema Modeling, FACT and Dimension Tables, Pivot Tables, GitHubBI Tools	Tableau 10.5, Dataiku, Power BI, QlikView, Smart Draw, SAP BusinessObjects, Crystal Reports.Languages	SQL, PL/SQL, ASP, Visual Basic, XML, Python, SQL, T-SQL, SQL Server, C, C++, JAVA, HTML, UNIX shell scripting, PERL.Applications	Toad for Oracle, Oracle SQL Developer, MS Word, MS Excel, MS Project, MS PowerPoint,  Teradata, SpyderBig Data	Hadoop, HDFS, Spark, Hive, Cassandra, MongoDB, MapReduce, Sqoop, Hive.Methodologies	Agile, RAD, JAD, RUP, UML, System Development Life Cycle (SDLC), Waterfall Model.Operating System	Windows, Mac OS, Ubuntu, UNIX.""";;;
"Data Scientist Asia Outsourcing LLCFebruary 2016 to PresentRole: Data ScientistProject Details:The Data Warehouse Application IFP that is currently has ETL in MF platform is getting converted to Hadoop, which will have ETL in Hadoop platform. The Fraud alerts data is processed in Hadoop cluster and stored in the HDFS and Teradata. The data is used for Fraud reporting.Roles and Responsibilities:• Reports creation and analysis at various levels for example Currency level report(CLR), Account Level Report(ALR) and other reports• Developing fraud detection models using different machine learning techniques• Defining the data streams and analyzing the data• Developed the ETL process in Hadoop Platform• Loaded semi structured data into Hadoop File System (HDFS).• Developed the Sqoop and Hive scripts for data transfer and data analysis.Environment: Isolation Forest, Logistic Regression machine learning algorithms, Python, Cloudera, HDFS, Hive, SqoopData ScientistAmerican Power and Gas LLCMarch 2014 to December 2015Project Details:Legacy systems get data from upstream systems in the form of files and tables. They get data from multiple sources, so data redundancy is increased, and multiple reporting problems are occurring, so the plan is to decommission these systems one after the other and build a single system.Roles and Responsibilities:• Perform extensive data studies to understand the data behavior• Perform Principal Component Analysis using different PCA techniques• Developing predictive models• Applied machine learning algorithms like clustering and segmentation methods for product offerings• Developed classification models to predict the products and offers subscriptions• Designed Python frameworks for machine learning models• Involved from design to implementation of machine learning models• Performed Import and export of data into HDFS and Hive using Sqoop and managed data coming from different sources• Defining the requirements for data lakes/pipe lines• Analyzed and fixed the data related issues with help of Hive and Sqoop.• Creating Hive tables, loading data and writing Hive queries.• Modeled various hive tables and optimized the access by designing partitions and bucketing.• Involved in code review and bug fixing for improving the performance• Worked on the core and Spark SQL modules of Spark using programming languages like PythonEnvironment: K-means clustering, Hierarchical clustering, Logistic Regression, Naïve Bayes, Decision Tree, KNN machine learning algorithms, PCA, Python, Cloudera, HDFS, Hive, Sqoop, SparkFinancial Data Analyst/Business IntelligenceRedcorp LLCJune 2011 to February 2014Roles and Responsibilities:• Preparing monthly/yearly P & L statement analysis report, financial ratio analysis report, cost analysis reports, and intra-company control report.• Tracks financial status by monitoring variances from plan,• Conducting due diligence on companies and industries by researching, reading financial statements and market data.• Determines financial status by comparing and analyzing plans and forecasts with actual results• Reconciles transactions by comparing and correcting data• Increases productivity by developing automated applications; eliminating duplications; coordinating information requirements; Artie-Financial dashboard• Provides information to management by assembling and summarizing data; preparing reports; making presentations of findings, analyses, and recommendationsEnvironment: TOP accounting System, SQL Server, MS Excel, MS Excel Macros, Ratio analysisLead Business Intelligence AnalystMediGain LLCMarch 2007 to May 2011Roles and Responsibilities:• Grounding, analyzing and consultation on business and industry for the clients with different interests (public and private hospitals, physician group practices, ambulance service providers, etc).• Producing the management reports and dashboards for the management of clients on financial and non-financial statistics their organization.• Develop weekly, monthly and quarterly reports on Insurance sector, Revenue Analysis, Management Information (productivity, performance and cost) for the internal management.• Presentation of information and reports to the CEOs, Directors of the clients as and when required to facilitate their decision-making process.• Identification of clients' requirements correctly and to develop, design or customize reports to suit their individual necessities where most of the technical knowledge is applied.• Target setting and overall performance management of multiple teams and reporting to Sri Lankan and United States management on client and team KPIs.• Planning for career development of team members and succession for key positions within the team.• Leading and participating in company-wide initiatives as part of the company's senior leadership team.Environment: SQL Server 2008, MS Access, statistical packages: Minitab, SPSS, e-views and MS Excel, VBA Macros to assemble, manipulate and format data and reports.,""TECHNICAL SKILL-SET:• Regression and Classification Techniques: Linear Regression, Multiple Linear Regression, Logistic Regression, KNN, Decision Trees, Support Vector Machines, KernelSVM, Random forest, Naïve Bayes• Clustering techniques: K-means, K-means++, Hierarchical Clustering• Analytical Tools: SQL, Spyder, Jupyter Notebook, Tableau, mysql• Programming: Python, R, Python - Data Manipulation, Numpy, Pandas, Matplotlib, Plotly• Big Data: Spark, Hive, Sqoop, HBase, HDFS, Spark    - Spark Core, Spark SQL, Spark Streaming, PySpark• NoSQL: Hbase, MongoDB• Methodologies: Agile and Waterfall model""";;;
"Senior Data Scientist Avlino, Inc. - Holmdel, NJOctober 2018 to PresentLed a team of Data Scientist to implement algorithms for process optimizing, automation and building predictive modeling for sea port operations and hotel chains in APAC and EU. Projects involve collection, visualization and analysis of large volume of data for actionable intelligence. developed PoC for potential clients across the globe.Senior Analyst/ Big DataContext Business Intelligence, Princeton, New Jersey - Princeton, NJFebruary 2017 to PresentInvolved in helping global customers with data analytics in banking and service industries to gather Real-time actionable intelligence. Projects involve global financial services firms such as Morgan Stanley, Barclays and energy company such as Schneider Electric; Responsibilities include analysis of unstructured data and text analysis; augmentation of external analytics implemented in Python/ R into data visualization component implemented in Qlik and Tableau to address and solve a variety of aspects for customers business including security. Schedule regular workshop to explain Statistical Analysis within team.Senior AnalystReverse Supply Chain - Basking Ridge, NJFebruary 2013 to January 2017Developed and implemented Analytics to optimize customer returned mobile handsets within the Verizon Processing Centerhandling 50,000+ average returns daily. Implemented decision algorithms and analytics for a specific OEM that led to documented savings of $1.5MM yearly. Data analysis included predicting and monitoring bounce rate using linear/ non-linearstatistical models with extraction of information from Teradata using SQL, as well as statistical comparison of competitor'sofferings. Awarded Verizon Spotlight Award for outstanding contribution in Analytics in 2014 and 2015.Senior Manager, Analytics Product R&D/ Pre-salesVPI Systems - Somerset, NJNovember 2011 to January 2013Led a team in statistical and network analysis to support VIP's Systems' Network Planning products. Evaluated and preparedreports on applicability, efficiency and accuracy of statistical methods and models in network analysis. Made recommendations concerning the use of VPI tool to support predicted traffic growth of VPI clients (network service providers). Providedtechnical sales consulting support by developing algorithm for VPI network planning tool to meet specific profiles of domestic and international clients. Contribution included discussions with domestic and internal clients (ISPs) to understand details of their historical and projected network traffic and pattern and modeling of the same into the VPI simulation tool for effectivenetwork traffic engineering followed by analysis and interpretation of modeling results focused on traffic congestion, routing and QoS. Acted as a liaison between market focused Sales Engineering group and Analytical product development team. Workcontributed to retention and extension of existing service contracts for multiple VPI clients. Also, developed PoC for potentialclients across the globe.Senior ManagerAnalytics Solutions - Bangalore, KarnatakaJuly 2010 to October 2011Accenture, Bangalore, IndiaResponsible for solutioning and delivering large scale engagements mostly in an on-shore/off-shore model. Led a 8 personconsulting team to design a solution blueprint for Airtel Communications (a major telecom service provider in India)integrating VPI planning tool. Was responsible for the end-to-end delivery of the project which included deployment and nationwide roll- out in three phases: requirements and design delivery, software development coordination and QA testing.Successfully delivered 2 releases of the complex Network Planning System. Completed detail performance analysis to supporttraffic diversity, customer and site migration, triggers for proactive maintenance, and trending. Achieved $.5M of annualsavings for the client by proactive planning through the system.Also worked as a pre-sales subject matter expert supporting new and existing opportunities in the OSS domain in Indiadomestic Telco market focusing on existing and new client accounts. Activities involved pre-sales proposal creation, proposalresponse, effort estimation and pricing.Head, Analytics & QualitySystat IncJanuary 2004 to June 2010a spin off from SPSS), CaliforniaContributed towards the enhancement of Systat products SigmaPlot & SigmaStat for improved graphical plotting,curve fitting and data analysis features of these tools. Led the Beta Testing and market trials for Systat Sigma Plot andSigmaStat and designed and conducted surveys for selected markets, analyzed and reported survey results. Developed and published competitive analysis reports for similar statistical products in the market with a goal to direct and define the Systatproduct road map.Six Sigma ConsultantMotorola SchaumbergMarch 2002 to December 2003Led the Six Sigma Quality initiative for Motorola for Wireless Group, Motorola University Green Belt and Black Belt program. Responsible for the overall Six Sigma Program Management consist of train the trainer program, multiple projects along with delivery and implementation. Defined strategy, offerings and execution plan for implementing Motorola's Six Sigma quality initiatives.Distinguished Member of Technical StaffAT&T Submarine Systems, Bell Labs - Holmdel, NJMarch 1996 to February 2002Network system planning and performance analysis: Projects involved diverse Network Service providers such as the regional Bell Operating Companies, Bell Canada, Telecom Brazil and network equipment manufacturers such as Motorola, NORTEL, Fujitsu and Hitachi; Responsibilities included collection, tabulation, analysis and interpretation of large volume of data related to product and market using SAS. Awarded Bell Labs (Lucent) Recognition Award for contribution to SONET/SDH DWDM product R&D.LANGUAGES	C, C++, SQL, MATLab, SAS, Minitab, SPSS, R, Microsoft Excel, Word, Visio and PowerPoint,""AREAS OF EXPERTISE   INDUSTRIES• Statistical Data Analysis• Survey Design and Analysis• Multivariate technique such as ANOVA, Regression, Clustering, Factor analysis, and Discriminant analysis• Fraud Detection• Simulation and Modeling• Numerical Methods• Statistical Quality Control• Time Series Analysis and Forecasting• Categorical Data Analysis• Lean/Six Sigma Implementation• Market Research• Business Process Improvement• Predictive Analytics and modeling (linear, non-linear, GLM & Logistic Regression)• Generating reports & graphs• Communications: Telecom Service Providers, Wireless• Academic Institution and R&D organizations: Research Labs & Universities• Manufacturing: Large communication equipment and electronics R&D/ Manufacturing Companies""";;;
"Data Scientist Pegasus Knowledge SolutionsJuly 2017 to PresentRoles and Responsibilities:? Understanding and analyzing business requirements for the project? Preparing Analysis plan.? Extraction of text data from several social media platforms? Data Analysis? Design and creation of Models for Text Analysis? Model retraining with new data from time to enable improvement in data pattern detection.? Presentation of ResultsProjects:Opinion mining - Text classificationInsight- Analysing Social Media Data to identify Product opinion by text classificationTasks:-• Data Extraction from twitter using REST API as a JSON Source.• SSIS sources include flat files from various other blogs.• Survey data from database added as source to SSIS.• Added necessary transformations to upload in database in unicode format.• Assigned source keys to each tweet/message to for identifications.• Created java application to connect to table using jdbc connection• Performed data cleaning and string operations and uploaded data back to source.• Connect SPSS modeler to SQL sever to perfrom NLP (Natual Language processing)• Performed Text transformations and build data dictionary from template for text classification.• Clustered Text into topics and calculating weight based metrics for each Topic.• Assigning Business rules for cluster associations using both word and text strings.• Prepared Link charts and Word clouds for reporting.• Tuned model with each update from data source.• Deployed and Re-deployed model• Accuracy of Model was improved by identifying text not falling into category and retuning.• Performance improvement was taken care by non-duplication using selective business rules per category.Environment: SSIS, T-SQL, SQL SERVER, Core Java, SPSS Modeler, Power point.Data scientistCapturing Event recorder downloadsData Scientist DeveloperPegasus Knowledge Solutions--- SanjoseCAJuly 2017 to PresentCapturing Event recorder downloads for all locomotives running on the NetworkComputing statistics for Throttle - Atlanta, GA, USJanuary 2016 to June 2017Atlanta-GAJan 2016- Jun 2017Insight: Creating a tool to report Undesired Emergency in Freight trainsTasks:-• Capturing Event recorder downloads for all locomotives running on the Network.• Building Consist data by tagging locomotives on train.• Applying Undesired Emergency conditions for Speed, PCS, CIE/EIE. TLEM.• Capturing data for Brake Cylinder and Brake pipe pressure during UDE• Computing durations for application and number of instances of UDE per train.• Computing statistics for Throttle, speed duration, change in air pressure (psi)• Measurement of slack action during braking.• Capturing mechanical failure including drawbar failure during UDE for preventive maintenance.Data scientistPheonix - AZOctober 2014 to November 2015Insight: Developing model to predict/estimate unknown fuel across freight trains.Tasks:-• Requirement gathering of historic data from several table sources spread across various databases and merged to create a raw dataset.• Cleaned dataset by performing outlier analysis. Prepared scatter and box plots to confirm outliers and their removal.• Performed several statistical tests and multivariate analysis including hypothesis tests, variance test and correlations to establish relationships between the multivariate components.• Performed transformations including binning and used standardization and normalization techniques.• Referred to past analysis and tests done on datasets.• After careful study of the model and relationships, several regression models were chosen.• Trained several multivariate models on K-fold using 80/20 Train/Test data.• Prepared Charts based of Model parameters and performed accuracy tests.• Re-trained models to generalize them to minimize over fitting issues.• Chose model based off generalization throughout the datasets with reasonable accuracy.• Prepared presentations and Reports with Team discussions.• Model deployment underway via PMML 4.0Environment:- SQL server, Terradata, Oracle, Hive, SSIS, ETL, RCore Responsibilities:-• Participating in Daily Scrum working with agile methodology.• Loading Unstructured Locomotive data from Event Recorder into Big data sources.• Running and Maintaining SSIS jobs on SQL server for daily reporting status of locomotives, failures, idle times and movement across crc7's, milepost and Subdivisions across the track network.• Discussing and planning on new initiatives for fuel conservation.• Performing Analysis to estimate report fuel saving across several months and comparing over years.• Preparing monthly Burn charts and Crate charts to describe fuel consumptions of various routes.• Working with Wabtec hardware and DOSS to build and study Event Recorder data across locomotives.• Working with ARC and WDL base station data to capture Event Recorder downloads.• Testing and preparing reports for TO (Trip Optimizer) and LDR (Leader) on fuel savings.• Working on Positive Train Control (PTC) devices and routes to estimate fuel savings and measuring safety standards as a Federal govt. requirement.• AESS reporting for Engine Start/Stop and failures through Error codes based of AESS data.• Building and deploying predictive models to study fuel based parameters for optimizationEnvironment: SQL Server, Terradata, Oracle, HDFS, SQOOP, Flume, Hive, SSIS, SSRS, RSenior Business AnalystOSSE - Washington, DC, USJanuary 2013 to September 2014Roles and Responsibilities:? Creating reports for various stake holders in T-SQL on Databases including Longitudinal database? Review existing business procedures and recommending and implementing new Business rules.? Prepare detailed statistical reports in SQL, SSRS, R & SPSS to track progress of weekly, monthly and quarterly Students Trends and Enrollment.? Involved in performing data conversions from flat files into a normalized database structure using SSIS and other tools.? Managing tables, procedures and functions on SQL server Database? Extensively used Joins and Sub-Queries to simplify complex queries involving multiple tables and also optimized the procedures and triggers to be used in production.? Working with data over multiple platforms for analysis including R and SPSS.Projects:Edfacts Reporting - FederalInsight: - Reporting annual student performance over multiple cohortsTasks:-• Data collection from various sources, including excel and flat files and OLE DB in SSIS.• Schema and coding was in T-SQL.• Performing joins between multiple tables on several different keys.• Establishing ODBC connections between SQL SERVER and STATA as required• Computing metrics including risk ratios, growth and School and student several performance metrics over Schools, LEA and Districts. Report was in document format.Environment:- SQL server, T-SQL, SPSS, SSIS, ExcelPOSEC Reporting - State and FederalInsight: - Reporting Annual student performance for test taken by graduating students.Tasks:-• Data collection from various sources, including excel and flat files and OLE DB sources.• SSIS was used for transforming data into suitable format and uploading into tables.• Building schema and coding data was done on T-SQL Scripts.• Performing joins and computing metrics on scores• Establishing ODBC connections between SQL SERVER and SPSS as required• Calculating internal scores for Student Aid using several student associated parameters.• SSRS was the final reporting tool used and reported in Sharepoint.Environment:- SQL server, T-SQL, SPSS, SSIS, SSRS, SharepointData ScienceCegedimFebruary 2011 to December 2012Stock Market data Analysing ToolData Source - Yahoo finance• Identifying stock symbols for stocks to analyze and building stock symbol dataset.• Used core java to execute url and collect csv data from yahoo stock finance• Collecting needed stock parameters and performing transformations.• Loading to Hive table using JDBC connection.• Running HQL scripts to compute metrics for stock analysis.• Creating a longitudinal record dataset for daily stock data updates• Stock demographics table updated using secondary data source.• Stat tests done using R to identify relationship between stocks.• Plots constructed using ggplot.• Created Unix Shell Script for automation of daily collection of stock data.Environment: Core Java, HDFS, HIVE, HQL, R, Power point.Customized marketingCegedim India Private LimitedJuly 2010 to January 2011Insight:- Need for categorizing customers based on their purchase pattern for effective marketing.Identifying frequently occurring purchase patterns for effective product placement.Tasks:-• Data collection was in a flat file comprising of delimited purchased items per line, per customer.• A Sparse matrix was used as an effective dataset in R• Produced plots for Item Frequency, Support confidence and Lift.• Created a model based on the Apriori algorithm for Market Basket Analysis to identify frequently occurring purchase patterns and the probabilistic interdependencies between products.• Top 25 purchase pattern segments created for effective target marketing.• Top 10 frequently occurring patterns identified for product placement.Environment:- R, Excel, PowerPointComplete project managementDiabetes detection Model - New york NY, NY, USJanuary 2009 to June 2010Insight:- A lending company needed to identify/categorize its customer based on a score that reveals effectiveness in doing business with.Tasks:-• Dataset comprised of transactions, income and demographics data.• Developed solution in SSIS for ETL automation and uploading data into database.• Used Stored Procedures for Data Checks and Cleaning.• Tables extracted by query of T-SQL.• Identified variables that justify our Business objective of financial strength.• Set ODBC connection between SQLSERVER and SPSS for data exchange• Performed factor analysis plotted histograms to obtain effective factors for the Modeling algorithm.• Used Logistic regression to identify probabilistic customers and assigning a score based on their probability of not fraud.• Computed Confusion matrix to identify errors and Lift and Gain charts for model performance• Prepared KS charts and calculated AUC from ROC curve• Also tried algorithm Neural network, but it failed to give better accuracy and performance was just as good.• Produced PMML and PFA format model interchange with deployed using OpenCPUEnvironment:- MSSQLSERVER, SSIS, SPSS Statistics & SPSS Modeler, Excel, PowerPoint.Roles and Responsibilities:? Managing a Team of Analysts and Researchers for project co-ordination.? Data Analytics, Complex Data Interpretation in SPSS & SAS in FMCG, BFSI and Pharma.? Complete project management? Preparing analyses plan and analyzing both Qualitative and Quantitative data? Creating and producing graphical and statistical reports on specific products and markets? SWOT Analysis.Key Projects Undertaken:? Sales &Marketing performance analyzer:The S&M performance analyser tracks brand promotion, awareness, usage, message recall, representative performance, brand perception and future prescription intent of brands against their main competing brands in various markets.? Social media research:Quantify presence of major pharmaceutical companies on leading social and networking media channels - Facebook, Twitter and Youtube. Monitor the trends of this new channel of communication on monthly basis.,""SkillsSQL SERVER (3 years), SQL (4 years), T-SQL (4 years), JAVA (4 years), SPSS (4 years)Skills:Analytics SkillsStatistical and Machine Learning Techniques: Regression, Classification Trees, Naïve Bayes, Kmeans, KNN, Association rules, CHAID, NLP and Text Classification with LDA.Analysis: Stat tests, PCA, Correlation, DOETECHNICAL SKILLSBig Data Hadoop, PIG, Hive, Flume, SqoopData Bases MS SQL Server, Oracle, TeradataProgramming Python, Core Java, T-SQL, Stored Procedures, Functions, Triggers, Unix Shell ScriptingStatistical Packages SPSS Statistics, SPSS Modeler, STATA, R, SAS Base, Quantum,BI tool SSRS, TableauETL SSIS""";;;
"Data Scientist IIISprint - Overland Park, KSMay 2016 to PresentLeadership role in the development of Sprint Big Data Lake. This position develops and defines Hadoop data tables and structures, validates coding, and develops analytical forecasting methods.  Methods developed include Financial Budgeting, Spectral Efficiency, ROIC forecasting, Capacity forecasting, and Seasonal customer patterns. •	Lead Scientist on designing Network Performance Reporting for the Big Data Solution.  I designed, modified, and developed the KPI data aggregation methods, data validation, and performance metrics.   I provided my code to the IT team for production.•	Lead Scientist on Financial Risk Assessments of Network Deployments.  I conducted several studies on the probability of the Engineering teams to accomplish the goals set forth.Skills•	Executive Presentation and Reporting•	Hadoop database security, configuration, and work space design•	Languages: HUE SQL, TeraData SQL, hBase, Pig, Python, R, and AltryxPrinciple Design EngineerSprint - Overland Park, KS2009 to 2014Leadership role to teach and lead the deployment of Sprint’s wireless networks.  The delivery of these networks play a key role in ensuring the business stay competitive in a highly competitive industry.•	Lead Deployment Engineer of Sprint’s next generation of Network Equipment and configuration standards.  Provided technical guidance on the deployment of the network and ensured the configuration standards were followed and documented. Led the development of a new high gain antennas to meet RF coverage requirements.•	Manager of network deployment and responsible for the delivery and budget.   This program was completed $39 million under budget and delivered two months early.  Responsible for budget, forecasting spend, billing, weekly reports, and escalations.•	Lead Design Engineer for the design acceptance of vendor proposed designs.  Skills•	Mentoring and Training of Project Managers and Engineers•	Executive Presentation and Reporting•	Base Station Development•	Antenna Development•	Business Development•	New Performance Data Review – SQL, VB, GIS, network modeling•	Patents – Antennas (5), Mechanical Devices (2), Protocol Modifications (1), SON (3)Senior Design EngineerSprint - Overland Park, KS2006 to 2009Refine the budgeting process of Sprint’s wireless networks.  Designed network models that translated growth requirements into network equipment and budget requirements.  Evaluate business cases based on growth models.  Assist in the development of the annual budget.   •	Development of the Radio Access Network model was built using VBA and Access.  This model uses Erlang B and Monte Carlo simulation with coupled parameters.  This allowed the model to test the sensitivity. •	Propagation Modeling using Planet (GIS) & Link Budget (CDMA, EVDO, LTE, GPS) •	Spectrum Valuation Modeling - VBA•	Key Performance Indicator development (KPI) for performance health measurements - SQL•	Design of the Quality of Service (QOS) of back haul IP networkSkills•	Mathematical Modeling – VB, VBA, Neural Networks, SQL•	Business Case Development•	Financial Modeling•	Patents – Mathematical methods(3) to evaluate the Networks healthEngineerSprint - Overland Park, KS2001 to 2006Refine the budgeting process of Sprint’s data networks.  Designed network models that translated growth requirements into network equipment and budget requirements.  Assist in the development of the annual budget.•	Internet modeling (IP) – Traffic loading and capacity planning•	IPv6 capacity planning - Researched and presented technical issues to be resolved•	Built and maintained IP capacity reports.  This reduced held orders by 30% in the first yearSkills•	SQL, VBA, Oracle and PearlProcess EngineerAsh Grove Cement Company - Overland Park, KS1993 to 2001Permit Ash Groves cement plants to burn waste fuels.  Designed the trial burn plans and gained approval of the plans from the EPA and the States.  Lead the report writing and analytical review of test samples.  Conducted 12 trial burns and received the first two permits in the United States.  Mentor and Teach new plant Engineers process optimization and testing methods.  Develop mass flow balances, thermal models of the cement kilns systems.  Predict the emissions of a plant we were building to gain a construction permit.  This model correctly predicted the emission and was validated after start up. •	Environmental models and studies – NOx reduction technologies, Dioxin & Furan reduction studies, Mid Kiln firing of tires, particulate studies, Mercury Cycles, Risk Analysis•	Environmental permitting – Lead the facilities testing and reporting•	Process Engineering – Thermodynamic models of new and old plants; Teaching and Mentoring•	Plant Automation – PLC, analog control logic, and Supervisory control (3 plants, 15 installations and commissioning)•	Instrumentation – Lead the development for an on line XRF to evaluate clinker real time,Patents – 33 filed";;;
"Senior Business Analyst and Data AnalystSenior Business Analyst and Data Analyst? - Columbus, OHApril 2017 to PresentThe project was for gathering requirements for Commercial Line Transformation and move existing multiple commercial lines products, processes and technology to a One Nationwide future with a competitive suite of common products, streamlined processes and enhanced technology.Job Responsibilities:• Work on Commercial line property insurance in Safe Agile methodology. Conducting grooming sessions, and facilitated daily scrum calls.• Gathering requirements for Commercial Line Transformation Product and Pricing - Interface team.• Requirement gathering from Inception and creating RTM, Functional Specification Documents and Data Mapping Analysis for System Integrations.• Responsible for defining the key identifiers for each mapping and data modeling process.• Responsible for conversion of data in Data Mapping and writing transformation rules.• Responsible for documenting the mapping and requirements of group insurance for interface and conversions between the source and applications.• Worked with Vendor Interface Program to load data from legacy system in to temporary table on Excel to validate the data.• Clarify, communicate and document requests for change requests from As-Is to To-Be process and coordinate with the testing and development team.• Experience with developing User Stories throughout the Agile Lifecycle as well as created UML diagrams such as Use Case, Activity, ER diagram and Chart diagrams with MS Visio.• Designing storyboard, process flow diagrams and visual presentations in MS Visio.• Worked on researching and pre-grooming user stories by understanding the business requirements as stated in the business requirements matrix by including key members from business teams, underwriting team, and closing SMEs and later translating those in an IT standpoint to explain the work to the team.• Participated in daily Agile Scrum, Sprint Planning and Retrospective Sessions and update the team on status of upcoming User Stories for the a project of changing the client's software maintenance structure of their various software products.• Conducted cost benefit analysis on commercial lines.• Provided support for complex business Data Modelling and Management, for billing, claims, and submission.• Used Sparx Enterprise Architect for CLT Business rules management.• Facilitated Joint Requirement Planning (JRP) sessions with Business User Groups, along with conducting Joint Application Development (JAD) sessions with IT Groups and Conflict Management with Project team members.• Identified efficiencies in ""current state"" of casualty underwriting divisions and helped with development and implementation of ""future state"" plan (As-Is/To-Be) by removing non-value added process and workflow automation.• Involved in formal requirements gathering methodologies, and developed reports based on specifications.• Involve in meetings to analyze the services and process. Conducted detailed assessment of operational workflow.• Coordinate tasks with other programmers, business users, database administrator, mainframe team, testing team and development team.• Ensured all technical artifacts complied with corporate SDLC Policies and guidelines.• Worked with technical team to improve report performance and performed system testing. Performed tasks like test cases, identifying defects, mockups, quality reporting, data cleansing and data quality.• Performed functional testing, integration testing, automation testing, and User Acceptance Testing.Environment: Mainframe system, XML, WSDL, Oracle 12, SharePoint, Version One, SOA, CA Rally, Rational Requisite Pro, SOAP UI, REST, TOAD, MS Visio.Senior Business AnalystSaint Paul, MNJuly 2015 to March 2017The MN Medicaid Program provides health services to low-income individuals, has an annual budget of 7.2 billion dollars and provides services to more than 1 million recipients annually.  MMIS processes 51 million Medical claims annually for more than 30,000 Medicaid providers. The focus of the project was to enhance the Medicaid Management information System (MMIS) for new Business Requirement, new MCO configuration, new eligibility rules configuration by following CMS guideline and validating HIPAA5010 and ICD10 codes.Responsibilities• Served as Senior Consultant responsible for designing, developing, testing, documenting and delivering technology solutions for Microsoft Dynamics ERP, Management Reporter, Crystal Reports, and SQL Server including customizations and alterations to existing applications.• Coordinated with the stakeholders and project key personnel to gather functional and non-functional requirements during JAD sessions.• Worked in combination of Agile and Waterfall.• Studied existing business process and created AS-IS workflow to illustrate the existing system.• Responsible for the full HIPAA compliance lifecycle from gap analysis, mapping, implementation, and testing for Medicaid Claims.• Analysis of complex MMIS System database design, reports and system processes. Supported the implementation and enhancement of Statewide MMIS, Web portal, and integration.• Responsible for gathering requirements, data mapping, gap analysis, and process flow and activity diagrams in changing old MMIS and Involved in testing new MMIS.• Responsible for Medicaid Claims Resolution/Reimbursement for peach state health plan         using MMIS.• Performed in-depth analysis of workflows, data collection, and report details associated with Epic• Recorded requirements in the Requirement Traceability Matrix (RTM) defining each technical requirement in detail from areas like: application software, networks, servers, internet and desktop configuration.• Assisting the project manager in creating the business case, project plan and data flow analysis.• Served as a liaison between the internal and external business community (Claims, Billing, Membership, Capitation, Customer service, membership management, provider management, advanced Healthcare management, provider agreement management) and the project team.• Actively analyzed current business processes (Claims, Recipient eligibility and enrollment, encounter, etc.) and worked with management to improve and implement enterprise solutions to ensure compliance.• Created process flow of EDI X12 837 P/I/D, 835 rules in claim processing module.• Responsible for receiving claims and encounters using EDI 837.• Correctly identified errors and refilled denied/rejected claims.• Responsible for creating data flow analysis and processes and creating management reports based on the analysis.• Followed the UML based methods using Rational rose to create use cases, activity ER diagram, sequence diagram, collaboration diagram that include functional and non-functional specifications to hand off to development teams.• Actively involved in updating internal processes (submit claims, check eligibility), updating data collection and data reporting.• Defects and bug testing by using Rational Clear-Quest, Configuration management and Version control with Clear-Case.• Performed system testing, integration testing, automation testing and UAT.• Performed security assessment of the health information as per the HIPPA guidelines and also the integrity and confidentiality of the user information.• Identified UI requirements, created Wireframes, Prototypes and UI specification.• Performed technical artifacts of the system as per the state guidelines.Environment: IBM Mainframe, Epic, ANSI X12- EDI UML, Rational Requisite Pro, SQL, PLSQL, Version One, Jira, SharePoint, MS Visio, MS Excel, MS Access, HP ALM.Senior Business AnalystDHHS IOWA - Des Moines, IAJune 2012 to June 2015The delivery of the 5010 transactions executed in multiple integrated releases and migration of MMIS along with system upgrade from ICD 9-10 in MMIS, as per the CMS guidelines. The scope of this project is planning, analysis, design, development and implementation required to implement the mandated HIPAA NCPDP Versions D.0 from 5.1 and electronic transaction standards.Job Responsibilities:• Developed and participated in business functional requirements planning and enhance IT's business knowledge base.• Managed requirements organization, prioritization and their lifecycle/traceability through technical solution delivery and transition to support and operations.• Worked with client to gather Business/Technical Requirements, Approval of CR (Change request), Design and Implementations for State MMIS.• Supported the complex MMIS system design, development, and implementation.• Responsible for designing future state processes for ICD 9-10 Crosswalk Table and drafted High Level Business Requirements for ICD 9-10 conversion mapping.• Responsible for conversion of HIPPA 4010 in the new system and eventually moving to HIPPA 5010.• Designed, developed, tested, documented and delivered technology solutions for Microsoft Dynamics ERP and CRM solutions including customizations and alterations to existing applications.• Worked on creating State based Rule requirement document with Rule ID (CFR number) and Request for Proposal document. (RPF).• Researched on state based rules, configuration to be implemented in integrated eligibility system.• Gained extensive experience in designing/modifying the CICS screens for various areas such as Enrollment, Billing, Provider Record and Reimbursement Status in MMIS.• Supported in developing the Data Conversion program/projects from legacy system to EPIC implementation (EMR).• Wrote clear, concise detailed System Requirements Specification (SRS) documents and user documentation in accordance to guidelines and standards of a level where developers can interpret, design and develop the application with minimum guidance.• For eligibility, responsible for creating wireframes for the web based application enhancement.• Experience in implementation of ICD-9 codes and ICD-10 codes changes in the current claim processing modules in MMIS.• Involved with the 837 (Claims and encounter), 835,834, 820 HIPPA-EDI Transaction Code Sets.• Analyzed the new NCPDP d.0 fields against existing NCPDP 5 fields and identified the modification, additions and deletion via the As-Is/To-Be process.• Tracked defects and assured overall performance of the pharmacy claims system.• Researched, validated, and resolved claims.• Worked on HP Quality Center 10.0 which include Defects Management, Test Plan and Dashboard.• Created application prototypes and performed screen mockups.• Documented Use Cases, Activity diagram, and process flow diagrams in MS Visio.• Talking to the client based on requirements of that particular defect, uploading document required, checking history, status notes, setting up resources to handle and fix it.• Worked on Rational Requisite Pro application to handle various requirements including Functional requirements, High-level requirements, Non-functional requirements, Scope statement and User requirements.• Prepared SQL queries and generated security reports,• Created standard business process models as well as conceptual prototypes and mock-ups when necessary.• Managed System Integration testing, functional testing, Automation testing for delivery teams and User Acceptance Testing.• Managed and documented business, functional and non-functional requirements.• Assisted in designing and implementing solutions for storing documents from Onbase repository.• Implemented Unified Modeling Language (UML) methodologies for process modeling and developing use cases.Environment: RUP, SQL Server, Jira, PL SQL, Oracle 12, Epic, Onbase, SharePoint, HP Quality center and ALM, Rational Requisite Pro, Hadoop, MS Access, Excel.Business System AnalystThe Ohio Casualty Insurance Company - Columbus, OHSeptember 2010 to May 2012The Ohio Casualty Insurance Company is one of America's private insurance providers. The project was to give the payers the clear vision of claim life cycle from submission to Ohio Casualty Insurance through payer adjunction. The project is to implement a web based claims processing and application health insurance claims automatically. It connected the organization to the largest all-payer network of commercial and government health plans nationwide to provide a wealth of real-time patient benefit information.Responsibilities:• Implemented the SDLC for the developing life cycle in agile approach and followed the standards process in the application.• Translated business requirements into functional requirements and approaches for developers.• Provided management support to the off-shore End to End integration/ Regression Test Team.• Workflow documentation and comprehensive training to the healthcare clients.• Analyzed corporate healthcare business processes to develop customized solutions.• Working with Medicare operational management to monitor, trend and report on operational metrics such as timeliness, workload, and staff trending, customer satisfaction, and other key measures to facilitate performance excellence.• Gathered requirements for Medicaid and CHIP insurance coverage and performed data analyses.• Analyze federal and state regulations/ policies for Medicaid and CHIP reimbursements.• Interacted with healthcare clients to gather requirements, objectives, and input and output requirement on payer reimbursement.• Developed Use case, Functional, Object diagrams using Rational Rose.• Supported in collecting HIPAA related EDI transactional data from data warehouse.• Worked on changes of implementation, expected of HIPAA X12 transactions EDI 837 (encounter),835, 270/271,278,834 in future upgraded system.• Responsible for architecting integrated HIPAA, HL7 messages, Medicare solutions.• Assisted in planning and test process for Pharmacy Claims.• Developed test cases and scripts for front end testing. Performed execution of test cases manually to verify expected results.• Ensured the accuracy and consistency of the data during the data loading process.• Assisted in documentation of the Onbase solutions using Microsoft Visio and Project.• Developed a detailed test plan and test cases to cover all the requirements.• Used Linux OS for application prototype and performed screen mockups.• Used Rational Rose to create UML diagrams such as use case, activity, sequence, class and component diagrams.• Provided support during go-live, and created user manuals.• Developed Flowchart and process diagram using Microsoft Visio.• Analyzed data architecture, documented and delivered data mapping, performed risk analysis.• Frequently communicated with developers to resolve technical issues.Environment: SQL, FACETS, IBM Cognos, MS Office, DB2, SharePoint, MS Visio, UML, Rational Rose, Jira, Windows XP.Business Analyst and Data AnalystIndus Services (Healthcare) - Hyderabad, TelanganaMay 2008 to August 2010Project Description: The HI-Exchange Project dealt with development of an online health information exchange (HIE) and a secure web portal to enable authorized Hospital providers to have fast and easy access to patient's electronic health record. The HI-Exchange web portal features EMR functions and Integrated Clinical decision Support tools for better care management. The project dealt with development of a Health Care Cost Containment System and implementation of an automated inter-operable web application that tracks patient medical history and health care plans via Viewer application and Electronic health records. The Viewer/ system provided online access to mobile patient records and improved communication in public health.Job Responsibilities:• Assist with creation and maintenance all necessary documentation and training materials for Epic Ambulatory application.• Performed analysis, design, development and maintenance of the Epic Ambulatory applications and other clinical information systems.• Experience with EPIC user and provider record provisioning, including the development of role-based, security classes, and user profiles.• Experience in Epic Resolute product implementation and deployment.• Hands on experience with Epic Hospital Billing and Ambulatory.• Experience with Epic Healthcare Information Systems.• Conducted user interviews, gathered requirements, and analyzed the requirements.• Worked with the business team to collect the business requirements, security and service level requirements and documented them.• Analyzed set behavior and contribution to business performance, critical business metrics & tracking underlying business trends using Business Objects.• Participated in the logical and physical database design sessions and developed design documents.• Performed collection, coding, and assessment and reporting of adverse event data using ARISg.• Worked in the ARISg Implementation of the EHR-Pharmacy Module.• Captured all HIPAA-related EDI data in the repository using FACETS.• Accepted inbound transactions from multiple sources using FACETS.• Supported integrated EDI batch processing and real-time EDI using FACETS.• Recommend tactic to implement HIPAA 4010 (EDI X12 835, 837,834,278,270) in the new System.• Worked on Electronic health record system as a CRM web based application.• Working Experience in Electronic Submissions in standard format E2B.Environment: SAS, MS Project, JAVA, MS Visio, MS Excel, MS PowerPoint, JAVA,  CRM Dynamics, MS Word, MS Access, EPIC, FACETS, and Rational Requisite Pro.,""• Experienced data analyst and business analyst with 10 years of experience in Business analysis and Project Management.• Good knowledge and experience in Software Development Life Cycle (SDLC) and its phases: Requirement gathering, Analysis, Design, Implementing, Testing, Deployment, and Maintenance.• Used various approaches of SDLC like Agile, RUP, and Waterfall• Experience in design, development, testing, implementation and support of Enterprise Resource Planning (ERP) and Business Process Modeling Notation.• Create Functional Specification Documents and Data Mapping Analysis for System Integrations.• Technical experience in Interfaces, Screen mockups, Data conversion and Data mapping.• Experience in conducting GAP analysis, SWOT analysis, Impact analysis, Cost benefit analysis, Risk analysis.• Well versed in Business Process Modeling with expertise in creating User Cases, Sequence Diagrams, Class Diagrams, Activity Diagrams, writing User Stories.• Experience in tracing requirements and using Requirement Traceability Matrix (RTM).• Good knowledge on Patient Protection and Affordability Care Act (PPACA), Clinical, Health insurance Marketplaces, Medicare, Medicaid, (CMS) Medicaid Management Information system (MMIS).• Knowledge of healthcare and pharmacy data (claims, billings, fees, eligibility, benefits, encounter) and statistical analyses.• Well versed in generating and evaluating Functional Requirement Documents (FRD), Business Requirement Documents (BRD), Work Breakdown Structure (WBS).• Well versed with the HIPPA 4010, 5010, ICD-9, ICD-10, HMO, PPO, HL7.• Conducted and participate in Joint Application Development (JAD). Worked with HIPPA ANSI X12 4010 and ANSI X12 5010, and medical transactions like 270, 271, 276,277, 835, 837I, 837P, 837D.• Highly motivated with multitasking capabilities, and analytic thinking. Efficient in working alone and in a team, with a proven ability to work under pressure, and meet deadlines.• Good interpersonal and communication skills, ability to work in a diverse environment, and highly desired to learn client's business requirements.TECHNICAL SKILLS:Methodologies              Agile, Scrum, RUP, WaterfallFront-End Tools            MS Excel, MS Office, MS ProjectTesting Tools              Testing Tools: Quality Care, HP ALM, HP Mercury Quality Center, Quick Test pro, SOAP UI, Log defectsBug Tracking Tools         Rational Clear Case, Jira, CA Rally, TFSModeling Tools             Rational Rose, MS Visio, Caliber RMProject Management Tools   MS Visio, MS Project, Share Point 2010, Version OneLanguages                  UML, XML, HTML, SQL C, C++, JAVADatabases                  IBM Mainframe, Oracle 12, FACETS, SQL Server, PL/SQLWeb Services               XML, XSD, JASON""";;;
"DATA ANALYST PRIVATE DATA CONSULTING PORTLAND - New York, NYJanuary 2018 to PresentDATA ANALY ST	SYSTEM DEVELOPER/ANAL YSTJANUARY 2018 - PRESENT	AUGUST 2014 - JANUARY 2018	SEPTEMBER 2012 - APRIL 2014Analytics Department LeadAccountable2015 to 2015for architecture, developing, clients requiring advanced analytics and	establishing, implementing, monitoring, and	and deploying 3 scalable, open-source problem-solving	strategies  for	data	maintaining post-adjudicated claims &	driven, health information systems. One deliverables in the Portland Metropolitan	eligibility data for over 500,000 lives for a	system (rabies vaccination system) leading to Area.	full rolling 10 years via pure automated,	an accredited publication with the American stable, and auditable SQL server procedures	Medical Informatics Association's 2015Symposium Hosted in Washing DC.,""Professional SkillsSYSTEM ANALYSIS AND DESIGN	BRANDING.	WEB-BASED DESIGN AND CODING.DATABASES DEVELOPMENT	MENTORING	VERSION CONTROL VIA GITHUBDATABASE ADMINISTRATION	SQL	HTMLS CSS 3DATABASE SECURITY	JAVA SDK & JDK	NODEJSDATA ARCHITECTURE	PYTHON	NPM BASHMICROSOFT SQL SERVER	C, C++, C# .NET	DATA VISUALIZATION.Object, CLR, Data Encryption, Dynamic	VBA	AM CHARTSDeveloper	Excel Outlook, Access, Visio, word PowerPoint	Dynamic charts via SQL ServerMICROSOFT OFFICE AND OTHER RELATED MS	X12 EDI DEVELOPMENT & IMPLEMENTATION	CRITICAL THINKINGOFFICE SUITE PRODUCTS	Working models.	i.e    boiling down seemingly complicated projectsExcel, Access, PowerPoint, Visio, BI, Word	MEDICAL/RX/ELIGIBILITY CLAIM EXTRACTS	to their base presumptions and specific client needpost-adjudicated and transactional file interfacing	thereby simplifying it:""";;;
Data Analyst Alphaport, Inc.at NASA Safety Center, Mishap Investigation Support Office - Cleveland, OHJune 2013 to February 2017Adapted Maximum Probable Loss insurance model to NASA mishap data. Closely predictedmishaps with regression on 2 years of preceding monthly mishap data. Utilized medianmonthly mishap residuals to correct for seasonal fluctuations. Predicted lesser frequencymishap data subsets via cumulative distribution fit to logarithmic model.Studied components of corrective actions associated with decreased recurrence of seriousincidents. NASA Incident Recurrence - Study Summary completed March – April 2017 at NASA Safety Center, JJR Solutions, LLC.Utilized conditional probability to verify math used to estimate XS-1 launch success basedupon historical launch success and human factor remedies.Proposed an alternate survival model whereby the likelihood of escaping a premature rocketengine ignition decreases significantly after a few seconds in contrast to the previous modelwhich predicted a flat survival rate.Demonstrated the capabilities of SPSS by using PowerPoint to illustrate the steps taken toanalyze lost work days. Annual Mishap Program Working Group Meeting, NASA Goddard Space Flight Center, Greenbelt, Maryland.Research AssociateLakeland Community College, Office of Institutional Research - Kirtland, OHOctober 2011 to April 2013Used geospatial mapping to assess potential online learning market amongst student population by visualizing distances from home to campus. Assisted department chairs and grant administrators with integration and analysis of student academic performance, retention and persistence data. Constructed and implemented online survey instruments. Analyzed data and reported results.Manager of PlanningLake County ADAMHS Board, Department of Research, Planning and Evaluation - Painesville, OHJuly 2007 to April 2010Assured HIPAA privacy and security compliance. Developed batch file programs to automate and confirm success of weekly claims uploads and database updates.Manager of MISLake County ADAMHS Board, Department of Research, Planning and Evaluation - Painesville, OHApril 2003 to July 2007Implemented Ohio MACSIS version of the HIPAA 837 Professional Health Care Claim format amongst contract agencies.Identified high-utilizing consumers. Found 1% of consumers to be utilizing 12% of resources.Research AssistantLake County ADAMHS Board, Department of Research, Planning and Evaluation - Painesville, OHMay 1991 to April 2003Identified senior and Hispanic populations as potentially underserved.Determined previous functional scale values and combinations resulting in successful severe mental illness certification. Applied these rules to current scores to predict and plan for future severe mental illness funding.Research AssistantKent State University, Department of Sociology - Kent, OHAugust 1990 to May 1991Utilized IBM mainframe computer to convert hardcopy student evaluation data to electronic form. Wrote SPSS syntax to define data file variables. Performed data entry.,Thank you for your consideration.;;;
"Data Analyst / Data EntryData Synthesis - Red Lodge, MTOctober 2013 to PresentAt Data Synthesis I work as a Data Analyst, Report Builder as well as Data Entry. Iwork for a company that contracts to a Children's Facility in California (Casa Pacifica)that works with at risk youth. I go through their medical records and data to find dataentry mistakes or missing data, analyze and report their data for grants, countyrequests, or just company improvements and efficiency. I also report their data to graphs and/or reports. I make reports that the faculty can use to dig deeper into theirprograms data. I design surveys for the company and do monthly scorecards for eachprogram (19) to report what services and how many of those services, their individualprogram has provided in the last month/quarter. I also run VCBH/VCOS quarterlyreports.There is also a lot of data entry as well as correspondence involved and frequent on the fly data requests made by the program administrators.I work with Microsoft Word, Excel, Citrix/Avatar, Crystal Reports, Power Point, SurveyMonkey, Outlook and many other computer programs in this job at Data Synthesis.Service WriterThunder Mountain Fleet Services - Cody, WYOctober 2010 to March 2011At Thunder Mountain Services, I was the front man in the office. I wouldgreet customers as the came in, answer phone calls, schedule appointments, trackprogress in the shop, and write up the service orders in the computer system. I doublechecked parts and hours to make certain the item(s) and the times are billed out on the invoices. I also enter a job description so the customer can see what exactly wasdone on their vehicle. I did a lot of filing and organizing as well as helped when somebody had questions with computer programs. I designed two spreadsheets for thecompany to effectively track progress and productivity.Customer service and interactionColorado Tubulars/Aztec Pipe - Glendive, MTOctober 2008 to October 2010Northern Region Inventory/OfficeAt CTAP I kept inventory on the different oil pipe in the Glendive yard, as well as theBowman and Ross ND., yards. I entered information into the Ocularis computersystem, and made sure tallies got received/billed in a timely fashion by the accountspayable/receivable dept. My new task before I left CTAP, had been to monitorinventories and forecast for upcoming rigs for upcoming months. AtCTAP I worked as a team member, but also individually.Accounts ReceivableGabert Clinic - Glendive, MTJanuary 2005 to September 2007I received payments from insurance companies; Medicare, Medicaid, BCBS, and all other individual insurances, personal self-payments, and all monies that are to be applied to individuals accounts. I also made adjustments on their accounts per Insurance Explanation of Benefits. I made sure that the ledger balanced and that my checks and cash matched my receipts. Also, I helped find differences in the hospitals general ledger and the clinics. I received payments from insurance companies; Medicare, Medicaid, BCBS, and all other individual insurances, personal self-payments, and all monies that are to be applied to individuals accounts. I also made adjustments on their accounts per Insurance Explanation of Benefits. I made sure that the ledger balanced and that my checks and cash matched my receipts.Also, I helped find differences in the hospitals general ledger and the clinics.,Skills & Tools• Accounts Payable • E-mail • Photo Shop• Accounts Receivable • Excel • Power Point• Banking • General Ledger • Print Shop• Cash Handling • General Office • QuickBooks Pro• Clean Driving Record • Insurance • Ten Key• Collections • Math Skills • Typing (word processing)• Computer Accounting • Microsoft Word • Windows 2000• Computer Literate • Multi-Line Phone • Windows XP• Customer Service • Outlook • Word Perfect• Data Entry • Own Personal Computer";;;
DATA ANALYST CRS DATAFebruary 2014 to PresentExtensive work with T-SQL - Data processing/manipulation/dynamic SQL/stored procedures to support backend database for Real Estate software package.Software QA Analyst/TesterTEK SYSTEMS2011 to 2013involving automated and manual processes, test case design and development, data validation.  Agile Methodology utilized.Software QA Analyst/TesterSCRIPPS2011 to 2013involving automated and manual processes, test case design and development, SQL data validation. Extensive use with MS Office ProductsSoftware Quality Assurance AnalystEnvironmental Systems Company - Knoxville, TNJune 2000 to May 2006Developing test plans/cases for windows-based software, utilizing data loggers for various forms of environmental monitoring, including CEM and Ambient.,SKILLSI am completely self-taught in the technical industry in which I have worked for decades. I am not afraid of a challenge and love to learn new things. My writing and communication skills are a good fit for most positions and creativity is my biggest asset.BARBARA HAWLEYDATA ANALYST | SOFTWAREQA865-332-8042;;;
"Data Analyst Data Doc September 2017 to July 2018• Develop, analyze, and evaluate data to create and maintain business intelligence frameworks• Update/create technical specifications: data mapping, data flows, dashboard content, data dictionaries, and relational diagrams• Liaison between technical and non-technical teams to produce reporting metrics. Conduct ad hoc data analysis and data quality investigations• Work closely with stakeholders across the company to gather business requirements, deliver quality reports• Communicate data processes to all stakeholders; routinely socialize updates and prioritize list of improvements and initiatives• Maintain risk controls, identify best practices, procedures, policies, templates and testing deemed necessary for data testing• Interact with vendor support representatives and access and use a variety of resources to research and find solutions for complex technical support issuesTechnical Quality ManagerAlpha EMCAugust 2016 to June 2017• Troubleshoot and resolve complex network/systems hardware and software issues related to data communications networks, client personal computing devices and voice communications• Partner with engineering, operations and other internal teams to communicate relevant technical issues in effort to mitigate call reoccurrences• Maintain logs and technical records related to reported issues and incidents; follow-up with clients to ensure timely resolution and customer satisfaction.• Identify and report trends and assists in developing action plans and remedial/preventative solutions• Communicate with internal/external customers and other parties as appropriate to gather information and clarify inconsistent, incorrect or missing information• Provide guidance and training as required to lower level, interns, temporary employees, etc.• Assist clients with technical education and guidance related to enterprise hardware and software resolutionIT AssociateWayfairJune 2015 to July 2016• Resolve first level technical issues related to software and hardware troubleshooting, upgrades, installations and changes• Responds to support requests (i.e., telephone, e-mail, support-portal and personnel requests) and resolve technical issues• Diagnose system errors and provide technical support to end-users both via remote connectivity solutions• Stay current with IT environment, changes, and updates; Identify and escalate problem tickets and urgent situations to the proper resource• Record, track, and document IT request, including all successful and unsuccessful decisions made, and actions taken, through to final resolution• Track and monitor problem resolution rates and status for all active IT-related helpdesk tickets• Manage simultaneous customer cases in a highly demanding environment and resolve issues using a company internal knowledge base• Escalate potential issues/complex problems in a timely manner that are not in-scope,""CORE COMPETENCIESProficient Troubleshooter	ProactiveVast Technical Experience	Interpersonal skills";" listening, speaking and writingAdvanced Microsoft Office (Excel, SharePoint, Word, and PowerPoint)   Extremely AnalyticalStrive in Matrix Environments   Exceptional Telephone EtiquetteReporting Analytics	Quality FocusedSuperb Organization	Influential Leader& Team Player""";;
"Sr. Business Analyst Data Analyst March 2018 to PresentSr. Business Analyst/ Data AnalystThis project was to make enhancement to a portfolio management application which allowed users to perform daily activities to manage their portfolios from account reconciliation, portfolio modeling and rebalancing, corporate actions to exposure and performance reporting.Responsibilities• Worked closely with PMO team to present, justify and negotiate the estimate with business stakeholders• Created and prioritized the Back Log, coordinated Planning Sessions and maintained User Stories and Acceptance Criteria• Involved in Corporate Actions like Bonus, stock splits, mergers and acquisitions of equities in capital markets for maintenance of portfolios.• Designed Use Case Diagrams and wrote specifications in the Use Case Specification documents based on requirements gathered.• Performed research and analysis across multiple for capital market products like equities and fixed income securities to identify attributes that should be incorporated in the portfolio reports• Created mock up screens for various modules including Portfolio/NAV Accounting Checklists, Portfolio Summary and various portfolio reports of Fixed Income funds.• Utilized SQL queries to access data stored in the database for analysis and data cleansing for return on investment• Analyzed the data elements for Data migration and ETL mapping from source to target data environment• Perform Data Analysis, Pattern Analysis, Data Validation and Data Quality on existing SQL Server Database.• Arranged Findings reviews sessions with Business and IT team for potential issue counts, impact on Day 1 release.• Involved in designing and preparing test scenarios, test plans, test cases and test data• Conducted analysis of the data collected and assured compliance standards.Environment: Agile Scrum, MS Visio, MS Word, MS Excel, JIRA, Confluence, HP ALM, SQL SERVER, Tableau.Business Analyst/ Data AnalystMizuho SecuritiesDecember 2016 to February 2018The project was involved in the re-engineering Portfolio Management System. Portfolio ManagementSystem allows the user to get a view of the comprehensive account summary that shows the portfolio value,Cash balance, and securities held in all of the banks accounts.Responsibilities• Captured and analyzed requirements through interactions with stakeholders.• Analyzed various components of client portfolio like equities, fixed income securities in capital markets to identify the attributes to incorporate in reports.• Conducted meetings and review of the documents with the concerned teams.• Accumulated business requirements from various business users and translated into business requirements.• Documented discussions, stored the requirements and tracked the changes maintaining.• Created use case scenarios and documents work flow and business process with use case diagrams.• Wrote SQL queries and assisted in mapping Data through different sources to process the data into the staging system• Developed data mapping for ETL process by analyzing the of logical & physical data model to create data mapping for ETL process• Read SQL for Data verification and Data Validation using SQL queries• Interpret data from primary and secondary sources and provide ongoing reports.• Performed data profiling, cleansing & selecting data using Excel and SQL.• Defined and created the Test strategies and associated scripts for the verification and validation of all defined business requirements and associated functionality.• Reviewed and analyzed the Use cases and came up with System design and Test Plan Templates and developed test plans, test cases and test strategyEnvironment: Agile Scrum, SQL Server, MS Visio-UML, JIRA, Confluence, HP Quality Center, MS Office SuiteBusiness ANalyst/ Data AnalystAlly FinancialJanuary 2015 to March 2016Project was based on customizing the Wealth Management platform that integrates resources and aggregates information, allowing Advisors to conduct business quickly and efficiently. The project was on wealth management components including bonds, equity and derivatives. The purpose of the system was to enable to users to manage individual portfolios.Responsibilities• Worked with the development team to define system specifications based on the business requirements• Worked with the different capital market products like fixed Income, equities and derivatives to understand the current business flow.• Generated asset allocation and better forecasting and financial planning to improve clients' portfolios; made recommendations for asset class diversification using capital market products.• Interviewed and worked closely with the modelers and business partners to define their requirements and document the requirements• Created Data specification documents and Service level agreements(SLA) to ensure proper data is received• Extracted data from data sources and created data mapping documents to support the development of database for risk modeling and reporting• Wrote simple complex SQL queries to streamline the data• Unified with Data Governance team the correct access and quality of data is met according to the requirement• Created Data Mapping document and mapped the data between EDW to Data Mart.• Perform SQL queries for Data Manipulation and Data Validation using SQL queries/Excel• Participated in meetings at the operational and project level, provide continuous feedback on project statusEnvironment: Agile Scrum, JIRA, Confluence, HP ALM, MS Project, MS Visio-UML, SQL server, TableauBusiness Analyst/ Data AnalystHarris AssociatesApril 2013 to December 2014The goal of the project was to enhance a funds and stock tracking application which provides daily trading volume, price change, and market capital change information, as well as generates weekly, monthly, and yearly reports on ROI, EPS, P/E Ratio, ROE, and CAGR for selected NYSE listed companies and funds managed by Harris Associates.Responsibilities• Incorporated financial data from Bloomberg, Yahoo finance and Morningstar for capital market products like equities and fixed income securities.• Conducted surveys with prospective users to gather requirements• Utilized SQL queries to access data stored in the database for analysis.• Verified accuracy of data analysis and coordinated with the business.• Managed all the high-level requirements and translated business requirements into functional requirements.• Coordinated daily meeting to ensure current development met the standard and timeline.• Communicated functional requirements with developers and QA in the testing process.• Developed test cases and wrote test plans to help developers locate and fix the defects.• Involved in the reviewing and analyzing processes of financial reports (balance sheet, income statement, and cash flow statement) from target companies.• Facilitated mapping review, data modeling, data profiling, data warehousing, data mapping of accounts for various financial clients• Participated in review session to help client understand our goal and collect feedback.• Facilitated User acceptance testing with clients and demonstrated features to track price and report ROI, EPS, P/E Ratio, ROE and CAGR of capital markets equities for selected companies in NYSE• Managed sign-off for deliverables (functional and non-functional specifications, change requests, user acceptance testing, and production deployment).Environment: Agile Scrum, JIRA, Confluence, SQL Server, MS Visio-UML, MS Word, MS Excel,Business AnalystGlobe Capital MarketsJuly 2011 to March 2013The project goal was to upgrade the online system to make it more convenient for user to handle different accounts as well as to track the transaction history.Responsibilities• Communicated the project plan tasks, accomplishments and status to Project/Program Management on a weekly basis.• Gathered requirements from key stakeholders, customers and subject matter experts to define the scope and requirements of online banking system.• Defined the context of the system by creating various use cases, developed system requirements specifications encompassing Functional and Non-Functional requirements.• Created screen mockups for the new transaction-filtering functionality• Developed test scripts, test cases and test logs and conducted functional/regression testing in the testing environments• Actively participated in daily bug triage meetings, reviews and walkthroughs and interacted with developers to ensure high quality software.• Prepared testing data for the User Acceptance Testing as well as guided the business testers during UAT.• Developed plans for verification and validation of requirements at all levels so that developed software successfully fulfilled user expectations and business needs.Environment: Waterfall, Rally, Rational Suite, Share point, MS Visio-UML, HP Quality Center, MS Office Suite,""Methodologies:Agile, Waterfall, Rational Unified Process (RUP)""";;;
"Data Analyst Cloud Big Data Technologies - New York, NYSeptember 2018 to Present·       Operate on EHR data, prospective and retrospective data analysis and epidemiology studies and present HEOR outcomes with channel partners, clients or healthcare professionals.·        Execute real world data studies on topics like patient unmet needs, economic burden, disease burden to understand value of treatment.·       Communicate and translate HEOR value proposition effectively and creatively through manuscripts and appropriate tools for payers.PresidentISPOR (St. John's University Student Chapter) - New York, NYMay 2017 to May 2018I conducted and arranged 200% more guest lectures than last president from industries, universities and consultants.Arranged biweekly journal club meetings, took an initiative to increase awareness about HEOR and ISPOR to undergraduates.o  Organized Health Economics and Outcomes Research (HEOR) related guest lectures, coordinated social activities (New York Cares day and University Service Day).o  Communicated with other members of the STJ-ISPOR chapter and faculty about events of STJ-ISPOR during the academic year.o  Prepared strategic plan framework for the ISPOR student research competition, 2018.Global ISPOR Social network marketingInternational Society for Pharmacoeconomics and Outcomes Research (ISPOR) - New York, NYMay 2017 to May 2018We used social networking platform to market ISPOR globally.The platforms like Twitter, Facebook and ISPOR apk. were really helpful in marketing ISPOR and connect people throughout the world.This helped us in adding more than 10 new chapters globally last year.Conference Services AssistantSt. John's University - New York, NYOctober 2016 to May 2018Booked more than 2000 all types of internal and external events (Sports and Cultural events, Educational Symposiums, International Conferences, Comicon, Job fairs) ranging from 5 people to 4000 people sizes.• Spearheaded a team and training of new student workers- Managed all sorts of crisis even at a short notice period and got praised for the best resource allocation during events booking.- Coordinatedf between various departments for providing best services, events setups, facilities or any media instruments setup.Research AssistantSt. John's University - New York, NYOctober 2016 to May 2018• Was awarded the research grant sponsorship of amount $3000 to work on my research topic.Research Title: “Use of Comic Books in pharmacy curriculum to develop feeling of sympathy and empathy towards patients and caregivers.”Objective: To explore if healthcare related comics can be used as a medium to develop feelings (sympathy and empathy) in pharmacy students towards patients and caregivers. ·  The prospective study (16 weeks) was conducted where 200 students were informed to read 2 healthcare comic books and at the end of semester fill up a survey designed for this research (IRB Approved).·  The results of my research provide an evidence for organizations like AACP and ACPE to implement comic books as an innovation in curriculum towards developing sympathy & empathy feelings in students.Data Analysis: Used SPSS software (Version 23) in accordance with statistical reliability and variance estimation.• Hands-on training on Federal, State and Private Research Grants Application process, NIH Research Project Grant (Parent R01), AHRQ (R03), Academic Research (R15), Exploratory/Development Research (R21).• Proactively worked on several projects in Research Opportunity Center and handled Marketing of OGSR department internally.Market Research ManagerBlithia - Mumbai IndiaSeptember 2015 to July 2016·       Spearheaded market research and branding of the company towards customer centered value proposition.·       Conducted market research to utilize market insights for designing prices and reimbursement strategies.·       Represented cross functional department issues and coordinated between internal partners such as legal team, competitive intelligence and distribution team.·       Formed strong relationships with KOLs, clients, franchises and contract teams.Market AnalystBecton and Dickinson (BD) - Mumbai, IndiaJuly 2013 to August 2015·       Analyzed business trends using EHR data and claims to drive robust forecasting and study outcomes to meet both commercial and market penetration objectives.·       Handled in-vitro diagnostic (IVD) business of more than USD 1M with 18% growth rate YOY. Generated new business potential worth more than US 200K based on market insights.·       Implemented patient centered outcomes (PRO) approach, analyzed, interpreted and presented HEOR outcomes with professionals.·       Developed strong relationships with KOLs and teams across the organization (Consumer Insights, Regulatory, Finance, Operations, Supply Chain).·       Working knowledge of invoice processing, product proposals, regulatory and commercial compliance issues pertaining to our business.·       Trained more than 500 healthcare professionals and conducted several social awareness programs.TOP ACCOMPLISHMENTS• Won B.J. Wadia hospital Contract with a bundle equipment deal (3 instruments).• One of the biggest competitor breakthroughs in Asia-Pacific region: (Wockhardt Hospitals- Chain) full product line and national level business tie-up with BD.Committee Member (Volunteer)Magazine Committee - Pune, Maharashtra2011 to 2013Academic InternBlue Cross Laboratories Ltd - Nashik, MaharashtraApril 2012 to September 2012·       Hands on experience in production department for liquid formulations and tablets.·       Hands on experience with documentation processes in QA and QC to ensure strict compliance with GMP.·       Got an opportunity to work with QA personnel on the shop-floor to check batches manufactured as per in-house specifications.·       At the end, inspected the packaging lines as per the guidelines and regulations for 2 most manufactured products in (oral syrup and tablet) in the company.Cultural in-chargeSinhgad College of Pharmacy - Pune, Maharashtra2011 to 2012College representativestudent's council2010 to 2011,""POSTER PRESENTATIONS• University Research Day (April 2018): “Use of Comic books in pharmacy curriculum to develop feelings of sympathy and empathy among pharmacy students.” In St. John’s University, New York.• Pharmeet (2013): “Sustained release floating in-situ gel of acyclovir” (University of Pune).• National pharmacy week (2012): ‘’Hypertension and antihypertensive drugs’’ (University of Pune).""";;;
"Sr. Clinical Data Analyst Data Mining, SQL, CLIA, COLA - Marietta, GAAugust 2016 to PresentQ2 Lab SolutionsResponsibilities: * Implemented, Created, Revised, Reviewed and Supported various software applications within LIMS, SharePoint, ELVIS, LOTUS NOTES and Workday.  Supported multiple department including project management, Quality Assurance, Programming and IT.* Serve as a Sr.  Clinical Data Analyst for global projects, coordinating with senior staff and peers building specific testing protocols, integrating multiple systems by mirroring interfaces between regions and laboratories.* Play lead role in verifying quality of laboratory testing by reviewing detailed plans to produce a cohesive and compliant result that meets business model specifications based on ISO documents.* Review and submit system test cases to document results.* Coordinated project work task plans, timelines and schedules by working with personnel to improve process flow within the LIMS software environment and TCWA LIS.* Proficient in defining and validating protocols for clinical studies and handling trial tasks throughout the data management lifecycle.* Interrelates with the programming team, functional leads, project managers and all other stake holders to identify, develop and implement project solutions.* Manage projects working with customer data managers and internal team members to ensure protocol adherence, workload projections and provide technical expertise on several global studies and serve in a leadership role.* Provides scientific and technical guidance while developing strategic communication plans appropriately.* Collaborate with colleagues during strategic planning meeting regarding project timelines, and project-related issues focusing on capabilities, assay development, biomarkers, clinical trial materials, laboratory testing, laboratory operations and specimen management.* Extract data from the research repository (SQL) write simple calculations to prepare analysis of datasets according to study protocol or SAP.Certifying ScientistMarch 2016 to August 2016RemoteAmeritoxResponsibilities: * Certified, reviewed and released patient results from beginning to end.* Remote Certifier.* Validated and troubleshoot LC-MS/MS methods for analysis of drug consumption levels and possible abuse (such as Opiates, Barbiturates, Cannabinoids and PCP) in urine.* Process, configure and analyze chromatographic peaks.* Remotely communicate with senior management and peers to discuss trends or any anomaly found in my review of analytes.* Analyzed abundance, intensity, area, height, mass transitions, polarity, internal standards, retention times and peak width when determining chromatographic peak readings.* Maintain and ensure a high level of accuracy and quality for results, records and documentation.* Contributed, recommended and developed ideas for continuous process improvement and performance of procedures, workflow and quality.* Learn and accurately execute daily: Laboratory Information Management Software (LIMS) to process samples; LC/MS/MS confirmation procedures; analysis, review, and reporting of test results.* Interpret all confirmatory, screening and specimen validity data and chain of custody data accurately.* Assist in investigation of any anomalies that are discovered with respect to sample preparation and instrumentation.* Run validation calibration, calibration verification and 20 points for QC sets with correlation samples.Certifying Scientist/Analytical ChemistUPS - Stockbridge, GAMarch 2013 to October 2015GAResponsibilities: * Set up high complexity toxicology start up lab (installation, compressor, UPS, air dryer, nitrogen setup, validation, pre- audit preparations).* Work directly with engineers, application chemist and PhD scientist to build * Proficient in LCMS theory and method development * Run optimizer for each analyte to determine optimal collision energies, voltage and fragmentors.* Familiar with CLIA and CAP guidelines.* Auditing of QC log books, inventory, reagents, solvents and SOP protocols.* Operator of API 4000 LC/MS/MS, Shimadzu Autosampler.* Responsible for complete maintenance of LCMS (cleaning spray chamber and spray shield, sonicating and nebulizer within source, changing column, purging pump lines on rough pump, perform check and autotuning, changing capillary.* Prepping, running and analyzing clinical patient samples through use of EZ Runs Quantitative software.* Analyzing abundance, intensity, area height mass transition, polarity, internal standards, calibrators to determine chromatographic peaks analysis.* Loading .csv files to R to organize and manipulate data ran on LCMS.* Utilize Tableau software to data mine and visualize patters and trends within assays that are ran daily on LCMS.* Utilize R studio and R program editor and console to define variables and to calculate standard deviations and coefficient of variations.* Assisting management with laboratory audits; compiling temperature, calibration verification, AU Olympus, LCMS maintenance logs and laboratory instruments.* Identify patient samples requiring reinjections or re-extractions following established protocols.* Participate in developing new testing opportunities and method development as needed.* Responsible for handling the entry and maintenance of large amounts of clinical data within LIMS environment as well as implementing and adhering to strong compliance controls regarding data, providing high level analysis and reporting for long term or recurring projects.ICP-MS Chemistry Laboratory TechnologistMetametrix Clinical Laboratory - Stockbridge, GAJune 2010 to March 2013Responsibilities: * Trained all new staff on introductory mechanics and standards of the laboratory and created a exam that they were required to pass before beginning assigned laboratory task.* Operator of specialty instruments such as LC/MS, GC/MS, HP/LC, UP/LC, ICP/MS; and automated chemistry instrument such as AU4000.* Handle bio-hazardous body fluids such as serum, plasma, whole blood and hair following universal handling precaution. May also handle urine and stool.* Prepares samples for quantitative analysis following documented protocol (SOP) for various chemistry assays.* Perform instrument daily maintenance and instrument cleaning and shutdown procedure as required.* Runs quality controls with every run, performs basic troubleshooting as needed, and enters QC into EZ runs software before reporting final run results.* Creating internal standards, calibrators and controls from scratch.* Responsible for three clinical lab tests from start to finish, including Whole Blood, Red Blood and Hair metal testing.* Verify and release patient results to physicians, clinics and hospitals.* Pull and process patient batches using STARLIMS software system.Laboratory Technician (FRAC)American Red Cross - Duluth, GAJune 2008 to June 2010Responsibilities: * Trusted to work in an FDA regulated environment and adhere to strict regulations * Manufacture, store and distribute blood products/samples. Meet the quality and quantity production and distribution goals established by designated department.* Perform data entry and operated the computer programs associated with component production, labeling, storage and shipment of regulated blood and blood products.* Maintain accurate, legible and complete manufacturing department records.* Ability to recognize and resolve testing irregularities and assist other departments in problem resolution and cross training * Perform the quarantine and disposition of unacceptable products/samples.* Responsible for performing good inventory management practices throughout the manufacturing and shipping process * Expected to meet assigned objectives independently * Trained and practiced daily cGMP, cGLP, OSHA, and HIPPA and tested on knowledge quarterly,""PROFESSIONAL COMPUTER SOFTWARE SKILLS:SQL	LIS Configuration	TableauMicrosoft Office	Small scale data mining	R Studio/R Program* Over 11 years of hands on functioning laboratory skills* 4 years of LCMS certifying and method development experience in drug management, analytical, and GMP pharmaceutical in a high complexity laboratory setting.* 3 years of clinical laboratory information data experience, reviewing test cases, creating specifically designed test codes and assuring quality and compliance of assignment based off ICH guidelines and SOP documents.* Interfaced directly with a diverse population of patients, respond to various inquiries and concerns* Ensured quality control of laboratory procedures, equipment, functionality and regulatory complianceComputer Skills:SharePoint, SQL Server, Lotus Notes database, TopCat, QLS, PeopleSoft, StarLIMS, NewLims, QLMS, LIMS, LIS, LTMS, FTP Client, Cisco AnyConnect Security Client, Elvis database, MultiQuant software, Analyst software, EZ-runs software, Chemstation software, Empower software, MassHunter software, LabSolutions software, Microsoft Office, Internet Explorer, typing speed 60-70 (wpm)""";;;
"Data Analyst Data Analysis at IPS CorporationJanuary 2018 to March 2018• Clean up using excel macro, functions and VBA code• Reconcile accounting data to balance the account payable and receivable• Insert data into Microsoft Access and create an interface through Microsoft Excel• Aggregate data and present visual summary• Sumarize balance statement with activities from Gneral LedgerVarious administrative tasks as requiredData Analysis at VSolvit LLCSeptember 2017 to December 2017September 2017 - December 2017• Clean up design and implementation of existing Google Sheets documents• Design and develop Google Sheets solution to support corporate goals• Maintenance of existing Google Sheets files• Conversion from Microsoft to Google for existing documents.• QA testing for SW Development projects• Various administrative tasks as required.Senior Project ChiefAugust 2016 to May 2017• Media Management Web Application - using Java EE, MySQL for back end, JSF, CSS, HTML and JavaScript for front tend, and deploy the application onto Amazon Cloud Service• create, modify, and implement process and workflow• coordinate module development, manage software version/artifact• test each software according a test plan and match software design specifications• design, debug and implement software in accordance to design specificationsSupply Accountant and Operational ClerkUS Marine CorpsDecember 2007 to January 2016• Created, stored and maintained all related documentations for each expenditure account• Manage a warehouse and related documentation to ensure federal compliance• Supervised supply requisitions and three junior supply clerks,""Technical Skill• Microsoft Office 365, MySQL, Google Sheets, Google Docs• Excel Function: Lookup, VLookup, HLookup, Index Match, Nested """"If"""" formulas, Countif, Sumifs• GitHub, Java Python, Access, Amazon Cloud Service, VBA, SQL• Java EE, JSF, CSS, HTML, JavaScript, PHP• Microsoft Operating System, Mac OS, Linux OS""";;;
"Data Conversions / Senior report analystData Conversions / Risk2007 to Presentmanagement•  My duties included analyzing declined transactions to evaluate the risk of fraud,analyzing new accounts for suspicion of fraud, and assisting customers with fraudinquiries and refunds as needed.Data Conversions / Senior report analyst•  My duties included creating questionnaires for the customer service reps to fill out after a contact via phone, email, or chat, compiling the data into a Excel spreadsheet to givea visual representation of metrics for each call group and each customer service rep'smetrics.Data Conversions / Product liaison•  My duties included assisting marketing, shipping, and support for products and being a general liaison between management and customer service reps.Data Conversions / Complianceadministrator•  My duties included entering confidential information into a compliance database.   Ideveloped a tracking database using Excel, to track incoming media and compliancydocuments.   I developed a tracking system for the compliancy department to trackindividual metrics to allow the management team to view and evaluate individuals taskaccomplishments. I worked with the IT department to develop a tracking database for media, so the entire company could view the progress of media through the workflow.  Ideveloped a tracking sheet to accompany media through the work process of eachstation through the compliancy department to allow users and others to view the media's progression through the department and help maintain accountability andaccuracy of work.Document management associate IIPRA International2004 to 2006CRF scanning - My duties included processing and scanning of clinical trial documents,filing them in their proper global document databases, using remote databaseconnection to verify documents placed in proper global databases. I also assisted with the manual filing of paper documents so the paper files reflect the Electronic TrialMaster files.•  Account contact manager - My duties included extracting information provided on FDAdocuments to create a global web-based contact database and providing the globalcompany of PRA International a quick and accurate reference library of contactinformation for doctors, vendors, organizations, clinical trial site and other contactinformation.REALTOR, licensed in Kansas and MissouriHarmon Realty Group, Inc2003 to 2006My duties included providing assistance in the marketing of residential properties and developing and implementing marketingcampaigns to effectively conclude the sale of residential properties.  I also providedbuyers assistance with the process of purchasing properties through effectivenegotiating skills.   Coordinated and helped buyers and sellers through the financing and closing processes of purchasing residential properties, provided sellers and otheragents with virtual tours by developing and maintaining KSMOvitualtours.com, providedagent services by designing property flyers to promote residential properties for sale, and assisted in the training and mentoring of new agents to realize their maximumpotential.Office ManagerPROSOCO, Inc1999 to 2004Office Manage - My duties included answering and directing multiple phone lines to appropriate departments, collecting and distributing all in-coming and out-going mail,creating several electronic forms for the use of the Human Resources department to letemployees coordinate request and process documents in a more efficient and expedient manner which allowed Human Resources to track the documentselectronically.  I also maintained and ordered office supplies for the corporate staff of30 and invoiced copy distribution for all 60  manufacturer's reps and all 10  salesmangers.ProgrammerA & A Electronics1993 to 1998Document Control - My duties included creating documents to track printed circuitboard serialization thru Excel software and instructional documents for printed circuitboard processes to flow through each department throughout the shop.•  Programmer - My duties included burning programming into computer chips using a data I/O machine.,""• Very strong computer skills, using, Microsoft Word, Excel, Power Point, Outlook, Publisher, andPhotoshop.• Very strong organizational skills• Self-starter with little or no supervision required• Able to handle multi-task• Very detail-oriented• Fast learner with the ability to adapt to new ideas, processes, and software""";;;
"Data Analyst The Analyst Syndicate July 2018 to Present• Research Analyst for blogging on the subject of Mobile Robotics, Drones, Automation, Autonomy, Machine Learning, Machine Vision and Artificial Intelligence. • Part of leadership decisions regarding business model, plan, design, and content. • Meets for Vendor Briefings and round table discussions using video conferencing.Consultant/Contractor/ResearcherGPVH Consulting - Warrenton, OROctober 2017 to PresentConsultations regarding Robots, Automation, Drones in Commercial and Consumer markets. Technology Research, collecting data sets--company information, market information.Sr. Research AnalystGartner1999 to 2017Researches all aspects of Drones, Robotics andResearch / AnalysisAutomation Several services to identify companies for surveys, as it pertains to Commercial / Industrial, Consumer, Military financial data, contacts, vendor reviews• Project Manager: Annual Semiconductor Market Share• Leader: forum for Drones & Robots (drove research) Facilitator / Motivator• Forecasts Military semiconductors, IoT Military, Commercial Demonstrated people skills to lead, communicate,Drones, all robotics and automation motivate, participate in projects.• Advises clients on implementation, evaluation, and augmentation of robotics/automation Deadline oriented.• Wrote prediction/trends documents on drones, robotics, Phone Skillsautomation• Identified ""Cool Vendors"" in drones and robotics markets Engages clients regularly and • Created/maintained Hype Cycle for Drones and Mobile successfullyRobots• Instrumental in coordinating major projects to communicate, Public Speakingshare and coordinate to a mutual product releases Public demonstrations/presentation• Spoke with Clients and Press daily in areas of expertiseBusiness AnalystVoice-Over1996 to 1999LSI Logic		Interviewing, hosting, paneling•     Liaison between Manufacturing and IT                                   Computer / Software•     Helped identify new systems for data captureAll MS Office Suite products (including macros, advancedStatistical AnalystCompression Labs1994 to 1996functions)Compression Labs (CLI)Adobe Publishing products•     Built statistical infrastructure for QA and Manufacturing•     Trained meeting facilitatorQuerying SQLStatistical AnalystQuantrix1991 to 1994Verilink		Hyperion ESSbase•     Created statistical data collection for manufacturing and qualitycontrol		WebEx•     Briefed management daily on findings                                      SkypeIT Operations SupervisorPayfax1988 to 1991•     In charge of daily machine maintenance calls•     Automated Process of Credit Card payments                                 Facebook, Twitter, LinkedIn, Instagram, Google Suite•     Managed team of 4 programmersMailChimp,Intuitive skills to picking-up and learning new software/systems:LogicCommon Sense";;;
"Senior Data Analyst - Nielsen ScarboroughData Enhancement GroupAugust 2018 to PresentData Analyst in the Data Enhancement Group for this media survey company, performing development and maintenance programming of custom data manipulation programs for the extraction, transformation, and loading (ETL) of flat-file data from source into relational tables, stored in MS SQL Server databases, Access, and in Xbase files.• Collation, reduction, migration, and maintenance of source data using Access, Visual FoxPro 9, and MS SQL Server 2012.• Data correction, cleansing, and grooming of extracted source data, ensuring high quality data for next stage analysis and statistical measurement.• Design and write SQL Select statements for use in data analysis and data research using SQL Server Management Console, Visual FoxPro, and Access.• Create or modify stored procedures and triggers for ensuring data integrity when updates to data storage and transaction tables are made.Software Developer IISuperion - High Point, NCApril 2015 to September 2017Development and maintenance programming of public safety applications in use with police and sheriff departments across America. Bug tracking, build process, and source code version control using Team Foundation Server and Vault.• Problem analysis, development, and maintenance programming of application products RMS, JMS, and MFR, using Visual FoxPro 9 and MS SQL Server 2012.• Unit and regression testing, development of test step procedures, and documentation of software problem resolutions.• Agile/Scrum process of software development and problem resolution.Project Team ManagerPrysma Technologies - Mountainside, NJMarch 2014 to April 2015Managed the migration of several legacy Visual FoxPro 9 database applications to an MS SQL Server 2012 client/server database implementation. Project lead for three direct-report database developers in a distributed team environment.• Responsible for leading the software development, testing, documentation, and implementation phases of the project using MS Project and established web-based version control using GitHub and bug tracking with Jira.• Used BaseCamp, GoToMeeting, MavenLink, and Skype as team management tools.Systems Test Engineer IIITASC - Stafford, VAFebruary 2011 to March 2012Member of the Data Integration Team for the Global Combat Support System-Marine Corps (GCSS-MC) Oracle Enterprise database application in use by MARCORSYSCOM-Quantico.• Data Integration testing of GCSS-MC with many interfacing applications that send/receive shipment status data across the interface, verifying receipt and updating the quantity status in the system.• Development of test plans and test step procedures for unit and integration testing.Principal Software EngineerGeneral Dynamics Information Technology - Fairfax, VADecember 2003 to October 2010Performed new development and maintenance of the Automated Manifest System - Tactical (AMSTAC), a vertical market military database application, developed using Visual FoxPro 9 and MS SQL Server 2005, in use with the U.S. Army's Defense Logistics Agency (DLA) and Marine Corps Systems Command (MCSC) for freight shipment packaging, receiving, and freight forwarding using Visual FoxPro 9.• Software engineering project team leader and lead developer, exemplifying best practices in software development, code reuse, unit and system testing, and source code and application version control.Senior Task LeaderL3 Corp-Government Services Division - Washington, DCDecember 1998 to December 2003Project leader and mentor for a team of five software programmers (direct-reports) for the development and maintenance of management-level database applications in use by the Naval Seas Systems Command's PMO 317 & 377 Amphibious Warfare Shipbuilding program offices at the Washington Navy Yard.• Provided management-level reporting of project status and delivery timelines and milestones.• Led development team in timely delivery of custom database applications using Visual FoxPro.Senior ProgrammerCC Pace - Fairfax, VAMarch 1998 to November 1998Database software programmer for custom and proprietary vertical market applications serving the home mortgage realty industry using Visual FoxPro.Database ProgrammerParadise Software, Inc - Herndon, VAOctober 1997 to March 1998Database software programmer providing modification and updates to the reporting system for client insurance company's billing applications using Visual FoxPro.Project Leader/Application DeveloperGE Capital - Chantilly, VAOctober 1996 to October 1997Project Team Leader and Software Developer with the Consulting division of GE Capital under acquisition of MaxTech, Inc., a software information technology company based in Northern Virginia, providing software development and database support to major clients Mobil Oil, Georgetown University Medical Center, and U-Haul. Team leader for three direct-report software developers.• Led development teams in timely delivery of custom database applications built using Microsoft Visual FoxPro and Access relational database tools. Provided reporting of project status  timelines and milestones.• Worked in healthcare domain developing a database application ""Georgetown University Medical Budget Builder"" (GUMB-B) for the Georgetown University Hospital System that created and managed the yearly budgets for all of the various departments of the hospital.• Worked on the Mobil Oil ""Bridge"" project using FoxPro and SQL Server and managed the team development of Synergy International's hospitality menu and event planning application.,""Skills* C#, HTML, Java, SQL, Xbase, XML* Object-Oriented Programming* Software Engineering* Agile/Scrum Team Development* Project Team Management* Requirements Analysis* RFP/SOW Authoring* Software Quality AssuranceTools* MS SQL Server* MS Visual Studio.Net* MS Office Word, Excel, Powerpoint* MS Visual FoxPro, Visual Basic, Access* Oracle Enterprise* MS Project, VS Team Foundation Server""";;;
"Business Analyst / Data AnalystEnterprise Data Governance ProgramMay 2018 to PresentDescription:CIT's data governance framework comprises of data management policy, related standards, and an enabling maintenance and control capability to define and standardize expectations and facilitate consistency in execution of data management practices across the enterprise, and in accordance with Regulatory Compliance - BCBS 239 Risk Data Aggregation & Risk ReportingThe Enterprise Data Governance Program was established as part of data governance framework and supports the Standard for Data Quality within the CIT Data Management Policy. It provides a common data governance operating model across all Business Segments and Corporate Resources to enhance the validity and accuracy of data from source systems and comprises of various working groups to provide services and solutions aligned with overall bank data governance strategy and in accordance with regulatory requirements.Responsibilities:• Facilitate data governance activities for various businesses and consumers including Anti- Money Laundering (AML), Corporate Credit Risk Rating (CCRR), FR Y 9c• Work on MRAs and Audit requirements in Compliance space - liaison with technology, operations and risk teams, including Finance, Compliance, Information Risk, and Audit• Analyze and define data quality requirements for Critical Data Elements (CDEs), define and implement business and data quality rules in accordance with Data Governance specifications• Trace, review and document the functional and technical lineage of CDEs from source systems to reporting• Assess existing quality control processes and identify control gaps and test to improve and enhance governance and oversight• Assess Business rules and Data Quality Rules to ensure consistency with Business and regulatory standards• Ensure data integrity of standard data sets that will be used for data analysis and reporting purpose by performing appropriate data profiling and analysis - query multiple databases to extract and analyze referential, transactional and master data• Perform Root Cause Analysis (RCA) of data gaps and quality issues and establish resolution plans of data sourcing/accuracy issues• Conduct working group sessions with SMEs, data owners and other impacted stakeholders to raise awareness and allow communication of data related opportunities, circulating gaps and issues• Compile and centralize gaps and issues using HP-ALM and raise IMR (Issue Management & Remediation) for efficient tracking and remediation• Propose and design tactical and strategic solutions - devise logic and derive information from existing data, and analyze and implement/ enhance solutions template• Publish the results and remediation status of Data Gaps and Quality monitoring and produce required dashboards and reporting artifacts for management awareness• Involve in creating and maintaining project documentation, and effectively communicate relevant project information to the senior management and stakeholders• Participate in various testing cycles to ensure the requirements are implemented successfully and provide support throughout the release process• Use Collibra - data governance platform to ? document data flow, track performance, workflows, implement rules and analyze quality? create and maintain Assets, attributes, lineage, table and structure information and data mapping? develop, document and revise system designs by creating flow charts and diagrams of logical operational models and steps of current procedures, systems and data flow? increase systems compatibility and information sharing within the organization's strategic shift towards single authoritative data source and template rationalizationBusiness Analyst/ Data AnalystIHC Enterprise Data ManagementApril 2017 to April 2018Description:Enterprise Data Management (EDM) team was established as part of BNPP's IHC formation (implemented under Section 165 of U.S. Dodd-Frank Act) to address requirements for effective data aggregation and reporting in adherence to BCBS 239 principles. The objective was to establish and maintain a robust governance framework around policies, standards, processes and technology required for better governance and management of data throughout the organization, in alignment with governance principles and meeting required levels of data quality. And to ensure the availability, accessibility, quality and consistency of data across the platform to perform mandated capital & liquidity modeling, provide risk data aggregation and reporting capabilities for risk management. This was accomplished through a combination of Systems analysis, control gaps assessment and data analytics and scrubbing.Responsibilities:• Gathering business requirements for Referential Data used in various regulatory reports (FR-Y9C/ FFIEC-002/ CCAR/ 5G) for defining the scope and identification of Key Data Elements (KDE's)• Analysis of data flow of Key Data Elements (KDEs) through systems, from source to reporting at Data Capture, Data Movement and Data Transformation levels and documenting the key hand offs & transformation throughout the journey of the critical elements.• Building project plan, prioritizing requirements, providing high level estimate of efforts for analysis, implementation and support, estimating delivery schedule and resource allocation• Building process flow diagrams, approach and implementation instructions for project procedure document• Performing data analytics - profiling, scrubbing for accuracy and consistency of data throughout data paths from upstream source systems to reporting systems to ensure data quality is consistent with Business and Regulatory standards.• Analyze data based on the profiling results, form new data quality rules based on the analysis and outcome of profiling to address inadequacy of checks/ controls at source system level.• Perform pre-assessment on these rules to identify the exceptions if any and discuss with the respective data steward to clean up the data or modify the rules based on the recommendation from data steward• Sourcing, extracting and analyzing large sets of data from various source and reporting systems using SQL, Advanced Excel, and Informatica by implementing fuzzy rules and logic to identify exceptions in data• Gap/Issue analysis and remediation plans - Investigating exceptions by conducting root cause analysis with input from SME's to define the gaps and propose tactical and strategic remediation plans to facilitate resolution process• Conducting working group sessions with data stewards, regulatory reporting teams and various end users of data to confirm and circulate identified exceptions• Centralizing the data defects identified, raising IMR, analyzing and publishing reports using HP-ALM.• Participated in generation of adjustments due to referential data quality issues. Involved in Y9C/002/RWA residual risk calculations based on unadjusted data.• Involved in maintaining and monitoring the progress and status of the project, creating custom dashboards and developing metrics for weekly, monthly reporting needs.• Liaising with cross-functional teams in Nearshore and Offshore and contributing to team effort by effectively work in a team environment and collaborating with team members on complex projectsBusiness AnalystRabobank - New York, NYSeptember 2014 to March 2017Description:LSTR is a liquidity and stress-testing platform that enables users to create and apply granular level of stress and sensitivities on firm wide products - to project cash flows under both stressed and non-stressed conditions; and to record firms' liquidity impact under different market and operational stress scenarios. The output from this platform is used for Bank's near term liquidity planning & capital management; and also used for regulatory reporting mandated by Basel III & Dodd-Frank such as 4g, 5g reports, LCR (Liquidity Coverage Ratio), NSFR. The core components included: 1) a rule builder- where assumptions and scenarios were applied to generate forecasted cash flow, 2) an aggregation calculator- which aggregates all trade positions and generates aggregated result, 3) a graphical User Interface where user can run a report for any particular business date and scenario by entering specific parameters, and 4) a reporting platform- which shows net inflow/outflow for any particular date for specific scenarios.Responsibilities:• Wrote use cases for applications of Assumptions/Sensitivities on various books of Assets & Liabilities such as Deposits, Wholesale Products (Repo/Reverse Repo), and Contractual Cash Flows such as loan payments, disbursements etc.• Built UI specifications with wireframes and flow diagrams for Rule Builder and command center for aggregation calculator• Conducted Functional Testing with help of team to prove out LCR calculations for multiple lines of businesses using excel models• Conducted tests for onboarding multiple upstream systems into Liquidity and stress platform• Followed the principles of Agile methodology during the entire software development life cycle• Responsible for defining the scope and business rules of the project, gathering business requirements, and document them textually and using models• Partnered with SME's from Investment, Commercial, Personal Banking and Regulatory departments to prepare high-level documents• Acted as a liaison between business users and software development team to assist in translation of business and conducted JAD sessions to allow different stakeholders to communicate their perspectives, resolve any issues, come to an agreement and achieve goals• Assisted Product owner in prioritizing requirements, maintaining and monitoring the progress and status of the project, providing high level estimate of efforts for analysis, implementation and support, estimating delivery schedule and resource allocation• Managed and prioritized stories from Production Backlog into the Sprint Backlog using JIRA• Piloted the daily scrum meetings, stand-up calls, sprint planning & review sessions, story mapping sessions and retrospective meetings as a Scrum Master• Worked with QA Team to develop Test Plan, Test Cases and performed functional testing, unit and integration testing in SIT environment. Documented and track defects, as well as produced detailed report using Quality Center• Analyzed financial historical data and created SQL queries from databases to validate accuracy of data and data flow during onboarding upstream processes into liquidity platform• Provided support to users during and post implementationBusiness AnalystRWA Calculator for Traded Products - Township of Warren, NJNovember 2013 to August 2014Description:The goal of this project was to build a new steady, scalable and sustainable regulatory capital reporting & analysis platform for traded product exposures based on Basel III Advanced and Standardized approach rule. The exposure calculator, part of the platform, was used for identification and measurement of traded product exposures and calculation of Basel III regulatory capital and RWA. The RWA calculations were used to produce required reports for internal and external data consumers. The mainstream integration engine incorporates data from upstream data warehouse along with reference data tables, third party and in-house applications and transmits the data to exposure calculator. The exposure calculator calculates variables such as RWA, EAD, LGD, PD, etc. based on different methodologies (e.g. CEM, IMM, Collateral Haircut, Simple VAR etc.) and then transmits the data to downstream reporting tool. The project is concentrated on traded product exposures like OTC derivative transactions, Repo-Style Transactions and Eligible Margin loans.Responsibilities:• Acquired a thorough understanding of Basel III capital requirements and regulatory reporting requirements• Prepared used cases for EAD calculations for repo style transaction by using Collateral Haircut approach• Contributed to the development of solid controls and reconciliation process around calculation and reporting of Risk Weighted Assets• Participated in reconciliations and ensured the consistency of the exposure between the Accounting and the Risk systems for calculation of Risk Weighted Assets• Contributed to the data collection and data source analysis and used historical data as a base to prepare use cases and validate the aggregator• Interacted constantly with the RWA production and compliance teams, and assisted RWA reporting team on deliverables• Conducted meetings and facilitated JAD sessions with Risk Management Team, SME's and stakeholders and prepared high level document and use cases to define the developer team about the process flow and functional requirements• Prepared graphs and diagrams using MS Visio and MS Excel to understand and describe Collateral Haircut approach to the developers• Followed the principles of Agile methodology during the entire development process• Performed data analysis for the financial data and created SQL queries for data validation and accuracy• Conducted Functional Testing by modeling the calculation methodology on excel and then comparing with the actual result• Managed defects and assisted QA team in developing test strategy, test plan, test cases, and test scripts; and conducted unit testing, integration testing, system testing, and regression testingBusiness AnalystMiddle Office Automation for SFT - Boston, MAMarch 2012 to October 2013Description:Repo/Reverse Repo Desk required a platform to centrally manage the collaterals of the trades in a way that is efficient and also optimized from the standpoint of both cost of collateral and meeting margin call. The Middle Office system is enhanced to provide unilateral views of surplus or deficit collaterals against active positions with counterparties on basis of Master Service Agreements (MSA-s) and Credit Support Annexure (CSA-s) . It also augments operational support to collateral trading activities by allowing users to track the margin call by transactions. The core components included 1) an Allocation module, which matches and allocates each repo and reverse repo trades based on settlement dates and maturity dates, currency and collateral, 2) a margin calculator, which calculates daily mark to market collateral value and 3) a granular User Interface, which allows users to run a net collateral report. System delivers full front to back office processing of collateral inventory report, margin control requirements and optimization of collateral. This application was an enhancement to the legacy system, which was unable to provide more granular information to the system.Responsibilities:• Conducted JAD sessions and meetings with business units and stakeholders to define project scope, to gather requirements and to identify the business flows for activities such as the Matching and Allocation logic and Mark to Market calculations• Created Use Cases and UML diagrams to demonstrate the flow of processes and define the Functional requirements of the application such as calculation of net surplus deficit, outstanding collateral margin call, etc.• Designed UI specs for operational dashboard• Prepared data requirement document to record and store market data like collateral price, fx-rates, mark to market rates, collateral reference, margin calls from clearing broker• Worked with different cross-functional teams like Reference Data team to leverage the market data for margin calculations• Worked closely with the collateral management team and regulation compliance team to understand existing system specifications and new system specifications• Conducted document analysis to capture the existing management system's work flows, and converted all the workflows to Future State Business Designs in the projected Environment• Conducted walkthrough with the development team and stakeholders using slide presentations on Repo and Reverse Repo for better understanding• Worked closely with developers to make sure they understand all the requirements and kept tracking the development progress• Followed the principles of Agile methodology during the software development life cycle• Liaised between product owner, scrum master, development team, and QA team throughout the project life cycle to derive and execute action plans, meeting deadlines, and organization standards, helped the product owner in managing the Product Backlog, Sprint planning, sprint Review, managing daily scrum• Conducted GAP analysis to identify the current business process and document the targeted goals and metrics• Communicated between the front and the back office to see the reports are up to the mark• Created SQL queries from databases to validate data• Conducted Functional Testing, System Integration Testing, Performance Testing, and Regression Testing. Involved in UAT, executing test cases, test scripts, evaluating test results and preparing test summary reports along with QA teamBusiness AnalystFixed Income Trading Platform Risk DashboardJuly 2011 to February 2012Description:The scope of this platform was to enhance the trading platform to seamlessly pull -in risk and analytic data for the ref trade or issuer or securities at the time of order initiation at front office. The existing process required manual interaction between traders and middle office for risk related info of the trade. By the implementation of this project, front office, middle office and risk analytics system were integrated more seamlessly and efficiently. The trader was capable of viewing metrics for risk, pricing, product structuring, pre-deal checking, trade values, position management, etc. The result was a more efficient risk management and a significantly reduced latency time for trading.Responsibilities:• Gathered business requirements from traders, portfolio managers, hedge fund managers, SME's and risk management group to identify and map detailed current processes on fixed income securities and develop functional requirements that supported overall strategy, goals and objectives• Prepared Wire frames, Prototype and Mockup screens and Simulations for trading workstation and risk engine• Prepared the Functional Requirement Document (FRD) and interacted with the developers and defined the requirements to develop the Graphical User Interface (GUI) for Risk management application• Performed data quality analysis of existing and future financial data stores through analysis of reference, market and trade data from vendors such as Bloomberg, Thomson Reuters• Involved with technical teams during implementation such that right business requirements are being translated into the system• Maintained a traceability matrix to keep a track of requirements and their status• Worked closely with QA teams to define test cases and execute test plans and conducted smoke testing, integration testing, system testing and user acceptance testingBusiness AnalystClient On-Boarding ProjectNovember 2010 to June 2011Description:This project was to implement an effective KYC program in the bank in compliance with KYC regulatory requirements. It was initiated to make the customer identification and verification process more streamlined, robust and compliant with the regulatory needs. As part of the program, a risk rating engine was created which assigned a risk rating to clients' profiles on basis of CIP, CDD, EDD conducted on the customer during its onboarding process. This risk-rating engine was integrated with customer master data, customer onboarding system and customer relationship management (CRM) system.Responsibilities:• Wrote specifications for integrating master data management system, CRM, KYC platform and risk rating system• Created data dictionary for different attributes on customer data and data model to define the customer profile for risk rating• Involved in designing the UI prototype using wireframes, screen mockups and high-level process workflows, which covered customer on-boarding, customer profiling, CDD, risk scoring, EDD, and investigations and reporting• Conducted JAD sessions, reviewed and gathered requirements from the SMEs and Stakeholders using various elicitation techniques and documented BRD and FRD for the KYC program• Analyzed the existing customer's data and understood the necessary information that needs to be captured for each existing customer and prepare missing values, anomalies for the completion of the CDD• Conducted meetings with data administrators to gather data from each department to match the KYC required inputs and creating data mapping documents for developers to create the KYC compliance database.• Understanding the data elements across all the business lines and identified and cleaned up the inconsistent data for key risk scoring elements with the help of data experts in our team• Maintained client and portfolio reference data and ensured accurate client data is maintained on internal systems• Performed data analysis for validating data during integration of multiple systems with risk engine• Developed user test cases and validated test results along with QA team for the User Acceptance Testing as well as guided the business testers during UAT and performed SITBusiness AnalystOnline Banking Project - Mumbai, MaharashtraFebruary 2010 to October 2010Description:The goal of this project was to upgrade the existing online banking system to make it more convenient for user to handle different accounts. The general functions of this online banking system included day-to-day personal banking services. Certain enhancements and new features added to the existing system were:• Added a one click button that enabled user to switch to a different account's transaction history page• Added a filter category to filter the transactions by types and range of amount• Added 'report missing card', 'change your profile settings' and 'print' button• Added 'schedule an appointment' under support centerResponsibilities:• Worked with marketing team in conducting surveys and interviewing selected users for gathering and improving client needs and to support the re-design and enhancement of the existing online system• Wrote business and functional specification documents for day-to- day retail banking needs• Created screen mockups and UI specifications using wireframe and flow diagrams for various retail banking functions and for documenting the functionality of separate modules• Worked with the design architect to make the User interface user-friendly• Functioned as the primary liaison between the business line, operations, and the technical areas throughout the project cycle• Played a key role in the planning, testing, and implementation of system enhancements and conversions• Involved in the testing phase along with QA team, prepared the data for the UAT and tested each new feature manually on various mainstream web browsers, like IE, Firefox, Opera, and Safari. Performed System testing, Integration testing, Regression testing and User Acceptance testing,""DOMAIN SKILLS• Experience of working in and implementing various Regulatory & Compliance platforms such as Basel I/II/III, CCAR, Dodd-Frank and KYC"; with understanding of liquidity risk and credit risk• Core functions of the data governance program, including Enterprise Data Governance in CCAR & Anti Money Laundering (AML)• Experience of working in Collateral Management System and enhancing FI trading platform for large Asset Management Firms• Conceptual understanding of several financial products (Equities, Fixed Income securities, Secured Financing products (Repo, Reverse Repo)BA SKILLS• Experience with various Software Development Life Cycle (SDLC) methodologies including Agile/Scrum, Waterfall• Highly proficient in requirement gathering, analysis and documentation by coordinating and facilitating JAD sessions, brainstorming, conducting interviews with business users• Excellent Business writing skills in writing Business requirements document (BRD), Use Case Specifications, Functional and Software Requirements Specification and business process workflows• Expertise in conducting GAP Analysis to document the existing system process workflow and proposed system process workflow required to determine project timeline, resources, and budget• Excellent skills in developing wireframes for GUI designs, writing Use cases, creating UML diagrams such as Activity, Use Case, Flow charts and process flow diagrams using MS Visio, Lucid Charts• Experience of using SQL queries across multiple database servers to extract, compile, track data and querying data for data quality analysis, testing and reporting purposes• Experience in planning, managing and communicating project plans and changes by using tools such as JIRA• Extensive experience developing and documenting test strategy, test plan, test cases, and test scripts;" created, imported, and ran Test Cases, logged defects and performed defect tracking using Requirement Traceability Matrix (RTM)• Extensive knowledge in conducting User Acceptance Test (UAT), System Integration Testing (SIT), Regression Testing, Functional Testing• Proficient with Microsoft Excel, Microsoft Visio, HP-ALM and well understanding of Structured Query Language (SQL) and Collibra• Solid knowledge of data governance and management principles and processes, including hands on knowledge of data analysis, data profiling, data lineage, data dictionary, data quality checks and metadata management, Reference, Transaction, Master and Reporting Data Management and IMR (Issue Management & Remediation)• Well versed with working in team-environment and developing relationship with external customers and internal counterparts, and managing workload within time sensitive deadlinesTECHNICAL SKILLS• Methodologies: Waterfall, Agile-scrum• Testing Tools: HP ALM, HP Quality Center• Data Base: Oracle 9i/10g/11g, MS Access 7.0, MS-SQL Server.• Operating System: Windows 2000/2003/2010/XP, Familiar with UNIX and LINUX• Languages: SQL• Tools: MS-Visio, MS-office, MS- SharePoint, MS-Project, JIRA, Informatica, Advanced Excel, IBM Cognos• Collibra Data Governance Platform""";
"Data Analyst Geographical Data - Menlo Park, CAMay 2018 to February 2019Via Collabera- Working closely with Places Geo Data, Ads Targeting & Home Prediction team to ensure that quality for the cities & countries for the Facebook & Instagram Database.- Verified the integrity of a large volume of Facebook's places and improving significantly the maps data with a high level of accuracy to determine data quality.- Creating city and places to Facebook database graph for proper ads targeting.-	Worked closely with the engineers and providing feedback upon improving the existing tools and the process efficiently.-	Evaluated the quality thousands of top cities where Facebook acquire their 100% revenue in Facebook Graph that resulted to increase of click-through rate of 2.3% percentage.Data Analyst - Places DataFacebook - Menlo Park, CAFebruary 2017 to May 2018Via Collabera- Manage team of data analysts in charge of gathering ground truth data about places on Facebook's graph; team delivered 10 million labels in 2018 in support of machine learning classification and overall measurement (representing a 50% increase from 2017)- Led a quality effort designed to increase the accuracy of labels generated; implemented tactics including training enhancement, guideline localization / translation, and cross-team collaboration which boosted data quality 36ppts (to 95%) vs. 2017- Identified opportunities to increase rating efficiency and visibility by brainstorming new ways to use internal rating tools; submitted feature requests and bugs, then worked with engineers to implement fixes that unlocked efficiency gains of 15-35% (allowing more throughput and minimizing cost of labeling)- Overall efforts helped contribute to Facebook graph quality increase of 15% vs. 2017 via various machine learning applications and human curation- Worked cross-functionally with teams including Operations, Product, Engineering, and OutsourcingPublic Content ReviewerFacebook - Menlo Park, CAMay 2017 to August 2017Via Collabera-	Reviewed and analyzed both graphic and sensitive contents for Facebook and Instagram projects with a 99% accuracy.-	Enforced Facebook & Instagram community standards and policies accordingly-	Work cross-functionally with community operations program managers, policy and safety teams, and project engineers-	Analyze data across multiple projects and provide daily insights and metrics reports into project trends and new casesINTERNSHIPHardware & Software SpecialistWorld Citi Medical CenterFebruary 2015 to May 2015* Quezon City, Philippines• Managing SQL/Oracle Database• Hardware and Software Technical Support• Setting up CCTV cameras• Cable Networking• Software Programming(.NET)• Assisting students• Provides computer helpdesk support and technical training on hardware and software to end userCompleted 486 Hours of practicum service as required,""• Can priority, work efficiently, productively and manages time well• Initiative and self-motivated• Fast Learner• Willing to work under pressure• Knowledge in programming languages (C#, Java, HTML, Java Script, VB.net, Assembly Language)• Content Management• Strong Data Analysis & Attention to detail• Proficient in managing SQL Database/Oracle Database• Knowledge in Networking/ Cisco 1-4• Excellent in Microsoft Office (Microsoft Excel, Word & PowerPoint) and Linux Based Products• Has a photo editing skill by using Adobe Photoshop•	Has a good technical skill in both Hardware & Software•	Bilingual: Tagalog & EnglishCertificate:Compti A+	2017-2017""";;;
"Data Analyst Intern Wunderman Data - Houston, TXSeptember 2018 to December 2018• Analyze and manipulate data per client's request in Mainframe• Manage large quantity files and submit reports for companies weekly• Communicate client's account unlocks and password resets to appropriate IT departments, and resolve account issues for clientCashierKaty, TXSeptember 2017 to December 2017• Managed the opening of the store: cleaning store, posting discount outside of store, opened cashier with appropriate amount and change• Managed over $150 cash• Interacted with customers to promote the sale and information of products• Sold in bulk and single productsDesk AssistantUniversity of Houston - Houston, TXAugust 2016 to May 2017• Help train new employer on residential systems, extensive information on all seven residency halls, and customer service reports.• Convert office from primarily paper files to paperless, seamlessly.• Respond and resolve all email, phone, and in person customer service inquiries, application cancellations, applications, questions, and conflicts.• Maintain up to date on all campus activities and details.• Organize, approve, and hang all advertisement and event flyers and publications.• Work with programs RMS, Mercury, and Microsoft Office to help current residents and prospective residents with applications or information of their housing finances.,""SKILLSFluent in Spanish.Customer serviceMicrosoft Excel, Access, Word, PowerPoint efficient.""";;;
"Financial Data Analyst Intern Access Data - Pittsburgh, PAAugust 2018 to Present• Utilizing SalesVision to review, clean and verify big data exceptions for mutual fund transactions and then standardize for processing • Assist in identifying process improvements to optimize operationsSalesMoonshine Chocolate - Pittsburgh, PAMay 2018 to Present• Sell upscale chocolate at multiple venues throughout the country, responsible for building relationships with show coordinators, booth setup and teardown, customer relations and fiscal management • Assisted in developing an Instagram marketing campaign increasing social media influencePACT TutorSpiritan Division of Academic Progress - Pittsburgh, PASeptember 2016 to May 2017• Tutored children from kindergarten through fifth grade in the Pittsburgh community • Organized after school recreational activities during study breaksLandscaper - Gaithersburg, MDJune 2013 to August 2016,""Summary of SkillsSoftware: Microsoft Office, Power Point, Word, Excel, Access, SQL, SalesVision, Microsoft Project, C++Core Competencies: Written and Verbal Communication, Problem Solving, Ability to Multi-Task""";;;
"Data Analyst Stratadata TechnologiesApril 2015 to December 2016*Visualized the data based on user experiences using ggplot2Graduate	specialized  in   Businesspackage and identified distinct groups of experience states with k- Analytics and Data Science with 2 yearsmeans clustering in R of work experience as Data Analyst.APR 2015 - DEC 2016Data Analyst, Stratadata Technologies,""TECHNICAL SKILLS	miner, as a result loyalist had 20% more chances of responding to a*	promotion campaignPython, SQL, R Studio	*Developed machine learning models to predict Customer LifetimeStatistics and Probability	Value (CLV) of an auto insurance company in Python, here RandomData Mining	Forrest being the best model with an accuracy of 81.34 % and mostData Visualization - Tableau	effective variables being the type of insurance and annual incomeData Analysis	Performed descriptive and predictive analytics on Lender's Club dataMachine Learning	in R. Forecasted Average Interest rate as15% based on lowWeb Scraping	delinquency, good payment pattern using Linear regression, logistic*	regression, SVM and Decision tree.Time Series AnalysisPower user of Excel, SASEnterprise Miner""";;;
"Data Analyst Data Science Center at Nell Hodgson Woodruff School of Nursing - Atlanta, GAMay 2018 to Present• Solve use cases proposed by health professionals using SQL and R based on an electronic medical database over 100 million patients• Develop Shiny App user interface for electronic health records (EHRs) database by incorporating functions of joining tables, makingcustomized plots and performing statistical tests• Utilize MongoDB and JSON data format to improve the performance of manipulating big database from the R studio end• Transform and analyze nurse notes by text mining algorithms to predict medicare safety and qualityResearch AssistantDordt College - Sioux Center, IAJune 2017 to August 2017• Updated statistical method to estimate the association between genotype with 10 to 10,000 gene variants and quantitative phenotypes• Created simulations to compare statistical powers of ten different methods and discovered the most vigorous one• Incorporated three datasets - gene expression, transcription regulatory network and metabolism framework and performed linearprogramming to predict metabolism of bacteria such as E. coli based on given media condition and gene expression informationData AnalystModular R&D - Shanghai, CNJune 2016 to August 2016• Developed Python algorithm that can scrape information about doctors' published papers from PubMed, import it into seven tables in MySQL database and update database periodically• Applied multiple linear regression to model doctors' achievement and evaluated model accuracy by cross validation• Extracted data from various sources, transformed and calculated data to appropriate format and loaded to database through SQL,""SKILLSProgramming: R (advanced user), Python (advanced user), SQL (advanced user), SAS, Tableau, R Shiny, MS Access,Mathematica, batch scripting in Linux, ETL Processing""";;;
"DATA ANALYST / REPORT WRITEREXPERIENCE 10+ yearsCreated ad-hoc management reports used to make critical business decisions. Supported management and staff with ad hoc projects i.e. tables, graphs, data presentation, etc. by querying data from a variety of Access and Oracle databases.Performed data mining of billing history database and identified significant previously unbilled revenues.Developed Microsoft Access applications to automate reporting tasks, e.g. daily customer enrollment status reports, billing histories, billing variance reporting and energy usage histories.Extracted, compiled, formatted, reconciled and submitted the physical energy sales data for the Federal Energy Regulatory Commission (FERC) Electric Quarterly Report (EQR). Significantly reduced report creation time by designing and developing a Microsoft Access application to merge, consolidate, and format sales data from over 88 Microsoft Excel spreadsheets. Created additional applications to format data extracted from the Allegro, ZaiNet and nMarket systems. Extracted all data from the existing billing system and associated systems as part of a new billing system implementation (Banner, 9-month project). Created queries that combined, manipulated and exported the data to Excel workbooks. Created various data verification and compression processes.Designed and created back office accounting reports via the report-writer function of the ZaiNet energy trading, scheduling and risk management system. Created ad-hoc and production property preservation SQL reports. Imported property inspection orders and cancellations from banks and mortgage companies, and returned the inspection results.Created and maintained process and procedure documentation.SCHOLARSHIP REPORTINGEXPERIENCE 3+ yearsManaged annual scholarship and endowed fund database and reporting process for over 1,000 scholarship funds.Acted as communication liaison between donor and scholar. Provided special reporting and ad hoc reporting (scholar/fund data/market values/book values) as needed. Researched and resolved data integrity issues.Initiated, compiled, and communicated the merge of Word and OneNote process and procedure documents into one resource file. Initiated and maintained many improvements to multiple FileMaker Endowed Scholarship databases resulting in significant time-savings and increased efficiencies:Created a multi-script process pulling data from multiple databases to be merged into one pdf file for endowed scholarship donor acknowledgement and reporting.Designed and created a FileMaker scholar thank-you letter proofing layout which increased colleague efficiency and timeliness. Created additional layouts that mirrored Dartmouth stationery eliminating the need for letter-head stock.Created scripts which identified all funds supported by a household (e.g. husband and wife with multiple and separate funds) and then produced the household's scholar announcement letter.Merged the data from two separate scholarship databases into one database resulting in a significant maintenance time-savings.Performed data updates to Scholarship fund, Monitored fund, In Memory Of and Prizes/Awards databases by importing data from multiple FileMaker and Oracle database sources (Financial Aid Office, Advance, Data Warehouse and iModules). Provided technical and software support as well as training (FileMaker, Excel, Acrobat Pro, printing and processes) to colleagues.SOFTWARE EXPERIENCEADVANCED: Microsoft Office (Excel, Access, Word, PowerPoint), FileMaker Pro, Adobe Acrobat, Adobe Photoshop 7EXPERIENCED:  SQL, Advance, iModules Encompass, FERC EQR System, ZaiNet Report Writer, Crystal Reports, HTML, PGP, 7-Zip, Web Help Desk, Adobe Dreamweaver, NetObjects Fusion, OpenOffice, MS Publisher, VISIO, Banner 2000, QuickBooks Pro, CorelDraw, Windows, DOSBEGINNER: Android Studio, Linux, Sybase Central 6.1, System Center Virtual Machine Manager (SCVMM) Admin Console, WordPress, mySQL, PHP, Oracle Report Builder,""EMPLOYMENT OVERVIEW:STEWARDSHIP COORDINATOR, company name withheld, Dec. 2014 – presentDATA & REPORTING ANALYST, National Field Representatives, Inc., May 2012 - January 2014MISCELLANEOUS SURVIVAL POSITIONS, March 2010 - July 2012FERC EQR ANALYST, consulting at Select Energy, February 2006 - May 2006, March 2007 - May 2008BUSINESS APPLICATION SYSTEMS DEVELOPER, Select Energy, August 2003 - February 2006DATA ANALYST, consulting at Select Energy, September 1999 - August 2003""";;;
"Data Analyst Apex Systems - Austin, TXApril 2018 to PresentLong term placement as data analyst working with Apple ?   Conducted market research and curation of ground truth data ?   Created ad hoc SQL queries for exploratory data analysis and operational needs ?   Maintained data integrity to a high degree of accuracy (redundant?) ?   Developed documentation and training materials for new recruits ?   Created scripts for for data checking and maintenanceStatistics AssistantStatistics OfficeFebruary 2016 to November 2016St. Helena (South Atlantic)St Helena Government, St Helena, South Atlantic OceanFebruary 2016 - November 2016 ?   Provided direct assistance to Government Statistician in collating, processing, analyzing and reporting on the 2016 St. Helena Census ? Data entry, validation and analysis using CSPro census software ? Maintained strict standards of confidentiality and data security ?  Designed workflows, spreadsheets and reports for data storage and analysis ? Collated and analyzed key government data for economic and statistical analysisStudent InternCayman Islands Ministry of Education - George Town, KYJune 2011 to July 2011June 2010 - July 2010; June 2009 - July 2009, May - August 2008 ?   Assisted with processing and analysis of student assessments and school performance,""SKILLS?   Skilled and experienced with SQL and statistical analysis"; certified SAS programmer?   High level of proficiency with MS Excel, Access and Word?   Experience working in data analysis with large datasets in confidential environment?   Problem solver; outcome driven;" works well independently and in teams?   Ability to develop and/or follow set project protocols and guidelines?   Resourceful researcher with experience in researching and evaluating critical data?   Excellent written, critical thinking and interpersonal communication skills and attention todetailSoftware Skills:?   Microsoft Office & G-Suite?   PostgreSQL?   SAS?   Python"""
Data Scientist, A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)or equivalent experience 4+ years of industry experience in predictive modeling, data science and analysisPrevious experience in a ML or data scientist role and a track record of building ML or DL models Experience using Python and/or R Knowledge of SparkMLAble to write production level code, which is well-written and explainable Experience using ML libraries, such as scikit-learn, caret, mlr, mllib Experience working with GPUs to develop models Experience handling terabyte size datasets Experience diving into data to discover hidden patterns Familiarity with using data visualization tools Knowledge and experience of writing and tuning SQL Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format Experience giving data presentations Extended travel to customer locations may be required to deliver professional services, as needed. Major responsibilities include: Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances . Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization. Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models. Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.Work with our Professional Services Big Data consultants to analyze,extract, normalize, and label relevant data.Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built. Assist customers with identifying model drift and retraining models.Research and implement novel ML and DL approaches, including using FPGA.;;;
