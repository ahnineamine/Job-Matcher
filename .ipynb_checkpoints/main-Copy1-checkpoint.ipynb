{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from DocSim.ipynb\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import unicodedata\n",
    "import flask\n",
    "from flask import request, jsonify\n",
    "import import_ipynb\n",
    "from DocSim import DocSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [25/Mar/2019 12:01:22] \"POST /processjson HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Initiate Flask application\n",
    "app = flask.Flask(__name__)\n",
    "app.config[\"DEBUG\"] = True\n",
    "\n",
    "#load word embeddings model\n",
    "model_path = \"word2vec_model\"\n",
    "model = KeyedVectors.load(model_path)\n",
    "\n",
    "#initiate DocSim object\n",
    "ds = DocSim(model)\n",
    "\"\"\"\n",
    "---this part is for Json file input---\n",
    "\n",
    "L_input=[]\n",
    "L_index=[]\n",
    "data = json.loads(open('test-data.json').read()) #name of json file in general\n",
    "for cv in data['cv']:\n",
    "    index = cv['id']\n",
    "    content = cv['exp']+','+ cv['skill']\n",
    "    L_input.append(content)   \n",
    "    L_index.append(index)\n",
    "\n",
    "content_offer = data['job']['title']+','+data['job']['desc']+','+data['job']['req']\n",
    "L_input.append(content_offer)\n",
    "\n",
    "\"\"\"\n",
    "def get_data(file):\n",
    "    with open(file) as f:\n",
    "        line_list=[]\n",
    "        index_list = []\n",
    "        for index,l in enumerate(f):\n",
    "            line = l.rstrip('\\n')\n",
    "            line_uni = unicodedata.normalize(\"NFKD\",line)\n",
    "            line_list.append(line_uni)\n",
    "            index_list.append(index)\n",
    "    return line_list,index_list\n",
    "\n",
    "\n",
    "#L_input,L_index= get_data('data/validation_data/validation_set_ITT.csv')\n",
    "\n",
    "@app.route('/processjson',methods=['POST'])\n",
    "def process_files():\n",
    "    data = request.get_json()\n",
    "    L_input=[]\n",
    "    L_index=[]\n",
    "    for cv in data['cv']:\n",
    "        index = cv['id']\n",
    "        #content = cv['exp']+' , '+ cv['skill']\n",
    "        content = cv['info']\n",
    "        L_input.append(content)   \n",
    "        L_index.append(index)\n",
    "\n",
    "    #content_offer = data['job']['title']+' , '+data['job']['desc']+' , '+data['job']['req']\n",
    "    for job in data['job']:\n",
    "        job_content = job['jobinfo']\n",
    "        L_input.append(job_content)\n",
    "        \n",
    "    #return jsonify(L_input)\n",
    "    return jsonify(ds.calculate_similarity(L_input,L_index))\n",
    "\n",
    "\n",
    "app.run(debug=True, use_reloader=False)\n",
    "#sim_scores = ds.calculate_similarity(L_input,L_index)\n",
    "\n",
    "#print(sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
