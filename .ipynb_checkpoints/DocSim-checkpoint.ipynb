{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from scipy.spatial import distance\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.matutils import sparse2full\n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "import math\n",
    "\n",
    "class DocSim(object):\n",
    "    def __init__(self, w2v_model):\n",
    "        self.w2v_model = w2v_model\n",
    "    \n",
    "    def _keep_token(self,t):\n",
    "        return (t.is_alpha and \n",
    "            not (t.is_space or t.is_punct or \n",
    "                    t.is_stop or t.like_num))\n",
    "    \n",
    "    def _lemmatize_doc(self,doc):\n",
    "        return [ t.lemma_ for t in doc if self._keep_token(t)]\n",
    "    \n",
    "    \n",
    "      #Gensim to create a dictionary and filter out stop and infrequent words (lemmas).\n",
    "    def _get_docs_dict(self, docs):\n",
    "        docs_dict = Dictionary(docs)\n",
    "        #CAREFUL: For small corpus carefully modify the parameters for filter_extremes.\n",
    "        #docs_dict.filter_extremes(no_below=5, no_above=0.2)\n",
    "        docs_dict.compactify()\n",
    "        return docs,docs_dict\n",
    "    \n",
    "    def _gensim_preprocess(self,document):\n",
    "       #preprocess the documents using gensim\n",
    "        proc_result=[]\n",
    "        for c in document :\n",
    "            doc=gensim.utils.simple_preprocess(c)\n",
    "            proc_result.append(doc)\n",
    "        return proc_result  \n",
    "    \n",
    "    #def _preprocess(self, doc_list):\n",
    "        #Load spacy model\n",
    "        #nlp  = spacy.load('en')\n",
    "        #lemmatise docs\n",
    "        #docs = [self._lemmatize_doc(nlp(doc)) for doc in doc_list] \n",
    "        #docs = self.gensim_preproc(doc_list)\n",
    "        #Get docs dictionary\n",
    "        #docs_dict = self._get_docs_dict(doc_list)\n",
    "        #return docs_dict\n",
    "\n",
    "    def vector(self,word):\n",
    "        try:\n",
    "            vec = self.w2v_model[word]\n",
    "            return vec\n",
    "        except KeyError:\n",
    "            # Ignore, if the word doesn't exist in the vocabulary\n",
    "            return [0 for i in range(150)]\n",
    "    \n",
    "    \n",
    "    def _get_tfidf(self, docs, docs_dict):\n",
    "        docs_corpus = [docs_dict.doc2bow(doc) for doc in docs]\n",
    "        model_tfidf = TfidfModel(docs_corpus, id2word=docs_dict)\n",
    "        docs_tfidf  = model_tfidf[docs_corpus]\n",
    "        docs_vecs   = np.vstack([sparse2full(c, len(docs_dict)) for c in docs_tfidf])\n",
    "        return docs_vecs\n",
    "    \n",
    "    def tfidf_weighted_wv(self,docs,docs_dict):\n",
    "        #tf-idf\n",
    "        tfidf_w   = self._get_tfidf(docs,docs_dict)\n",
    "        #Load word2vec vectors\n",
    "        tfidf_emb_vecs = np.vstack([self.vector(docs_dict[i]) for i in range(len(docs_dict))])\n",
    "        #we just need to matrix multiply docs_vecs with tfidf_emb_vecs\n",
    "        docs_emb = np.dot(tfidf_w, tfidf_emb_vecs)\n",
    "\n",
    "        return docs_emb\n",
    "\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def Euclidean(self,vec1, vec2) :\n",
    "        return distance.euclidean(vec1, vec2)\n",
    "\n",
    "    def Theta(self,vec1, vec2) :\n",
    "        return math.acos(self._cosine_sim(vec1,vec2)) + math.radians(10)\n",
    "\n",
    "    def Triangle(self,vec1, vec2) :\n",
    "        theta = math.radians(self.Theta(vec1,vec2))\n",
    "        return (np.linalg.norm(vec1) *np.linalg.norm(vec2) * math.sin(theta)) / 2\n",
    "\n",
    "    def Magnitude_Difference(self,vec1, vec2) :\n",
    "        return abs(np.linalg.norm(vec1) - np.linalg.norm(vec2))\n",
    "\n",
    "    def Sector(self,vec1, vec2) :\n",
    "        ED = self.Euclidean(vec1, vec2)\n",
    "        MD = self.Magnitude_Difference(vec1, vec2)\n",
    "        theta = self.Theta(vec1, vec2)\n",
    "        return math.pi * math.pow((ED+MD),2) * theta/360\n",
    "\n",
    "    def TS_SS(self,vec1, vec2) :\n",
    "        \"\"\"Find the Triangle Similarity - Sector Similarity between two vectors.\"\"\"\n",
    "        return self.Triangle(vec1, vec2) * self.Sector(vec1, vec2)\n",
    "\n",
    "\n",
    "    def calculate_similarity(self, target_docs=[],L_index=[]):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document \"job offer\" & all\n",
    "        the target documents \"CVs\". \"\"\"\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "        target = self._gensim_preprocess(target_docs)\n",
    "        target_tuple = self._get_docs_dict(target) \n",
    "        docs_emb = self.tfidf_weighted_wv(target_tuple[0],target_tuple[1])\n",
    "        without_source_emb = docs_emb[:-1]\n",
    "        source_emb = docs_emb[-1]\n",
    "        results = []\n",
    "        for elem,index in zip(without_source_emb,L_index):\n",
    "            sim_score = self.TS_SS(elem, source_emb)\n",
    "            #sim_score = self._cosine_sim(elem, source_emb)\n",
    "            #if sim_score > threshold:\n",
    "            results.append({\n",
    "                    'score' : sim_score,\n",
    "                    'id' : index,\n",
    "                })\n",
    "            # Sort results by score in asc order\n",
    "            results.sort(key=lambda k : k['score'] , reverse=False)\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
